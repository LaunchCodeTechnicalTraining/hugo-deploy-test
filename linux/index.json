[{"content":"chmod Practice Create a new file called chmod.exercises.\nQuestion: What are the default permissions for the new file?   CLICK FOR ANSWER  -rw-rw-r--:\n owner: Read and Write group: Read and Write all others: Read    Bonus Question: What was the command to view the file permissions?   CLICK FOR ANSWER  ls -l chmod.exercises\n  Change chmod.exercises permissions to -r--r--r-- Change the file permissions to Read only for the owner, group and all other users.\nQuestion: What was the command for changing the file permissions to -r--r--r--?   CLICK FOR ANSWER  chmod 444 chmod.exercises\n  Change chmod.exercises permissions to -rw-r----- Change the file permissions to match the following:\n owner: Read and Write group: Read other: no permissions (None)  Question: What was the command for changing teh file permissions to -rw-r-----?   CLICK FOR ANSWER  chmod 640 chmod.exercises\n  Change chmod.exercises permissions to -rwxr-x--x Change the file permissions to match the following:\n owner: Read, Write and Execute group: Read and Execute other: Execute  Question: What was the command for changing the file permissions to -rwxr-x--x?   CLICK FOR ANSWER  chmod 751 chmod.exercises\n   Note After completing the exercises feel free to delete the chmod.exercises file.\n  ","description":"","tags":null,"title":"Chmod Exercises","uri":"/file-permissions/exercises/chmod/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## File Permissions --- ## Linux File Permissions All files have permissions for different types of classifications The classifications are Owners, Groups, and Others ___ ### Available Permissions Read, Write, Execute, None Read: User, Group, and Other can Read the file Write: User, Group, and Other can Write to the file Execute: User, Group, and Other can execute the file None: None of the above permissions ___ ## Possible Permission Combinations Read only Write Only Execute only Read and Write Read and Execute Write and Execute Read, Write, and Execute None ___ ### View Permissions You can use the -l option with the ls command for a long listing format of files within a given directory You can expand even further and provide the -a option in addition to -l for all files (including hidden) --- ## Changing File Permissions The chmod command allows you to change file permissions for a file or directory chmod [OPTION] [file-name] Read is represented by the numeric value 4 Write is represented by the numeric value 2 Execute is represented by the numeric value 1 None is represented by the numberic value 0 ___ ### chmod Command Example chmod 444 example-file-name The above command would provide the Owner, Group, and all Other users with access to the \"example-file-name\" file with Read only permissions ___ ### Providing Multiple Permissions You are able to use the numeric values in addition to one another to provide multiple permissions for any given Owner, Group, and Other users Read + Execute = 5 Read + Write = 6 Read + Write + Execute = 7 --- ## Changing File Ownership The chown command allows you to change file ownership for a file or directory chown [OPTION] [OWNER][:[GROUP]] [file-name] ___ ### Change User Ownership chown new-user example-file The above command would change the ownership of the example-file from its current owner to \"new-user\" ___ ### Change Group Ownership chown :new-group example-file The above command would change the ownership of the example-file from its current group to \"new-group\" ___ ### Change User and Group Ownership chown new-user:new-group example-file The above command would change the ownership of the example-file from its current owner to \"new-user\" and group to \"new-group\"         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/file-permissions/slides/"},{"content":"File Permissions  Linux File Permissions All files have permissions for different types of classifications\nThe classifications are Owners, Groups, and Others\n Available Permissions Read, Write, Execute, None\nRead: User, Group, and Other can Read the file Write: User, Group, and Other can Write to the file Execute: User, Group, and Other can execute the file None: None of the above permissions\n Possible Permission Combinations Read only Write Only Execute only Read and Write Read and Execute Write and Execute Read, Write, and Execute None\n View Permissions You can use the -l option with the ls command for a long listing format of files within a given directory\nYou can expand even further and provide the -a option in addition to -l for all files (including hidden)\n Changing File Permissions The chmod command allows you to change file permissions for a file or directory\nchmod [OPTION] [file-name]\nRead is represented by the numeric value 4\nWrite is represented by the numeric value 2\nExecute is represented by the numeric value 1\nNone is represented by the numberic value 0\n chmod Command Example chmod 444 example-file-name\nThe above command would provide the Owner, Group, and all Other users with access to the “example-file-name” file with Read only permissions\n Providing Multiple Permissions You are able to use the numeric values in addition to one another to provide multiple permissions for any given Owner, Group, and Other users\nRead + Execute = 5\nRead + Write = 6\nRead + Write + Execute = 7\n Changing File Ownership The chown command allows you to change file ownership for a file or directory\nchown [OPTION] [OWNER][:[GROUP]] [file-name]\n Change User Ownership chown new-user example-file\nThe above command would change the ownership of the example-file from its current owner to “new-user”\n Change Group Ownership chown :new-group example-file\nThe above command would change the ownership of the example-file from its current group to “new-group”\n Change User and Group Ownership chown new-user:new-group example-file\nThe above command would change the ownership of the example-file from its current owner to “new-user” and group to “new-group”\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/file-permissions/slides/fullscreen/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Scripting with Bash --- ## Bash Scripting Basics A shell script is simply a file that holds a certain set of commands to be run within your terminal and executed by Bash Commonly ending with the file extenstion .sh (although not necessary) shebang - informs OS what shell to use when executing the script. The shebang points to the absolute path of the shell (#!/bin/bash) ___ ### Executing a Script File Executing or running a script file can be done in multiple ways The two examples in this course: By using the command \"bash\" and the script file as an argument Invoking the script by using the absolute or relative path to the script file ### Slide 1 Vertical Slide --- ## Bash Variables Similar to other programming languages you are familiar with Bash utilizes variables Bash Variable: name=\"John\" JavaScript Variable: let name = \"Paul\"; Python Variable: name = \"George\" Java variable: String name = \"Ringo\"; ___ ### Variable Types Similar to Python a bash variable will respect any value type you assign to it --- ## Conditional Statements Bash also contains conditional statements if statements if else if elif else if statements must be closed with \"fi\" ___ ### Operators Bash has built in binary operators for the following: equal to: -eq not equal to: -ne less than: -lt less than or equal to: -le greater than: -gt greater than or equal to: -ge --- ## Loops Bash also contains loops The two we will cover in class will be the for loop and while loop For loops and While loops will have a \"do\" statement with a clause, and a closing \"done\" statement We will also cover for loops with conditional statements         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/bash-scripting/slides/"},{"content":"Scripting with Bash  Bash Scripting Basics A shell script is simply a file that holds a certain set of commands to be run within your terminal and executed by Bash\nCommonly ending with the file extenstion .sh (although not necessary)\nshebang - informs OS what shell to use when executing the script. The shebang points to the absolute path of the shell (#!/bin/bash)\n Executing a Script File Executing or running a script file can be done in multiple ways\nThe two examples in this course:\nBy using the command “bash” and the script file as an argument\nInvoking the script by using the absolute or relative path to the script file\nSlide 1 Vertical Slide  Bash Variables Similar to other programming languages you are familiar with Bash utilizes variables\nBash Variable: name=“John”\nJavaScript Variable: let name = “Paul”;\nPython Variable: name = “George”\nJava variable: String name = “Ringo”;\n Variable Types Similar to Python a bash variable will respect any value type you assign to it\n Conditional Statements Bash also contains conditional statements\nif statements\nif else\nif elif else\nif statements must be closed with “fi”\n Operators Bash has built in binary operators for the following:\nequal to: -eq\nnot equal to: -ne\nless than: -lt\nless than or equal to: -le\ngreater than: -gt\ngreater than or equal to: -ge\n Loops Bash also contains loops\nThe two we will cover in class will be the for loop and while loop\nFor loops and While loops will have a “do” statement with a clause, and a closing “done” statement\nWe will also cover for loops with conditional statements\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/bash-scripting/slides/fullscreen/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Bash: Streams, Redirection \u0026 Pipes --- ## Types of Streams STDIN: Standard Input - 0 (file descriptor) STDOUT: Standard Output - 1 (file descriptor) STDERR: Standard Error - 2 (file descriptor) ___ ### Standard Input All Bash command are a form of STDIN ___ ### Standard Output STDOUT is always displayed inside of the terminal window by default Should you ever wish for STDOUT not to be displayed this can be accomplished in different ways Sometimes a command allows -s as a \"silent\" option You can also redirect the stream into an alternate location ___ ### Standard Error Similar to STDOUT, STDERR is also displayed inside of the terminal window by default STDERR is commonly the result of an incorrect bash command, incorrect arguments, or incorrect options provided --- ## Redirection Redirect Write  Redirect Append  ___ ### Redirect Write with STDOUT The  operator is used to redirect STDOUT and write to a new location Using the redirect write option will **overwrite** the contents of the target location Redirecting the STDOUT will also prevent the STDOUT of the command to be displayed inside of the terminal window ___ ### Redirect Append with STDOUT The  operator is used to redirect STDOUT and append to a provided location Using the redirect append option will **append** the contents of the target location This means that the STDOUT will be added to a given file in addition to what is already inside As mentioned in the previous slide this will also prevent the STDOUT from being displayed inside of the terminal window ___ ### Redirect STDERR STDERR can also be redirected using its file descriptor To write STDERR to a new location you would use 2 To append STDERR to a new location you would use 2 --- ## Pipes The Bash pipe operator | allows the user to take STDOUT from the first command and use it as STDIN for the next Piping allows the user to chain multiple commands together for more complex commands         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/bash-streams-redirection-pipe/slides/"},{"content":"Bash: Streams, Redirection \u0026 Pipes  Types of Streams STDIN: Standard Input - 0 (file descriptor)\nSTDOUT: Standard Output - 1 (file descriptor)\nSTDERR: Standard Error - 2 (file descriptor)\n Standard Input All Bash command are a form of STDIN\n Standard Output STDOUT is always displayed inside of the terminal window by default\nShould you ever wish for STDOUT not to be displayed this can be accomplished in different ways\nSometimes a command allows -s as a “silent” option\nYou can also redirect the stream into an alternate location\n Standard Error Similar to STDOUT, STDERR is also displayed inside of the terminal window by default\nSTDERR is commonly the result of an incorrect bash command, incorrect arguments, or incorrect options provided\n Redirection Redirect Write \u003e\nRedirect Append »\n Redirect Write with STDOUT The \u003e operator is used to redirect STDOUT and write to a new location\nUsing the redirect write option will overwrite the contents of the target location\nRedirecting the STDOUT will also prevent the STDOUT of the command to be displayed inside of the terminal window\n Redirect Append with STDOUT The » operator is used to redirect STDOUT and append to a provided location\nUsing the redirect append option will append the contents of the target location\nThis means that the STDOUT will be added to a given file in addition to what is already inside\nAs mentioned in the previous slide this will also prevent the STDOUT from being displayed inside of the terminal window\n Redirect STDERR STDERR can also be redirected using its file descriptor\nTo write STDERR to a new location you would use 2\u003e\nTo append STDERR to a new location you would use 2»\n Pipes The Bash pipe operator | allows the user to take STDOUT from the first command and use it as STDIN for the next\nPiping allows the user to chain multiple commands together for more complex commands\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/bash-streams-redirection-pipe/slides/fullscreen/"},{"content":"Updating the Ubuntu Display Size From your Ubuntu Home screen:\nDo an Activity search for Displays:\nSelect the Displays option which will open up the Displays configuration window:\nSelect Resolution and set it to a larger value than the default 800 x 600 (4:3). Be aware of your own monitor resolution. The monitor of the laptop I am using is 1920 x 1080 (16:9) if I choose this option the new window will take up my entire monitor. I will use a smaller resolution, so I still have some monitor real estate.\nI personally chose: 1360 x 768 (16:9):\nAfter making your decision click the Apply button:\nUpon clicking this button, two things will happen:\n The window size of your VirtualBox will be automatically resized slightly larger than the resolution you chose. Ubuntu will display a screen asking you to keep or revert the changes.  If you do not click the keep changes button, within the time frame, your resolution will be automatically reverted back to its original setting.\n Note Ubuntu forces you to accept the changes manually because it is possible to configure your display in a way that would prohibit it from displaying information in a way you can understand it. For this reason, Ubuntu will automatically revert back to the original settings that it knows will work.\n  This change in Display resolution is stored within the machine. So next time you boot up this VirtualBox image it will automatically use the display resolution we just configured!\n","description":"","tags":null,"title":"Updating the Ubuntu Display Size","uri":"/quality-of-life/walkthrough/ubuntu-display/"},{"content":"In the top right corner of each page you will see a link in the page menu section called Edit this page. Clicking this button will take you to the GitHub repository of this project. If you are currently logged in to your personal Github account you will be presented with the option of Forking the repository into your own account.\nAfter you fork the account, you will be able to directly edit the page through the fork on your account. Once you have completed your changes, you will be prompted to title your commit, add a description of the work you completed, and to open a Pull Request back into the original Github repo.\nOnce you create the Pull Request LaunchCode will be able to see your requested changes and can then approve, or deny the proposed changes. If approved your changes will be merged into the master branch and will be deployed to the live site.\nSteps Edit Page On the page where you have seen a typo, click the Edit this Page button found in the breadcrumb menu in the top right hand corner of your screen. It looks like the following picture:\nRepository has Write Protection The GitHub repository is likely configured in a way that protects write access. The only individuals that can write directly to the repository are the team of developers and employees at LaunchCode that are responsible for maintaining this curriculum. Never fear, you still have a mechanism for sharing your changes with the team to be included in the curriculum, and you will become a contributor of the project!\nGitHub is aware of this write protection and will prompt you to fork the repository to your own account, where you will have write access. You can make the corrections on your forked version, and then create a GitHub Pull Request into the original version. One of the project maintainers will be able to include your changes into the project, assuming your changes are accepted.\n Note When you first click the Edit this Page button if you aren’t already logged in to your GitHub account you will be prompted to do so and will be greeted by a login screen:   Forking the Repository After logging in you will be asked to Fork the repository, assuming you haven’t forked the repository in the past.\nClick the green Fork this repository which will create a new repository on your github account at that follows this pattern: https://github.com/your-github-username/repository-name. However, GitHub will display to you a screen that allows you to directly edit the file called\n Note Take note of the notification in the picture: “You’re making changes in a project you don’t have write access to. Submitting a change will write it to a new branch in y our fork paulmatthews1989/linux, so you can send a pull request.” It is clearly telling us any changes we make and commit will go to our forked project at the path in the note.\n  The bottom of the page has a basic form for allowing you to commit your changes to your personal fork. We will create a new Pull Request after making our changes, and committing to our personal fork.\nIdentifying \u0026 Making a Change Looking over the file we see a typo. On line 18 the current curriculum says the word it's, but they are using the apostrophe incorrectly. The typo is highlighted in the following picture:\nWe can make the change directly in this window by removing the apostrophe:\nWe could continue to copy/edit this page, but for simplicity sake let’s go ahead and say our work is complete.\nPropose a Change By Committing Once our edits are complete we need to create a commit on our personal fork of this project, and propose the change. This is done simply in one step when we click the Propose changes button.\nBefore you propose your change make sure to add a Commit Title and Commit Description like the following picture:\n commit title: fixed typo commit description: changed `it’s` to `its` on line 18.  Once you have added a meaningful commit click the Propose changes button:\nUpon clicking this button, multiple things happened. What you see is the comparing changes screen before a GitHub Pull Request is created. It is comparing https://github.com/LaunchCodeTechincalTraining/linux/ master branch to https://github.com/paulmatthews1989/linux patch-1 branch.\nIn fact we are trying to merge the paulmatthews/1989/linux:patch-1 branch into the LaunchCodeTechnicalTraining/linux:master branch.\n Note Behind the scenes stuff: paulmatthews1989/linux/tree/master paulmatthews1989/linux/tree/patch-1\n  Once you click the Create pull request button on the Comparing changes screen you will notice the screen changes to:\nThis is giving you a chance to change the Pull Request title, or description. If you didn’t provide a meaningful title and description make sure to do so before clicking the Create pull request button which will finally create the Pull Request.\nPull Request Screen After the pull request has been created you will be taken to the page for the pull request you just created. This screen will contain:\n a pull request number pull request conversation pull request commits that are a part of the branch being merged into master, the status of any checks  listed are all of the commits that occured in the patch-1 branch that are being merged into the master branch   all files that experienced a change  Pull Request Checks As a part of this pull request there are various checks that are being performed. One of which will include a link to a live link for this project thanks to Netlify.\nAs the work is being performed and the checks are processing you will likely see a screen similar to the following image:\nThe Netfliy checks haven’t completed yet, and the Required Netlify task of deploying the preview for this Pull Request is still processing.\nOnce Netfliy has completed the deployment you will see:\nThere are two things of note here:\n All checks have passed: Netlify did it’s thing and was able to successfully deploy the project including your changes! Browse the preview: https://deploy-preview-15--lctt-linux.netlify.app: A live link exists that we can follow to see the entire project deployed including your changes!   Note If you didn’t see the link for the deployment try this picture highlighting the link:   Go ahead and click the link, and navigate to the page you edited:\nNotice the typo is gone.\nPull Request Approval Process Your pull request will still need to be reviewed by a maintainer of this project.\nWe will do our best to incorporate valid changes to the curriculum, but make no guarantees that your work will be approved and merged into the LaunchCode GitHub repository. We will make an effort to leave feedback on pull requests that are denied with a brief explanation on why the pull request was denied.\nRegardless to your pull request being approved or denied we thank you for your contributions to this project!\nThanks to all of the Linux Contributors!\n","description":"","tags":null,"title":"Suggest a Change to a Page","uri":"/contributing/edit-page/"},{"content":"","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/introduction/slides/fullscreen/"},{"content":"chown Practice Create a new file called chown.exercises.\nQuestion: What are the default owner and group for the new file?   CLICK FOR ANSWER  student student\nThe student user owns the file.\nThe student user is a part of the student group.\n  Bonus Question: What is the command to view the file owner and group?   CLICK FOR ANSWER  ls -l chown.exercises\n  Change the chown.exercises file owner to the root user. Question: What was the command?   CLICK FOR ANSWER  sudo chown root chown.exercises\n  Change the chown.exercises file group to the root group. Question: What was the command?   CLICK FOR ANSWER  sudo chown :root chown.exercises\n  Change the chown.exercises file owner to student and group to student. Question: What wast he command?   CLICK FOR ANSWER  sudo chown student:student chown.exercises\n   Note After completing the exercises feel free to delete the chown.exercises file.\n  ","description":"","tags":null,"title":"Chown Exercises","uri":"/file-permissions/exercises/chown/"},{"content":"Walkthrough User File Permissions Changing File Permissions Changing File Ownership  ","description":"","tags":null,"title":"Walkthrough","uri":"/file-permissions/walkthrough/"},{"content":"Walkthrough Scripting Variables Conditionals Loops  ","description":"","tags":null,"title":"Walkthrough","uri":"/bash-scripting/walkthrough/"},{"content":"Walkthrough Under normal circumstances every Linux distribution package has three streams opened when it starts. A stream for standard input, a stream for standard output, and a stream for errors \u0026 diagnostic information.\nThese streams are ubiquitously known as:\n STDIN: Standard Input STDOUT: Standard Output STDERR: Standard Error   Note By default the STDOUT \u0026 STDERR streams are displayed within the terminal window.\n  Understanding the three data streams is an important concept when working with Linux.\nAlmost every package expects input, performs operations on, or uses, the input, and will very likely provide output based on the actions that were performed.\nAdditionally, when a package encounters unexpected behavior or exceptional conditions information about the failure is displayed to the error stream.\nSTDIN You have worked with STDIN already in this class without knowing it.\nEvery Bash command argument is a form of STDIN.\nArguments are STDIN Consider the bash command ls:\nls /home/student ls is the name of the command and one argument is provided. The argument /home/student is the string representation of the directory that the ls command should operate on.\nA package argument is a form of STDIN.\n Note ls requires an argument because the source code needs to know which directory’s contents should be displayed to STDOUT. ls is configured to use the current working directory when an argument is not provided as the default value of the argument.\n   Bonus Many bash commands and packages are configured in a way to accept multiple arguments. Try:\nls /home/student /home/student/Desktop How does adding a second argument affect STDOUT?\n  STDOUT By default STDOUT is displayed to the terminal window.\nTerminal Display is STDOUT Consider the bash command ls:\nls /home/student Output:\nThe command ls was performed on the /home/student argument and the results were displayed to STDOUT. The string Desktop Documents Downloads Music... is a representation of the contents found inside of the provided directory.\nSTDERR By default STDERR is displayed to the terminal window.\nTerminal Display is STDERR Consider running the cat command on a file that does not exist:\ncat a-file-that-does-not-exist.txt Output:\nThe file a-file-that-does-not-exist.txt does not exist. When provided as an argument to the cat command cat is unable to locate the provided file and prints out an error message: No such file or directory.\nThis error message is not what we expected as the user of the cat command. We expected the contents of the file to be displayed in STDOUT, but since an error occurred when the cat command was running it instead streamed the message to STDERR, which by default is the terminal window of the CLI shell.\nRecap There are three data streams:\n STDIN: input provided to CLI commands STDOUT: standard output provided to the user as a result of CLI commands STDERR: standard error output provided to the user as an error result of a CLI command  The following articles explore stream redirection operators (\u003e and others) and the pipe operator (|) that provide ways to work with the three data streams discussed in this article.\nContent Redirect STDOUT Write File Redirect STDOUT Append File Pipe Operator Bonus: Redirect STDIN Bonus: Redirect STDERR  ","description":"","tags":null,"title":"Walkthrough","uri":"/bash-streams-redirection-pipe/walkthrough/"},{"content":"Content Updating the Ubuntu Display Size  ","description":"","tags":null,"title":"Quality of Life Improvement Articles","uri":"/quality-of-life/walkthrough/"},{"content":"What are GitHub Issues GitHub Issues is a powerful feature built into GitHub that allows individuals to raise issues directly inside the source code of a project. These issues are monitored by the maintainers of the project and the maintainers use the information inside of an individual issue to improve the overall project.\nGitHub issues often include:\n bugs feature requests found vulnerabilities package updating requests optimization requests and more  The maintainers of the project can use these GitHub issues to crowd source bug fixes, and plan additional work to be added to the project that are reported directly from the users.\nProject maintainers have no obligation to include any suggested features, to patch any bugs or vulnerabilities, but do often use the issues to best determine what work needs to happen on any given project.\nGitHub Issues Example: nodejs/node Let’s take a look at the GitHub repo for the NodeJS Project.\nThis is the standard homepage for any GitHub repository. It contains information around:\n name of organization: nodejs name of repo: node repo visibility: Public repo watchers (2.9k), forks (23k), and stars (86.3k) the current branch: master a listing of all of the directories and files in the project  You should notice a list of tabs that can be selected for more information:\n The currently selected, default tab: \u003c\u003e Code Issues Pull requests Discussions Actions Projects Security Insights  Let’s click the Issues tab and see the currently open issues of this repo:\nAt the time of this photo there are 1320 Open \u0026 12987 Closed issues. As you may have guessed node is a tremendously popular and widely used programming language. In the nodejs/node repository bugs, vulnerabilities, possible optimizations, and new features are reported constantly for this very popular tool.\nTwo of the three issues we can see are clearly marked with a feature request label. Both of these issues are requests made by node users for the node developers to add additional features to the project.\nLaunchCode Curriculum GitHub Issues At LaunchCode we store all of our curriculum in GitHub repositories. Our curriculum is going through constant changes and as you work through the curriculum you may find bugs, vulnerabilities, compatibility mismatches, or you may have ideas for features that can be added.\nCreating a new GitHub Issue can be a daunting task. For this reason we have pre-configured three different GitHub Issue Templates to help you in providing us with the information we need to continue improving the curriculum.\nAvailable LaunchCode Provided Issue Templates:\n Bug Clarity Request Feature Request   Note In addition you can open a new blank issue in which you can bring an issue to our attention outside of the three available templates.\n  Creating a New LaunchCode GitHub Issue Curriculum Repository Homepage Curriculum Repository Issues Homepage Curriculum Repository Choose New Issue Template Available Issue Templates LaunchCode provides three Issue Templates, that we encourage you to use:\n bug clarity request feature request  Bug A bug issue is your way to inform us about a bug in the curriculum.\nCommon bugs include:\n a copy/edit error (misspelling, grammar mistake) broken links missing images un-executable code in code-fences buggy features (like the search, or the menu)  As you are working through the curriculum you may encounter any of the above bugs, or ones not mentioned in the list. In the case of encountering the bug we encourage you to create a new issue by using the Bug Issue Template.\nExample Let’s take a look at the Bug Form.\nYou must provide us with:\n Title of the Issue  A brief title for this issue like: Typo on Why Learn To Code   The URL where the bug exists  The full URL: https://education.launchcode.org/intro-to-professional-web-dev/chapters/introduction/why-learn-to-code.html) Or more simply, the path: intro-to-professional-web-dev/chapters/introduction/why-learn-to-code.html   The nature of the bug  What bug did you encounter?  How was it supposed to behave? (expected behavior) How did it actually behave? (actual behavior)   For example: I clicked on the Learn More link, but the resource could not be found with a 404 status code.    Additionally, we ask that you provide any More information around the context of this bug. To adequately fix the bug we have to first recreate the bug on our system. This verifies the existence of the bug and gives us insight into identifying the underlying problem that is causing the bug. These steps have to be completed in order to fix the bug.\nClarity Request Confusion is a natural part of the learning journey. We try to create and organize content in a way that reduces confusion for as many different learning styles as possible.\nThere may be instances where a large number of students and course staff will encounter confusion around the same section of curriculum. When this happens it’s a good indicator that a section should be reworded, reorganized, or rebuilt in a way to reduce the confusion experienced by a large number of individuals.\nThe Clarity Request Form is the mechanism that allows students and course staff to provide feedback around clarity improvements that can be made to the curriculum.\n Warning Please talk to other students and course staff about your confusion before creating a new clarity request. It is possible that the section is already in an adequate format that is meeting the needs of the majority of students and course staff. However, when a large number of students and course staff agree upon a section that is causing confusion it is an appropriate time to create a clarity request.\n  Example Let’s take a look at the Clarity Request Form:\nYou must provide us with:\n Title of Issue The URL to the issue The section of text that caused confusion: Confusing Section  Additionally we ask that you provide:\n Any Suggestions you may have for improving the clarity. Additional information to help us understand the nature of your confusion, or the underlying issue.  Feature Request In some instances you may have ideas about new features to the website hosting the curriculum, or new content that might have a positive impact on the experience of students and course staff working through a LaunchCode program.\nFeatures of the website include:\n text search buttons navigation bars menus  table of contents   next and previous buttons etc  Content may include:\n more code examples more exercises more concept checks additional sections to chapters additional chapters additional explanations additional definitions additional diagrams etc  There are many things that could be added to the website or to the content of the curriculum. Again we are looking for consensus from a large number of students and course staff.\nIn this case you need to create a Feature Request Issue.\n Warning Please talk to other students and course staff about your ideas around new content before creating a new feature request. We cannot create every feature that every individual user desires, but are very interested in adding features and content that a majority of students and course staff desire.\n  Example Let’s take a look at the Feature Request Form:\nYou must provide us with a Title and Feature Short Description. We must know the description of the feature you are requesting. If you cannot adequately describe to us either the new feature or content that should be added we cannot decide if the feature or content should be created.\nAdditionally we ask you to provide a longer description of the feature, and suggestions on where/how the feature or content should be added.\nProviding as much details about the new feature or content is necessary for LaunchCode to determine if the feature / content is feasible, and if it should be developed. This makes the longer description of the feature section an important part of the form.\nProviding suggestions on where the feature should be added is also important for LaunchCode to determine where and how the feature or content should be implemented.\nReview GitHub Issues are a way for the users of a project to communicate directly with developers or maintainers of a project.\nGitHub Issues are a mechanism for communicating improvements that can be made to the existing project.\nLaunchCode encourages students, course staff, and allies of LaunchCode to create issues when encountering bugs, requesting new features, or requesting clarity reviews.\nLaunchCode prefers students, course staff, and allies of LaunchCode to utilize the pre-existing GitHub Issues Templates (bug, feature request, clarity request), but still allows for blank issues to be raised.\nClosing Remarks All Issues will be considered by a LaunchCode representative. However, making an issue does not guarantee that the encountered bug, clarity request, feature request or any other issue will be incorporated into the curriculum.\nAny issues may be closed without discussion or reason by a LaunchCode representative.\nLaunchCode reserves the final say in all things related to the curriculum.\nWe appreciate any and all feedback gathered through GitHub Issues and we thank you for your work towards creating better experiences for future students!\n","description":"","tags":null,"title":"Creating a GitHub Issue","uri":"/contributing/gh-issue/"},{"content":"Exercises Chmod Exercises Chown Exercises  Questions \u0026 Answers What are the three different permissions?   CLICK FOR ANSWER   Read Write Execute    Each file has permissions for three different classifications of users? What are those three classifications?   CLICK FOR ANSWER   file owner (user) owner group all other users    What is the command that allows for changing the owner or group of a file?   CLICK FOR ANSWER  chown\n  What is the command that allows for changing the permissions of a file?   CLICK FOR ANSWER  chmod\n  ","description":"","tags":null,"title":"Exercises","uri":"/file-permissions/exercises/"},{"content":"Question and Answers: How do you assign a bash variable?   Click Here for Answer  bash_variable=variable-name    How do you call a bash variable?   Click Here for Answer  $bash_variable_name    What is a shebang?   Click Here for Answer  A shebang is a line that informs the operating system of the exact shell to use when executing the script.\nThe shebang simply points to the absolute path of the shell.\n  What is the shebang syntax for bash?   Click Here for Answer  #!/bin/bash    Build Your Own Script Exercises: Redirection Practice Script Scripting Grep Index of Highest Value Script  ","description":"","tags":null,"title":"Exercises","uri":"/bash-scripting/exercises/"},{"content":"Exercises Redirection: myname.txt Redirection: Saving History Bonus: Pipe Operator  Questions \u0026 Answers What are the three data streams in Bash?   CLICK FOR ANSWER   STDIN STDOUT STDERR    What is the purpose of STDIN?   CLICK FOR ANSWER  STDIN is the mechanism for passing data to a bash command or script.\n  What is the purpose of STDOUT?   CLICK FOR ANSWER  STDOUT is the repository of any standard output generated by the command or script.\n  What is the purpose of STDERR?   CLICK FOR ANSWER  STDERR is the repository of any error output generated by a command or script.\n  When running a command or script from a bash shell where is STDOUT \u0026 STDERR directed?   CLICK FOR ANSWER  By default STDOUT \u0026 STDERR are routed to the terminal that invoked the command or script.\n  How can STDOUT be redirected from a terminal window to a file?   CLICK FOR ANSWER  By using the STDOUT redirection write operator \u003e and designating a file to write the contents to.\nAdditionally, the STDOUT redirection append operator \u003e\u003e and designating a file to append the contents to.\n  How can STDOUT be redirected to the STDIN of the following command?   CLICK FOR ANSWER  By using the pipe operator |, the STDOUT generated by one command is converted into the STDIN of the following command.\n  ","description":"","tags":null,"title":"Exercises","uri":"/bash-streams-redirection-pipe/exercises/"},{"content":"Next Steps Linux follows the philosophy of everything is a file.\nA fantastic resource to learn more about Linux files and the filesystem is The Linux Documentation Project: Chapter 3. About files and the file system. This resource goes much deeper than this course on explaining the Linux File System.\nAdditionally read the man pages for both chown and chmod.\nman chown man chmod ","description":"","tags":null,"title":"Next Steps","uri":"/file-permissions/next-steps/"},{"content":"Next Steps To round out your bash scripting skills we recommend looking into bash functions and useful bash articles:\n Bash Manual  ","description":"","tags":null,"title":"Next Steps","uri":"/bash-scripting/next-steps/"},{"content":"Next Steps ","description":"","tags":null,"title":"Next Steps","uri":"/bash-streams-redirection-pipe/next-steps/"},{"content":"Pre-Course Requirements The only dependancy for this class is that you have VirtualBox installed on your machine and you are able to run Ubuntu 22.04. The configurations walkthrough will take you through the steps for both Windows and MacOS installations.\nConfigurations  Configurations Home  VirtualBox Download \u0026 Installation Ubuntu Image in VirtualBox    Schedule Day One  Morning  VirtualBox Installation Validation Linux: Introduction Bash: Introduction   Afternoon  Bash: Streams, Redirection, \u0026 Pipes Bash: File System File Permissions    Day Two  Morning  Package Manager Git   Afternoon  Userspace Applications  Wget Curl      Day Three  Morning  Userspace Applications: Continued  Grep Sed     Afternoon  Userspace Applications: Continued  Vim   Bash: Scripting    Day Four  Morning  Cron Web Servers   Afternoon  Web Servers Continued    Day Five  Morning  systemd   Afternoon  Final Project    ","description":"","tags":null,"title":"One Week Schedule","uri":"/schedule/"},{"content":"Get Organized What needs to happen for the Angular project to be deployed?\nVirtualBox  VirtualBox Image created VirtualBox First time setup completed  Machine State  git must be installed web server must be installed I’ll use caddy  Project Artifacts The artifacts are already built, I just need to install them onto the machine with git.\n use git to clone build artifacts  Web Server Configuration caddy must be configured to catch HTTP requests and respond as a file_server, and then must be reloaded.\n configure caddy reload caddy  At this point the angular project should be accessible.\nThe Script Organization # Install Dependencies (Machine State)  # Download Project Artifacts  # Configure Web Server Install Dependencies # Install Dependencies  ## Update Package Repositories sudo apt update -y  ## Install Git sudo apt install git  ## Install Caddy  ### Add Caddy Package sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo tee /etc/apt/trusted.gpg.d/caddy-stable.asc curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list  ### Update Package Repositories  sudo apt update -y  ### Install Caddy sudo apt install caddy Download Project Artifacts # Download Project Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts Configure Web Server This is a little different, we have to create a valid Caddyfile that instructs it to catch HTTP requests and serve the files in our build artifact directory. We could manually do this with vim or Visual Studio Code or something, or we could use a bash Heredoc to create a file.\n# Configure Web Server  ## Create Caddyfile ( cat \u003c\u003c'EOF' https://localhost { root * /home/student/angular-tour-of-heroes-artifacts/ file_server } EOF ) \u003e Caddyfile  ## Reload Caddy sudo caddy reload Full Script Solution #!/bin/bash  # Install Dependencies  ## Update Package Repositories sudo apt update -y  ## Install Git sudo apt install git  ## Install Caddy  ### Add Caddy Package sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo tee /etc/apt/trusted.gpg.d/caddy-stable.asc curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list  ### Update Package Repositories  sudo apt update -y  ### Install Caddy sudo apt install caddy  # Download Project Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts  # Configure Web Server  ## Create Caddyfile ( cat \u003c\u003c'EOF' https://localhost { root * /home/student/orbit-report-artifacts/ file_server } EOF ) \u003e Caddyfile  ## Reload Caddy sudo caddy reload Validation New VirtualBox Image I deleted my old virtual box images to emphasize the point that this script will do all the work of configuring the machine.\n Warning I would recommend creating a new virtual machine instead of deleting and starting fresh.\n  After deleting all virtual machines with a fresh virtual box home screen:\nFirst time VirtualBox Setup Booting the machine after inserting the virtual CD boot disk:\nStill installing:\nStill installing:\nFirst time login:\nRun Script Write and view script:\nRun script:\nCheck Browser ","description":"","tags":null,"title":"Example: Angular Initialization Script","uri":"/final-project/example-angular/"},{"content":"Setup Dependencies  Note This Spring Todo MVC application requires openjdk-11-jre to run. You should already have this on your machine. If you do not, feel free to install it with apt.\n  Deploy Artifacts (GitHub) You can find the artifacts for this project at the Spring Todo MVC artifacts GitHub repo\nInstructions Using the project dependencies and the deploy artifacts create a unit file for the Spring Todo MVC application, configure the unit to restart on failure, and to start on boot (multi-user.target).\nCreate Unit File   CLICK FOR ANSWER  sudo touch /etc/systemd/system/todo-mvc.service    [Unit] Section   CLICK FOR ANSWER  Using your editor of choice append the following text into the unit file.\n[Unit] Description=Todo MVC Application    [Service] Section   CLICK FOR ANSWER  Using your editor of choice append the following text into the unit file.\n[Service] ExecStart=/usr/bin/java -jar /home/student/spring-todo-mvc-artifact/todo-mvc.jar Restart=on-failure    [Install] Section   CLICK FOR ANSWER  Using your editor of choice append the following text into the unit file.\n[Install] WantedBy=multi-user.target    Enable the Service   CLICK FOR ANSWER  sudo systemctl enable todo-mvc.service    Start the Service   CLICK FOR ANSWER  sudo systemctl start todo-mvc.service    Hints The Spring Todo MVC application is configured to start on port 8080, make sure no other applications are using the port.\n","description":"","tags":null,"title":"Service: Spring Todo MVC","uri":"/systemd/exercises/spring-todo-mvc/"},{"content":"Install each of the following packages:\n git  sudo apt update -y sudo apt install git which git git --version   curl  sudo apt update -y sudo apt install curl which git curl --version   vim  sudo apt update -y sudo apt install vim which vim vim --version   openjdk-11-jdk  sudo apt update -y sudo apt install openjdk-11-jdk which java java --version    How to update package repository list? Solution   CLICK FOR ANSWER  sudo apt update -y This should be done before installing any new packages.\n  How to install git?   CLICK FOR ANSWER  sudo apt install git -y    How to install curl?   CLICK FOR ANSWER  sudo apt install curl -y    How to install vim?   CLICK FOR ANSWER  sudo apt install vim -y    How to install openjdk-11-jdk?   CLICK FOR ANSWER  sudo apt install openjdk-11-jdk    ","description":"","tags":null,"title":"Existing Package Repositories","uri":"/package-manager/exercises/existing-package-repositories/"},{"content":"systemd isn’t touched by the end user directly. End user’s work with systemd by using the systemctl package and by defining systemd unit files.\nsystemctl gives the end user access to information and control over all services, daemons, and unit files.\nKnowing some of the basic commands of systemctl is necessary for working with services.\nStatus  Show terse runtime status information about one or more units, followed by most recent log data from the journal.\n systemctl status nginx The status command displays the current status of a specific service.\nStart  Start (activate) one or more units specified on the command line.\n sudo systemctl start nginx The start command starts a service.\nStop  Stop (deactivate) one or more more units specified on the command line.\n sudo systemctl stop nginx The stop command stops a service.\nEnable  Enables one or more units… …Enabling simply hooks the unit into various suggested places (for example, so that the unit is automatically started on boot or when a particular kind of hardware is plugged in).\n sudo systemctl enable nginx The enable command will automatically start a service at a specific computer runtime target. For example a service may be configured to start when the computer boots.\nDisable  Disables one or more units.\n sudo systemctl disable nginx The disable command will not automatically start a service at a specific computer runtime target.\nListing Units systemctl list-units All units can be listed with the list-units command.\nIn the following articles we will explore the Caddy and NGINX unit files that were automatically created when those tools were installed on the computer.\n","description":"","tags":null,"title":"systemctl","uri":"/systemd/walkthrough/systemctl/"},{"content":"System Users and Permissions All files within a Linux system define permissions for owner, group, and others.\nThe available permissions for any given owner, group, and other users is as follows:\n Read Write Execute None  An owner, group, or other users can have any combination of the above permissions.\nThe following list shows all possible options:\n Read only Write only Execute only Read and Write Read and Execute Write and Execute Read, Write, and Execute None  Viewing Permissions in Terminal Open up a terminal and navigate to the home directory if necessary.\nView all the contents of the home directory with:\nls -l For each non hidden file found by ls -l the following is displayed:\n file type file permissions number of contained folders file owner file group file size (in bytes) file last touched date file name  Output:\nThe line with the Desktop directory can be broken down as follows:\n file type: d for directory file permissions: rwxr-xr-x number of contained files: 4 file owner: student file group: student file size (in bytes): 4096 bytes (4 kilobytes) file last touched date: Apr 20 10:00 file name: Desktop  The file permissions section defines read, write and execute permissions for each of the file owner, file group, and all other users.\nrwxr-xr-x is broken into three:\n rwx: the file owner has read, write and execute permissions r-x: the file group has read and execute permissions r-x: all other users have read and execute permissions  Bringing it together:\n drwxr-xr-x 4 student student:  Directory that allows the student user to Read, Write, and Execute, the student group to Execute and Read, and all others to Execute only.    The line with the snap directory is as follows:\n drwx------ 4 student student:  Directory that allows the student owner to Read, Write, and Execute, the student group has None permissions, and all other users have None permissions.    Alternate Users Now that you have a basic understanding of the user and file permissions structure lets take a look at a different directory with alternate users.\nUsing the ls -l command view the file permissions for all files within the root directory:\nls -l / Output:\nTake note that all folders and files located within the root directory belong to the root user and root group.\n/usr/ File Permission Breakdown drwxr-xr-x 21 root root 4096 Apr 20 10:20 tmp drwxr-xr-x:\n d: file is of the directory type rwx: root owner has read, write and execute privileges r-x: root group has read and execute privileges r-x: all other users have read and execute privileges  /lost+found/ File Permission Breakdown drwx------ 2 root root 16384 Mar 11 14:32 lost+found drwx------:\n d: file is of the directory type rwx: the root owner has read, write and execute privileges ---: the root group has no permissions ---: all other users have no permissions   Bonus You may also notice that some of the lines begin with an l. The first character on the line will always provide what type of file it is. In this particular example the l signifies a symbolic link. The other types of files you may see are as follows:\n -: regular file d: directory c: character device file b: block device file s: socket file l: symbolic link  You are not expected to fully understand any of the special file types in this course.\n  ","description":"","tags":null,"title":"User File Permissions","uri":"/file-permissions/walkthrough/user-permissions/"},{"content":"Requirements: Create a script that does the following:\n Creates a new directory called redirect-practice inside of your home directory Creates a file called redirection-name inside of the redirect-practice directory Creates a file called redirection-files inside of the redirect-practice directory Creates a file called redirection-directories inside of the redirect-practice directory Appends your name to the redirection-name file Appends the list of files inside of your home directory to the redirection-files file Appends only a list of directories inside of the redirection-directories file.    Click Here for Answer  #!/bin/bash  mkdir ~/redirect-practice  path_to_dir=~/redirect-practice  touch $path_to_dir/redirection-name  touch $path_to_dir/redirection-files  touch $path_to_dir/redirection-directories  echo \"[Your Name]\" \u003e $path_to_dir/redirection-name  ls ~/ \u003e $path_to_dir/redirection-files  ls -l ~/ | grep \"^d\" \u003e $path_to_dir/redirection-directories    ","description":"","tags":null,"title":"Redirection Practice Script","uri":"/bash-scripting/exercises/redirection-practice-script/"},{"content":"Bash Scripting A bash shell script is a file that holds a set of bash commands to be read and executed by Bash.\nBash files are commonly denoted with a .sh file extension for example: example-script.sh.\nAdditionally the first line of a Bash script commonly contains a shebang. A shebang is a line that informs the operating system of the exact shell to use when executing the script. The shebang simply points to the absolute path of the shell.\nFor example: #!/bin/bash.\n Note Any valid bash syntax can be run in a file without the .sh extension and without a shebang when the bash command is invoked. However, to run a file without explicitly invoking the bash command, the bash script file requires a shebang and must be executable.\nOnce these conditions are met the script can be invoked directly without the bash command.\n  Examples The following examples are complete bash scripts that can be executed on any machine with the bash package.\nCreate new directory/new file script The first example:\n navigates to a specific directory creates a new directory changes into the new directory creates a new file  Create a new file called create-dir-file.sh and add the following contents:\n#!/bin/bash  ## navgiate to /home/student/Desktop cd /home/student/Desktop  ## create new directory inside of /home/student/Desktop mkdir new-directory  ## navigate to new-directory inside of /Desktop cd new-directory  ## create new file inside of new-directory touch new-file Execute the script by invoking the bash package and providing the path to the newly created script as the argument:\nbash create-dir-file.sh Upon creating and executing the create-dir-file.sh script a new directory and file will be created in one fell swoop!\nLook at the contents of the /home/student/Desktop and /home/student/Desktop/new-directory directories.\nLaunchCode Employee Script The first script was pretty basic. Let’s create a more complex script that combines multiple tools we’ve learned in this class. Let’s scrape, extract, and transform some data into a more usable state.\nThe LaunchCode website provides an about page, and on the page is a listing of all current LaunchCode employees.\nIt looks similar to the following image:\nSay we want a script that will:\n make a request for the raw HTML extract the data we want with grep trim the data using sed write the output to a new file   Note The about page of the LaunchCode website is subject to change. To ensure the provided script will work we have provided the raw HTML as a part of this curriculum.\n  The file the script will be requesting is found at the link of the following attachment.\n Practice File about.html (65 KB)   By hovering over the file you can find the URL of this specific resource, in the bottom left corner of your web browser.\n Note You can add that specific resource to the wget command inside of the following script! As I was creating this walkthrough the specific link for me was http://localhost:1313/bash-scripting/walkthrough/script/_index.files/about.html\n  Create a new file called lc-employee.sh and add the following code:\ncd /home/student/Desktop  mkdir launchcode-roster  cd launchcode-roster  wget http://lctt-linux.netlify.app/bash-scripting/walkthrough/script/_index.files/about.html  cat about.html | grep '\u003cp style=\"line-height: 1.4;\"\u003e\u003cstrong\u003e.*\u003c/strong\u003e\u003cbr/\u003e.*\u003cbr/\u003e' | sed 's/^.*\u003cstrong\u003e//g' | sed 's/\u003c\\/strong\u003e\u003cbr\\/\u003e/: /g' | sed 's/\u003cbr\\/\u003e.*$//g' \u003e lc-employees.txt  cat lc-employees.txt | grep \"^John\\|Paul\" \u003e john-paul.txt   Warning The url you provide for the wget command must be correct in order for this to work properly! Make sure you copy the correct url from the about.html file! The lctt-linux.netlify.app portion of the URL has likely changed!\n  Execute the newly created script:\nbash lc-employee.sh Output:\nScript Validation Check to see if the script worked!\n Navigate to your Desktop folder to view the newly created launchcode-roster directory. cd into the launchcode-roster directory and list the contents. cat out of the contents of the john-paul.txt   Bonus Check the contents of the lc-employees.txt file! Inside should be all of the employees of LaunchCode with their titles.\n  Recap:  Bash scripting description  #!/bin/bash: shebang   Example Bash Scripts:  Script to change directories, create a new directory, add a file to new directory Script to create a list of LaunchCode Employees and also separate John and Paul from the list!    ","description":"","tags":null,"title":"Scripting","uri":"/bash-scripting/walkthrough/script/"},{"content":"STDOUT Redirection By default STDOUT goes to the terminal window of the CLI.\nBash provides a collection of STDOUT redirection operators that give the user the ability to redirect STDOUT from the terminal window to a different location.\nAs a base example consider:\nls /home/student The results of this command are placed in STDOUT and by default STDOUT is directed to the CLI terminal window like so:\nThis default behavior can be changed by using one of the STDOUT redirection operators.\nSTDOUT Redirect Write to File STDOUT can be redirected to a file with the \u003e redirection operator.\nThe syntax for the \u003e redirection operator would be [bash command] \u003e file.txt.\nGive it a try:\nls /home/student/ \u003e home-contents.txt Upon entering this command any STDOUT text will not display in the terminal window, but instead be written into the home-contents.txt file.\nOutput:\nhome-contents.txt output\"\nIt comes as no surprise that no STDOUT message was printed to the terminal window. The contents of STDOUT should have been written to the file home-contents.txt.\nPrint the contents of the working directory and print the contents of the home-contents.txt file:\nUsing the Bash STDOUT redirection write operator a new file was created and it’s contents are set to what was in STDOUT.\n Warning The Bash STDOUT redirection write operator will overwrite any contents that exist in the file provided. For example the contents of home-contents.txt would be overwritten by rerunning the command, but changing the argument of the ls command:\nls /home/student/Desktop \u003e home-contents.txt Output:\nThe contents of the file no longer contains the contents of the home directory, but instead of the Desktop directory inside of the home directory. Which in this case is empty!\n  ","description":"","tags":null,"title":"Redirect STDOUT Write File","uri":"/bash-streams-redirection-pipe/walkthrough/redirect-stdout-write-file/"},{"content":"Creating myname.txt Using the echo command and the redirection write operator \u003e, create a new file named myname.txt that contains your first name.\nSolution   CLICK FOR ANSWER  echo \"Paul\" \u003e myname.txt    Overwrite myname.txt Using the echo command and the redirection write operator \u003e, overwrite the myname.txt that contains a more informative line like firstName=[YOUR FIRST NAME].\nSolution   CLICK FOR ANSWER  echo \"firstName=Paul\" \u003e myname.txt    Appending to myname.txt using the echo command and the redirection append operator \u003e\u003e, append your last name as a new line to the myname.txt file like lastName=[YOUR LAST NAME].\nSolution   CLICK FOR ANSWER  echo \"lastName=Matthews\" \u003e\u003e myname.txt    Verification of myname.txt How can you verify that myname.txt matches the following structure? firstName=[YOUR FIRST NAME] lastName=[YOUR LAST NAME]    CLICK FOR ANSWER  By using the cat command.\ncat myname.txt Output:\nfirstName=Paul lastName=Matthews    ","description":"","tags":null,"title":"Redirection: myname.txt","uri":"/bash-streams-redirection-pipe/exercises/redirection-myname/"},{"content":"Creating File Executing vim [file-name] from the terminal will either create a new file or will open the file, if it currently exists.\nFrom the home directory enter:\nvim temp-file.txt Upon executing the command a new file named temp-file.txt will be created and the vim text editor will be opened taking over your entire terminal.\nNote the file is empty, which makes sense as the file was just created. The file name is listed at the bottom of the terminal window: \"temp-file.txt\" [New File]. This is standard behavior for creating a new file using vim.\nWhen a file is opened vim will be in Normal mode by default.\nThe next article will show how to write and quit the file.\n","description":"","tags":null,"title":"Create File","uri":"/userspace-applications/walkthrough/vim/create-file/"},{"content":"Caddy Exercises The Caddy exercises include deploying a React, Spring Boot, and .NET application using the caddy service.\nReact Exercise Spring Boot Exercise .NET Exercise  ","description":"","tags":null,"title":"Caddy Exercises","uri":"/web-server/exercises/caddy-exercises/"},{"content":"Install Build Dependencies: Clone React Build Artifacts: Clone the following repository to the home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts How do you deploy the react-tic-tac-toe project using Caddy?\n  Click Here for Answer  Ensure the caddy service is running:\nsystemctl status caddy Start the caddy service if it is inactive:\nsudo systemctl start caddy Create a Caddyfile\n You can create the Caddyfile anywhere you would like. For this exercise it was created inside of the home directory.  Add the following code to the Caddyfile\n## Default localhost port https://localhost {## Path to build directory  root * /home/student/react-tic-tac-toe-build-artifacts## file_server directive  file_server } Reload the Caddy Service:\ncaddy reload Open Localhost in the browser:\n  ","description":"","tags":null,"title":"React Exercise","uri":"/web-server/exercises/caddy-exercises/react/"},{"content":"Deploy Artifacts (GitHub) You can find the artifacts for this project at the React Tic Tac Toe Tutorial artifacts GitHub repo\nInstructions  Configure NGINX to serve the files that make up the react-tic-tac-toe-build-artifacts project  Questions \u0026 Answers What did the NGINX configuration need to contain to properly serve the artifacts?   CLICK FOR ANSWER  server {  listen 80;  server_name localhost;   location / {  root /home/student/react-tic-tac-toe-build-artifacts;  index index.html;  } }    What command was used to reload NGINX after a change was made to the configuration file?   CLICK FOR ANSWER  sudo nginx -s reload    ","description":"","tags":null,"title":"React Exercise","uri":"/web-server/exercises/nginx-exercises/react/"},{"content":"Installation sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update sudo apt install caddy Validation which caddy caddy version Upon a successful installation you should see the location of the caddy binary and the version of the installed caddy package with the preceding commands.\nFor more information and to see useful Caddy commands run the below command:\ncaddy help\nManaging the Caddy Service Caddy Start sudo systemctl start caddy Check status:\nsystemctl status caddy Curl Localhost If you scroll towards the top of the STDOUT you will find similar html formatting.\ncurl localhost Caddy Stop caddy stop curl localhost ","description":"","tags":null,"title":"Setup","uri":"/web-server/caddy/setup/"},{"content":"Installation  Note Before beginning this walkthrough please shut down Caddy with the command sudo systemctl caddy stop. Caddy is running as a service in the background on port 80 which is the same that NGINX is going to attempt to use. This will prevent any issues trying to start NGINX.\n  There are multiple ways to install NGINX. This class recommends adding the official NGINX package repository and then installing the NGINX packages with the apt CLI.\n Bonus This installation is similar to the Package Manager Adding Package \u0026 Repository article. As the information was covered adequately in that article, this article will simply provide the steps and validation of successful installation.\n  To read the installation instructions provided by NGINX look over the NGINX Ubuntu Installation Article.\nInstall Tools Used in Installation sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyring Download and Add the nginx_signing.key: curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg \u003e /dev/null Check the Contents of the nginx_signing.key: gpg --dry-run --quiet --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg Desired Output of the nginx_signing.key:\npub rsa2048 2011-08-19 [SC] [expires: 2024-06-14]  573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 uid nginx signing key \u003csigning-key@nginx.com\u003e Add NGINX Package Repository: echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] http://nginx.org/packages/ubuntu `lsb_release -cs` nginx\" | sudo tee /etc/apt/sources.list.d/nginx.list Configure Package Repository Set up repository pinning to prefer our packages over distribution-provided ones:\necho -e \"Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n\" | sudo tee /etc/apt/preferences.d/99nginx Update Package Repository List and Install nginx Package: sudo apt update sudo apt install nginx Validation which nginx nginx -version Output:\nUpon a successful installation you should see the location of the nginx binary and the version of the installed nginx package with the preceding commands.\nManaging the nginx.service NGINX automatically creates a service upon installation. The nginx.service can be controlled with the systemctl package.\nSystemctl Status systemctl status nginx Output:\nSystemctl Start sudo systemctl start nginx Validation systemctl status nginx curl localhost Systemctl Stop sudo systemctl stop nginx Validation systemctl status nginx curl localhost ","description":"","tags":null,"title":"Setup","uri":"/web-server/nginx/setup/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Web Servers --- ## Purpose Program that allows you to serve web pages to the end user ___ ### Protocols HTTP: Hypertext Transfer Protocol HTTPS: Hypertext Transfer Protocol Secure --- ## Web Servers Covered Caddy: Serve files and reverse proxy, automatic HTTPS Nginx: Serve files and reverse proxy, no automatic HTTPS Both of the above web servers can accomplish the same tasks ___ ### Use Cases This course utilizes Caddy and NGINX to server static files as web applications for the following: - React Project - Spring Boot Project - Angular Project - C# Project - Python Project Caddy - User friendly, less configuration, newer technology (released in 2015) NGINX - Many organizations still use Nginx (released in 2004) This Linux Course curriculum is currently being served with a Caddyfile --- ## Caddy Requires a Caddyfile to be configured in order to serve web applications default Caddyfile located at /etc/caddy/Caddyfile Best practice is to store your Caddyfile in the default location --- ## NGINX Requires a .conf (config) file to be configured in order to server web applications default .conf file located at /etc/nginx/conf.d/default.conf Best practice to store any custom .conf files at /etc/nginx/conf.d/         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/web-server/slides/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Userspace Applications --- ## wget GNU software package used to retreive files using HTTP, HTTPS, FTP, and FTPS ___ ### Usage with wget you can download a file from the url holding that file The download can be any format Once downloaded you are able to manipulate the file as you see fit --- ## curl tool used to craft HTTP and HTTPS requests while also displaying responses Open source software ___ ### Usage Allows the user to transfer data from within your terminal or by the use of scripts Great for testing APIs using HTTP methods GET, POST, PATCH, DELETE, and PUT requests --- ## grep tool used to search content (using words and regular expressions) ___ ### Usage Search for file names matching a specific pattern in a directory Search contents of a file for specific patterns Search web request data for lines matching specific patterns ___ ### Patterns A pattern is written as a regular expression or RegEx as you may be more familiar with This can be: a single character a word an entire phrase all of the above using the tools / syntax defined by regular expressions --- ## sed tool used to edit streams of data (substitute) ___ ### Usage search and replace add content before or after specific patterns delete lines add lines --- ## vim tool used to edit files within your terminal ___ ### Usage Allows the user to edit files within your terminal Create new files Edit existing files Read files ___ ### Why it is Useful Vim and other similar tools are useful when working inside of a remote server The reason being is that the remote server has no GUI No provided text editor that you are comfortable with ___ ### Modes Normal - mainly used for navigation Visual - making changes to selected text Insert - allows user to insert new characters or remove them You may see additional modes listed inside of this curriculum but the two modes you are expected to learn and be comfortable with are Normal and Insert modes ___ ### Vimtutor type \"vimtutor\" in your terminal and hit enter to begin a vim tutorial         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/userspace-applications/slides/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## systemd --- ## Purpose Responsible for initializing and managing daemons and services ___ ### Interacting with systemd Users interact with systemd by using the systemctl package and defining unit files systemctl provides the end user access to information and control overall services, daemons, and unit files --- ## Unit Files Unit files are used to complete a default or custom service Each systems unit files are stored in the /lib/systemd/system directory If you ever wish to modify the way any given unit functions you would edit the unit file inside of /etc/systemd/system ___ ### Unit Files Continued A common use for modifying a unit file would be to start or stop a service at a desired machine state (power on, power off, user login, user logout) One major upside to this is that if your server were to ever fail, your Unit file will restart the service on reboot         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/systemd/slides/"},{"content":"Download VirtualBox Installer Before we can install Oracle VirtualBox we need to download the installer application.\nThe direct link for the MacOS VirtualBox download can be found here. Download the linked .dmg file to your computer.\n Warning The link will start a download for the .dmg file needed to install VirtualBox on a MacOS system.\n  A .dmg file is an Apple Disk Image file. Apple commonly uses this type of file (.dmg) to store software installers.\nInstall VirtualBox To begin the VirtualBox installation we simply need to run the previously downloaded .dmg file.\nRun the .dmg file Double click the .dmg file that we downloaded from the first step in this article.\n Note If you are having trouble locating the downloaded .dmg file it is more than likely located in your downloads folder.\n  Start the Installation Once you open the .dmg file a new window will pop up on your screen. You will need to double click the VirtualBox.pkg file. This will open up the VirtualBox installer window.\nVirtualBox Installer Once the installer has started you will be prompted to allow the VirtualBox.pkg file to run. Click the Allow button.\nIntroduction After clicking the allow button you will find a brief overview of the installation process and what VirtualBox is capable of. After reading through the description click the continue button.\n Note Take note that the installer skips past the Destination Select screen. VirtualBox changed how you can specify the installation location, but left the option on the installer. This article uses the default installation location. If you are ever prompted to change, or select an installation location leave it on the default option. At the time of creating this article the installation location was hidden behind the Change Install Location... button. You can see this button in the following images. This article will not even click the button as we want the default location.\n  Security and Preferences Note At some point in time during the installation of VirtualBox your MacOS will display a pop up window with the message: System Extension Updated.\nYour MacOS is letting you know that the programs associated with Oracle America, Inc. (in this case VirtualBox) have been registered in your MacOS’ Security Preferences. In order to use the software installed you will have to confirm the access this software has to your computer. This is standard behavior for MacOS. This article will cover the work that needs to be completed in the MacOS Security Preferences settings after completing the installation of VirtualBox.\n Warning The System Extension Updated pops up at a non deterministic time in your installation process. It could pop up almost immediately, or you might not see it until one of the later screens of the installation. Whenever the System Extension Updated window pops up click the Open Security Preferences button and move the window out of the way, you will check these settings after completing the VirtualBox installation. Whenever you see the above image in your VirtualBox installation click the Open Security Preferences button and set the resulting screen to the side so you can complete VirtualBox installation.\n  Installation Type You will be using the standard installation of VirtualBox for this walkthrough. This is the default type of installation. Click the Install button.\nInstaller Credentials You might receive a notification that your installer is trying to install new software. Click on the Use Password... button and provide your credentials to continue our installation process.\nComplete Installation The installer will now run the scripts included within the VirtualBox.pkg file to complete our configured installation. This may take a few moments.\nOnce your installation has completed successfully you should see a window similar to the following image:\nFrom here you can exit the Install Oracle VM VirtualBox window.\nConfiguring MacOS Security \u0026 Privacy Before you can use the VirtualBox software we need to finish up the update necessary to grant proper access to Oracle America, Inc..\nDuring the installation process you ran into the following pop up:\nYou clicked the Open Security Preferences and put the resulting window to the side. The resulting window was called Security \u0026 Privacy and looks like the following image:\nUsing this window we will be granting VirtualBox the permissions needed to use the software.\nFrom the Security \u0026 Privacy window we will need to:\n unlock the security preferences Allow “Oracle America, Inc.” permission to our machine Restart our computer  Unlock Security Preferences To make the required changes to our Security \u0026 Privacy we will need to unlock the security preferences by clicking the padlock icon in the bottom left corner.\nUpon clicking the padlock icon you will be asked to enter your password. Please provide your credentials.\nGrant Oracle America, Inc. Permission Once you have entered your password you will see a “System software from developer “Oracle America, Inc” has been updated towards the bottom of your Security \u0026 Privacy window. Click the Allow button.\nRestart Computer For the settings to take affect you will need to restart your computer.\n Warning Do not restart your computer until you have completed the VirtualBox installation.\n  Either click Restart or Not Now depending on if you have completed the Installation steps from the previous section.\nValidation After your machine restarts you should find the VirtualBox.app within your applications folder. You can locate this by opening your finder and selecting the applications tab.\n Bonus Alternatively you can find the VirtualBox.app by hitting command + space bar (cmd + space) and typing in the program name “VirtualBox.app”.\n  Finally, when you open the VirtualBox application you should see a window similar to the following image:\nOnce you have reached this screen you have successfully downloaded, installed and configured VirtualBox to run on your MacOS.\nSummary In this article we downloaded and installed Oracle VirtualBox onto our host computers. In the next configuration article we will be using VirtualBox to create a virtual machine image of Ubuntu, which will be the Linux distribution used in this class.\nLook over the Ubuntu Configuration Article to complete the configurations necessary for this course.\n","description":"","tags":null,"title":"MacOS Installation","uri":"/configurations/virtualbox/mac-instructions/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Bash: Introduction --- ## Bash Bash is the GNU Project's shell. Bash stands for **Borne Again Shell**. Bash is a text based shell. ___ ## GNU GNU stands for **GNU is Not Unix**. A confusing, but informative recursive acronym. GNU contains many programs that are included with the Linux kernel, one of which is the default shell for Ubuntu: **Bash**. --- ## Shell A **shell** is an interface between a user and the kernel. There are two different types of shells: text based and graphical. The Ubuntu graphical windows management shell is called GNOME. The Ubuntu text based shell is called **Bash**. --- ## Terminal Emulator In order to access the Bash shell, which is text based in nature, we must open up an application that can display output and receive our Bash commands. The program that manages the input, output, window, minimize window, maximize window, close window, keyboard press events, and mouse events is called a **terminal emulator**. The Bash shell we will be using throughout this class will be presented to us in a terminal emulator. ___ ### Terminal In the version of Ubuntu we are using the terminal emulator is simply named **terminal**. In other Linux distributions the terminal emulator will likely be named something else. Terminal emulators are named such because they are emulating the text-based terminals which used to be the **only way to interface with a computer**. --- ## Bash Shell The Bash shell is extraordinarily powerful. Almost everything that can be accomplished using a Linux distribution can be completed using the Bash shell. --- ## Bash Commands Being a text based shell, Bash is expecting us to invoke various commands. These commands may include **arguments** and **options**. --- ## General Bash Command Structure `command --option(s) argument` The structure is consistent across the commands and programs we will be invoking. ___ ## Example `ls -la /home/student` The command `ls` is being invoked with the options `-l` and `-a` upon the argument `/home/student`. --- ## Bash Arguments A Bash command may require no arguments, one argument only, or many arguments. ___ ### No Argument Example `pwd` The print working directory command takes no arguments. ___ ### Default Argument Example `ls` The list contents command will automatically use the current working directory if no arguments are provided. This is known as a default argument. ___ ### One Argument Example `ls /home/student` The `ls` command has been provided a specific directory in which we want the contents of listed. Instead of using the current working directory, `ls` will use the provided directory instead. ___ ### Multiple Argument Example `rename /home/student/example.file new-name.file` Two arguments were provided to the `rename` command. The first argument is the existing file we want to modify. The second argument is the new name we want the file to have. --- ## Bash Options A Bash command may be presented with any number of options. The options may modify the command, provide additional information to the command, or change the output of the command. Options are indicated by using double hyphens (`--option-name`) or single short-hand hyphens (`-o`). ___ ### Bash Double Hyphen Option Example `ls --all` Print all contents of directory, including any hidden files or directories. ___ ### Bash Single Hyphen Option Example `ls -a` `-a` is the short-hand version of the `--all` option for the `ls` command. Not all commands have both a short and full version. You can learn about the various options by viewing the Reference Manual for a given command. ___ ### Bash Combining Options `ls -la` You can oftentimes combine multiple options together. The `-a` flag will list all files/directories including hidden ones. The `-l` option displays the output in a long format providing more information about the files and directories. The short-hand options can be combined together behind a single hyphen. --- ### Bash Shell Variables The Bash shell has various variables that contain information useful to Bash. They are indicated by the following pattern: `$VARIABLE_NAME` ___ #### `$BASH` The `$BASH` shell variable contains the absolute path to the shell this session is using. ___ #### `$HOME` The `$HOME` shell variable contains the absolute path to the home directory of the user that initiated the Bash shell. ___ #### `$PATH` The `$PATH` shell variable contains a collection of all the tools currently accessible to this current Bash Shell session. --- ## Bash Command Reference Manuals To learn more about any Bash command you read its Reference Manual. You can access the Reference Manual by entering `man command-name` in your Bash Shell. This will open up the Manual in your terminal. You can explore the provided information with the directional keys on your keyboard. You can exit the Manual by pressing the `q` key. --- ## Walkthrough Your Walkthrough will take you through some of the basic Bash commands you will be using regularly. Throughout this class we will continue to learn more about Bash as it is a key tool in most Linux distributions.         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/bash-introduction/slides/"},{"content":"Terminal Emulator To use this text-based Bash shell on our Ubuntu machines we will need to open a terminal emulator application. The terminal emulator is the graphical software that provides many features including:\n a window a window exit button minimize and maximize window buttons  The terminal emulator is also configured to:\n handle key-press events handle click events receive Bash commands display Bash Standard Output (STDOUT)  The terminal emulator we will be using in this class is simply called terminal. You can find it by clicking the Activities button in the top left corner of your Ubuntu screen.\nThen search for the program terminal.\nEither hit enter, or click the terminal application and a new terminal emulator will be launched!\n Bonus You can also open a new terminal in Ubuntu with the ctrl + alt + t keyboard shortcut!\n  ","description":"","tags":null,"title":"Terminal Emulator","uri":"/bash-introduction/walkthrough/terminal-emulator/"},{"content":"VirtualBox This configuration will walk you through the steps of downloading and installing Oracle VM VirtualBox.\nVirtualBox is a virtualization tool. It will allow you to create a virtual operating system inside of your host operating system. Using this tool we will be able to begin working with a Linux Operating System inside of your personal operating system without compromising the integrity of your current Operating System. VirtualBox will handle all the implementation details and will create a isolated sandbox environment with the guest Linux Operating System.\nDownloading First up we need to download the VirtualBox software onto our host machine.\nAt the time of writing VirtualBox 6.1 is the Oracle recommended version, however we recommend using the currently recommended version when you are downloading VirtualBox. See the following picture as an example.\nClicking the giant blue button stating Download VirtualBox 6.1 should lead you to the downloads page which has links for many common Operating Systems. The downloads page should like the following image.\nOn this page you should see multiple links that coincide with your Operating System. Upon clicking one of these links it should automatically start a download that will work for your OS.\n Note If you are using a Linux based operating system the link from the downloads page will take you to another page with various options, find the one for your specific distribution. If you are currently using a Debian based Linux distribution you should be able to just use it with the instructions in this class and don’t need to install VirtualBox, or setup an Ubuntu virtual machine. However, there will likely be slight differences between your outputs, and file locations from what is listed in this course.\n  Installation Instructions MacOS Installation Windows Installation  ","description":"","tags":null,"title":"VirtualBox","uri":"/configurations/virtualbox/"},{"content":"Cron Syntax Cron will schedule a command to be executed at a specific time. Cron expects five time parameters, and a valid command.\nThe times are correlated with:\n minute: 0-59 hour: 0-23 Day of Month: 1-31 Month of Year: 0-11 Day of Week: 1-7  After the five time parameters are provided to Cron, it expects a valid command resulting in the line:\n* * * * * echo \"Hello Cron\" \u003e\u003e ~/Desktop/hello-cron.log The above cronjob would run and append the phrase “Hello Cron” to the hello-cron.log file every minute.\n Note In the preceding example the five time parameters are each * indicating to run at every minute, hour, day of the month, month of the year, and day of the week.\nCron will execute the command echo \"Hello Cron\" \u003e\u003e ~/Desktop/hello-cron.log every minute of every hour of every day of the month of every day of the year of every day of the week.\n  Special Characters  * Asterisk: Specifies that the command will fire at every interval in a given time slot - Hyphen: Expression to designate a range of values within a given time slot / Forward Slash: Expression to allow dividing time slot into intervals , Comma: Expression to create a list within any given time slot  ","description":"","tags":null,"title":"Cron-syntax","uri":"/cron/walkthrough/cron-syntax/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Cron --- ## Purpose Tool used to execute scheduled commands at a specific minute, hour, day, month, and day of the week ___ ## Parameters Cron requires five time parameters to be considered a valid command * * * * * command to be run minute | hour | day of month | month of year | day of week --- ## Crontab Crontab is the file that will hold instructions for the cron daemon You can have as many cronjobs within the crontab as you would like ___ ### Global Crontab vs User Crontab You can find the global crontab at the following location: /etc/crontab - This crontab file is system wide When you open crontab using the crontab -e command it is user specific --- ## Cronjobs Every job within the Crontab is considered a cronjob ___ ### Use Cases Cronjob that updates your package repositories at the end of every week Cronjob that clears unwanted files from specific directories at end of a month Cronjob that reminds you of important dates The list goes on         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/cron/slides/slides/"},{"content":"In this class we will be learning about Linux. In order to use Linux we will need to install Linux on to our computers.\nIn lieu of overwriting our preferred operating systems we will be using VirtualBox to create a virtual operating system inside of our host operating system. This is possible by partitioning a portion of our hard drive to hold a full-fledged operating system, a concept known as virtualization.\nUsing our virtual operating system we will be able to learn about and use Linux without installing it as the primary operating system of our personal computer. We will also be able to remove this virtual operating system after this class is over.\nIn order to setup this virtual operating system we will need to:\n Install and configure the Oracle VirtualBox software. Download the Ubuntu Operating System Disk Image Create a new virtual machine in VirtualBox. Configure the new virtual machine to use the Ubuntu Operating System Disk Image. Start our new Ubuntu virtual machine and complete the first time Ubuntu setup.  All of these steps are covered in the following articles.\n Warning Throughout this course there will be many images of the virtual machine we are configuring. The following articles will give you specific instructions for naming your virtual machine and user. The pictures from this program assume you have followed these naming conventions. If you choose to name your virtual box, or user something other than what the articles dictate your virtual operating system will still work, but your output will look slightly different than the images in this course.\n  Configurations VirtualBox Ubuntu  ","description":"","tags":null,"title":"Configurations","uri":"/configurations/"},{"content":"For this exercise we want you to go through the process of:\n creating a new local repo creating a new remote repo adding the remote repo to the local repo adding files going through the basic git workflow  Creating a New Local Repo From your home directory create a new directory called hello-git.\nInitialize the hello-git/ directory as a local git repository.\nSolution   CLICK FOR ANSWER  cd ~ mkdir hello-git cd hello-git git init    Creating a New Remote Repo Create a new remote repo on your personal GitHub account named hello-git.\nSolution   CLICK FOR ANSWER  Create New Remote Repo Dropdown Fill Out Form \u0026 Submit From here you must click Create repository.\n  Adding Remote Repo to Local Repo   CLICK FOR ANSWER  Copy Remote Repo URI Add New Remote to Local Remote via Terminal cd ~ cd hello-git git remote add origin [copied-remote-URI]    Adding Files to Local Directory Add a file called myname.txt and add your name to the contents of the file.\n  CLICK FOR ANSWER  cd ~ cd hello-git echo \"Paul Matthews\" \u003e myname.txt    Basic Git Workflow Add the file to staging, commit the staged changes, and push the commit to the remote repo.\n  CLICK FOR ANSWER  cd ~ cd hello-git git add myname.txt git commit -m \"added myname.txt\" -m \"Contents of file contains my name.\" git push origin master After you should be able to see the changes on your remote repo.\n  ","description":"","tags":null,"title":"New Project","uri":"/git/exercises/new-project/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Git --- ## Git Review Version Control Software created by Linux Torvalds Similar to the Linux Kernel (also created by Torvalds) it is open source software ___ ## Basic Workflow Adding changes to staging Committing changes to local git repo Pushing changes from local repo to remote ___ ### Creating a Local Repo git init (within project directory) will initialize a git repository in your current directory This allows you to begin controlling \"versions\" of your project --- ## Branches Branches allow you to diverge from your master or main branch of development You are able to create a new branch in multiple ways: git branch new-branch-name git checkout -b new-branch-name --- ## Merging This course will cover two different types of merging strategies Traditional merge with git merge merging with git rebase ___ ### Traditional Merge Using the traditional merge strategy allows you to keep the original history of commits in-tact It also means that you will be working directly on your main or master branch of development ___ ### Git Rebase git rebase will reapply commits from your current branch on top of the target branch You are working with a feature branch and conflits are handled prior to merging directly into your main or master branch of development A rebase does alter the history of the feature branch         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/git/slides/"},{"content":"Prepare Before using any new tool it’s always a great idea to take a look at the provided documentation.\napt Man Page Enter man apt and look over the description.\napt --help Option Enter apt --help and look over the displayed information.\n Bonus Using the apt CLI man page and the --help option challenge yourself to use this walkthrough as a reference.\n  ","description":"","tags":null,"title":"apt CLI","uri":"/package-manager/walkthrough/apt/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Package Manager A key aspect of a Linux distribution is the **Package Manager**. A distribution's package manager is the preferred tool for managing software on the computer. --- ## Package A **Package** is software and additional metadata. The additional metadata includes: *dependencies*, *version*, *origin*, *essential* to operating system, *conflicts*, *source*, and more. The package contains the executable software and additional data for managing the software. ___ ### Under the Hood A package is a collection of compressed files that can easily be made into executable files. Many packages are configured to work directly with a package manager. However, it is possible to manually build packages to access the executable software. For Debian based (like Ubuntu) distributions you will regularly find `.deb` packages. For RedHat based (like CentOS) distributions you will regularly find `.rpm` packages. Manual packages are commonly bundled together as a `.tar` file. --- ## Package Repository All packages that are managed directly by a package manager have an associated **repository**. This is the web location in which the package files can be downloaded. Part of the Package Manager's responsibilities is in maintaining these package repository lists. For the major linux distributions there are thousands of repositories. Many of which are maintained by the linux distribution themselves. ___ ### Package Repositories in Ubuntu Checkout the list of Packages managed by Ubuntu for [Ubuntu 22.04 (jammy)](https://packages.ubuntu.com/jammy/) This is the list of official Ubuntu Packages. You can add new package repositories from parties outside of Ubuntu, which would give you access to even more packages. --- ## Common Package Managers The majority of Debian based distributions use `APT` (Advanced Package Tool). The majority of RedHat based distributions use `RPM` (RPM Package Manager). These are the predominate underlying package managers in the Linux world. However, they are low level tools used directly by the operating system. End users interface with these tools with various text-based or graphical clients. --- ## Package Manager Clients For `APT` we have the CLI's named `apt` and `apt-get` / `apt-cache`. For `RPM` there are the CLI's named `rpm` and `yum`. Most linux distributions that come with a graphical windows system also provide a graphical client to access the underlying package manager (`Ubuntu Software` in Ubuntu 22.04). We will only be using the CLI options from our Bash shell's.         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/package-manager/slides/"},{"content":"Questions \u0026 Answers What is the purpose of wget?   CLICK FOR ANSWER  To download files over a network.\n  What is the command for downloading the file found at https://www.launchcode.org/?   CLICK FOR ANSWER  wget https://www.launchcode.org/    What is the name of the file downloaded from https://www.launchcode.org/?   CLICK FOR ANSWER  index.html\n  How could you view the contents of the file downloaded from https://www.launchcode.org/?   CLICK FOR ANSWER  cat index.html    Bonus: How could you tell wget to rename the file downloaded from https://www.launchcode.org/ to launchcode-homepage.html?   CLICK FOR ANSWER  wget -O launchcode-homepage.html https://www.launchcode.org/    ","description":"","tags":null,"title":"Wget Exercises","uri":"/userspace-applications/exercises/wget/"},{"content":"Create a Hidden folder called notes and a note file  create a hidden notes directory in you home directory create a file-system-navigation.notes file in your new hidden notes directory edit the file-system-navigation.notes file with a brief description of what each of the following commands do:  pwd ls cd absolute path vs relative path ., .. and ~ shortcuts mkdir touch mv    Questions \u0026 Answers What is the command to change working directories?   CLICK FOR ANSWER  cd\n  What is an absolute path?   CLICK FOR ANSWER  An absolute path is the unique path for a specific file/directory. It always starts at root (/).\n  What is a relative path?   CLICK FOR ANSWERR  The path to a file/directory relative to the current working directory. This path always starts from the current working directory sometimes denoted as a . character.\n  What is the nano program?   CLICK FOR ANSWER  nano is a command line text editor. It allows you to edit the text content of files directly from a terminal.\n  How do you save a file in nano?   CLICK FOR ANSWER  One way to save a file in nano is to press Ctrl + O to write out the file.\n  How do you exit a file in nano?   CLICK FOR ANSWER  You exit a file in nano by pressing Ctrl + X to exit the file. If changes have been made to the file nano will ask you if you want to write changes before exiting, or to discard changes before exiting.\n  ","description":"","tags":null,"title":"Create Hidden Notes","uri":"/file-system/exercises/notes/"},{"content":"Review: Where am I? To get your bearings and view your current working directory you can use the familiar pwd command.\n Note The pwd command simply prints out the contents of the $PWD shell variable. Don’t forget you can see the contents of any shell variables with the echo command!\n  Review: What are the contents of this location? To view the contents of the current working directory you can use the familiar ls command without any arguments.\nChange Current Working Directory To change the current working directory you can use the cd builtin command.\ncd allows for one optional argument. If no argument is provided it will set the current working directory to the $HOME shell variable.\ncd works with both absolute and relative paths.\ncd relative path Starting from the home directory we could move into the Documents/ directory with the following command:\ncd Documents\nTake note from the image that our terminal emulator always tells us the current working directory. You should see ~/Documents$ directly before the character where you can enter text commands. You can also see on the previous line before the cd command had been executed the text directly before our input area is only ~$.\ncd absolute path Our current working directory is /home/student/Documents. We can return to the home directory by using an absolute path:\ncd /home/student/\nAnd we’re back to $HOME!\nThe main benefit in using an absolute path as the argument for the cd command is it will work from any location. The absolute path is an unique identifier for a directory.\nShell Shortcuts Another useful tool for changing directories is to learn some of the Bash shell shortcuts.\n ~: a shortcut for the $HOME variable .: a shortcut for the current working directory ($PWD variable) ..: a shortcut for the parent of the current working directory  Shortcut Home From a terminal change into the root directory:\ncd /\nFrom the root directory change into the home directory by using the home shortcut:\ncd ~\n Note The default argument for the cd command is the home directory. An even more efficient shortcut for changing into the home directory would be simply cd with no arguments. Try it out on your own, by changing into the root directory, and then entering cd without any arguments.\n  Shortcut to Parent From your home directory let’s change into the parent directory using the .. shortcut:\ncd ..\nUsing the parent directory shortcut we were able to move up one directory.\n Bonus You can extend the parent and current directory shortcuts. Assuming you are in /home/student/Documents you can change into /home/student/Desktop with the command: cd ../Desktop. Additionally, the parent and current directory shortcuts can be used with most bash commands.\n  ","description":"","tags":null,"title":"Review \u0026 Changing Directories","uri":"/file-system/walkthrough/review-and-changing-directories/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Bash: Filesystem --- ## The Linux Filesystem (FS) The file system is a part of the Linux kernel. In Linux **everything is a file**. That is to say directories, files, links, and a few other Linux tools are all files and are a part of the file system. Knowing the basics of the Linux FS hierarchy, Bash shell FS navigation commands, and how to perform actions on files is a fundamental aspect of using Linux. --- ## Filesystem Hierarchy The Linux FS begins with the **root (`/`) directory**. This is the top level directory that contains all other directories and files that are a part of the operating system. If you understand the general purpose of top level directories inside of the root directory, you will have a good idea where various files live. --- ## Required root Directories According to the [Linux Documentation Project](https://tldp.org/) the Linux FS is required to have the following directories inside of the root directory. - `/bin`, `/boot`, `/dev` - `/etc`, `/lib`, `/media` - `/mnt`, `/opt`, `/sbin` - `/srv`, `/tmp`, `/usr` In this class you are expected to know the purpose and use of the files in `/bin`, `/etc`, `/usr` and the often utilized `/home` directories. --- ## `/bin` Essential command binaries Contains useful commands that are used by both the system administrator and non-privileged users. Contains shells like `bash`. Contains commonly used shell commands like `cp`, `mv`, `rm`, `cat`, `ls`. The tools found in `/bin` are separate from many of the other user tools as they are crucial for servicing the operating system if other areas become corrupted. --- ## `/etc` Host-specific system configuration The container for **all** system related configuration files. These files are used to control the operation of all programs. Example files `hostname` (name of computer), `timezone` (timezone of computer), `environment` (the contents that control the `$PATH` shell variable). --- ## `/usr` User binaries, documentation, libraries, header files, etc The container for programs and files that are shared across all users of the computer. Many of the applications we will learn about in this class are found in `/usr`. Examples include `nano`, `python3`, `man`, and `which`. --- ## `/home` multi-user data and applications Linux distributions are allowed to add additional directories to the root directory. Ubuntu, and some other Linux distros add `/home`. `/home` is the location of all individual user data and applications. Some Linux distributions create the `/home` directory within the `/usr` directory. --- ## Other Root Level Directories Check the slides below for the top level description of the remaining TLDP top level directories. We will not be covering the details of these directories, however you can learn more at the [Linux Filesystem Hierarchy from TLDP](https://tldp.org/LDP/Linux-Filesystem-Hierarchy/Linux-Filesystem-Hierarchy.pdf). ___ ## `/boot` Static files of the bootloader ___ ## `/dev` Device files ___ ## `/lib` Essential shared libraries and kernel modules ___ ## `/media` Mount point for removable media ___ ## `/mnt` Mount point for mounting a filesystem temporarily. *Flash drive, or external hard drive, among others* ___ ## `/opt` Add-on application software packages ___ ## `/sbin` Essential system binaries ___ ## `/srv` Data for services provided by this system ___ ## `/tmp` Temporary files --- ## Bash File System Command Review `pwd`: print working (current) directory `ls`: list contents of current directory These two commands will help you get your bearings as you move away from your home directory. --- ## Navigating the File System Changing the working (current) directory is a common and useful action while in a Bash shell. You can change the current directory with the `cd` shell builtin command. It takes an optional argument in the form of the directory which is used to update the current working path. --- ### `cd` examples - `cd /home/student/Documents`: absolute path - `cd Documents`: relative path - `cd .Documents`: relative path - `cd ~`: the \"`~`\" key is a shortcut for `$HOME` - `cd`: default argument is `$HOME` - `cd ..`: change to parent directory --- ## Creating Directories `mkdir [new-dir-name]`: make directory `mkdir` works with both relative and absolute paths. ___ ### `mkdir` examples - `mkdir ~/new-dir`: creates a new directory in the home directory - `mkdir new-dir`: creates a new directory in the current working directory - `mkdir /home/student/Documents/new-dir`: creates a new directory using the absolute path provided --- ## Creating Empty Files - `touch new-file.txt`: create a new empty file named `new-file.txt` in the current working directory. - `nano new-file.txt`: open the file named `new-file.txt` in nano editor. ___ ### `touch` actually updates timestamps `touch` can be used to create new empty files, but it's main purpose is to update an existing file's timestamp. You can try this out by creating a new file with `touch example-file` checking the last file modified date with `ls -l` and then waiting a few minutes and then running `touch example-file` again. --- ## Displaying the Contents of a File Reading the contents of a file is always handy. In a terminal you can either take the entire contents and dump it into STDOUT with `cat`. Or you can break the output into chunks and scroll through them manually with `less`. ___ ### `cat` example `cat /etc/hostname`: display the contents of `/etc/hostname` in the terminal window. ___ ### `less` example `less /etc/hostname`: open the contents of `/etc/hostname` in chunks in an interactive terminal window. `less` works by breaking the file into smaller chunks and then displaying one chunk at a time. This way even *very* large files can be displayed as only one chunk of the file must be loaded into active memory (RAM) at a time. `less` is the default tool when using the `man` command to access a package's Manual Reference Page. --- ## Searching for Files `find [location] -name file-name` --- ## Moving Files and Directories `mv file new-location/`: will move file to `new-location/file`. ___ ### Using `mv` to rename files/directories You can use the `mv` command to rename files and directories in place, or change their name when moving to a new location. - `mv file file2`: will rename `file` to `file2` - `mv file Documents/file2`: will move and rename `file` to `Documents/file2` --- ## Deleting Files `rm [file-name]`: relative or absolute path - `rm temp-file` - `rm Documents/file2` - `rm /home/student/Documents/file2` --- ## Deleting Directories `rm` will also delete directories, but it must first delete any contents inside of the directory. You can trigger this behavior with the `-r` option. `rm -r Documents`: delete the Documents directory and all files/directories in the Documents directory. You can stop it from asking about every document by adding the `--force` option. This can cause some nasty effects if used on the wrong directory. --- ## Editing the contents of a File using Nano `nano` is a terminal text editing program. `nano filename`: will open the existing filename or create a new file and open it for content. ___ ### Saving file from Nano - `ctrl`+`o`: write file ___ ### Exiting Nano - `ctrl` + `x`: exit file, will prompt for save if changes are detected --- ## Creating aliases `alias whereami=pwd` show `whoami` make a `whereami` alias --- ## `~/.bashrc` file run for every new shell session initiated by user. This where you can add things to permanently add them to your shell. You can also add any shell customizations here. ___ ### Adding whereami alias to `~/.bashrc` `nano ~/.bashrc` scroll to bottom of file add: ```bash # My aliases: alias whereami=pwd ``` `source ~/.bashrc` --- ## `sudo` Execute a command as another user. Super (root) user is the default argument.         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/file-system/slides/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n   Fullscreen   .reveal .slides ol, .reveal .slides dl, .reveal .slides ul { display: block !important; text-align: left !important; margin: 0 !important; } .reveal .slides h1, h2 { margin-top: 0 !important; } .reveal blockquote { margin: 5% auto; width: 100% } .reveal .slides table { color: inherit; font-size: 1.5rem; width: 100%; } .reveal .slides pre { width: 100%; } a { color: white; }  ## Linux --- ## Terms - Operating System - User space applications - Kernel - GNU - Shell - Terminal - File System --- ## Operating System An operating system contains two major components a **kernel** and a collection of **user space applications**. ___ ## End User Any person using a computer is considered an end user. An end user uses a computer to achieve some goal which varies depending on their specific needs and wants. ___ ## OS Serves the End User The OS is responsible for allowing the end user to interface with a computer by handling two responsibilities: - managing the physical components of the computer (kernel) - providing interfaces to the computer that can be used by the end user (user space applications) End users **only** interact with end user applications. --- ## User Space Applications User space applications are all of the programs on a computer that the end user interacts with directly. Every action you have ever completed on a computer is considered an user space application. Creating a word document, Writing/Compiling/Executing code, watching movies, editing photos, browsing the internet, sending emails are all user space applications. Even the Graphical User Interface (GUI) you use to select your documents and applications is itself a user space application! ___ ## OS Provides the User Interface These applications have been created with people in mind to achieve a specific goal. In essence one of the primary responsibilities of an OS is to provide a collection of programs that allow interfacing with a computer easy and intuitive. ___ ## Under the Hood Additionally, under the hood the OS is also responsible for providing to a monitor, managing the mouse location, determining mouse and keyboard click events, opening programs by allocating memory (RAM), writing to the disk when files are created or modified, and managing CPU access to all running processes. All of these under the hood actions are responsibilities of the kernel. --- ## Kernel Software that manages computer operations including all of the physical hardware of a machine. ___ ## Example Consider all the actions needed to open a word document. From a user perspective we simply double click the file in our file manager or on our desktop. The computer has to determine which file was clicked based on the mouse position, find that file from hard disk storage, open the contents of the file in memory (RAM), create and send the display of the file to the monitor. All of these under the hood tasks would burden the user and are therefore handled by the kernel. --- ## Linux Kernel The Linux kernel is an *open source* and actively developed *monolithic* kernel. It was originally created by Linus Torvalds, but has since received commits from 1000s of contributors. [GitHub repo](https://github.com/torvalds/linux) [The Linux Kernel Documentation](https://www.kernel.org/doc/html/latest/) --- ## GNU GNU is a recursive acronym that stands for **G**NU is **N**ot **U**nix. GNU offers a huge collection of free software, that is commonly bundled with the Linux kernel to create a full fledged operating system. Many of the tools we will use in this class are created and maintained by GNU. [GNU Homepage](https://www.gnu.org/) [GNU Package Listing](https://www.gnu.org/software/software.html) --- ## Shell A **shell** is software that is end user interactive. It's purpose is to serve as the interface between an end user and the kernel. There are both text-based shells (Bash shell) and graphical shells (gnome-shell). --- ## Terminal A **terminal** is the graphical application that powers a text-based shell. Before graphical shells (like the Xerox Neptune Directory Editor, Windows 1, Apple Lisa \u0026 Macintosh, etc) there were only text-based shells. ___ ### Terminal Emulators Terminals which were the monitors connected to these computers only provided a text-based interface. In our modern era of computing we mostly use *terminal emulators*. They emulate what the original text-based only terminals felt like, but provide additional features, and are run as an application within a graphical shell. ___ #### Terminal Emulator Examples If you have used *git-bash*, the *bash shell*, *powershell*, or the Windows *cmd* line you have used a terminal emulator. We will be spending the majority of our time in this class using a terminal emulator displaying the *bash shell*. --- ## File System The filesystem of a computer is defined and managed by the kernel. The Linux filesystem contains a **root** directory (`/`) which holds all of the files and directories on the computer. ___ ### Root Directory Many of the subdirectories inside of the **root** directory contain configurations, data, and tools that are used directly by the operating system. The end user can see, and possibly edit or delete these files which are crucial to running the operating system. To mitigate the risk of having end users mess around with kernel level data Linux has also designated **userspace**. ___ ### Userspace **Userspace** is a term that describes the areas of the Linux filesystem that contain end user files and directories. Userspace is usually found in a couple of different locations and the location varies by Linux distribution. In Ubunutu, which is the Linux distribution we will be using, it is predominately found in the `/usr` and `/home` directories.         function initSlides() { Reveal.initialize({ controls : true, center: true ,\thistory: false , progress: true , transition: \"concave\", plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ], }); }   var toto = document.getElementById('slideContent').innerHTML document.getElementById('slideFrame').contentWindow.document.write(document.getElementById('slideContent').innerHTML); document.getElementById('slideContent').remove(); document.addEventListener(\"DOMContentLoaded\",function(){ setTimeout(function () { document.getElementById('slideFrame').contentWindow.initSlides() ; }, 2000); });  ","description":"","tags":null,"title":"Slides","uri":"/introduction/slides/"},{"content":"Correct user-data.csv The user-data.csv file we downloaded from https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv has a couple of mistakes we need to fix across the entire file.\n Typo: company mastercard should be Mastercard Typo: company spectrum should be Spectrum Company Stephens-Griffin name changed to: Stephens-Griffin-Ferguson  sed substitute ‘mastercard’ with ‘Mastercard’ Run a substitute command:\nsed 's/mastercard/Mastercard/' user-data.csv Output:\nHowever, this doesn’t alter the file it simply displays the substitution in STDOUT.\n Bonus You can see that the change didn’t take place by running grep 'mastercard' user-data.csv:\n  Write Changes Write the changes to a new file named user-data.corrected.csv. This way the original file stays unchanged.\nsed 's/mastercard/Mastercard/' user-data.csv \u003e user-data.corrected.csv Validation Since the substitution is writing to a file instead of routing to STDOUT the change is not seen automatically. There are many tools that allow you to view the file so the changes can be validated:\ngrep 'Mastercard' user-data.corrected.csv Output:\n Bonus Since you have access to both the original file and corrected file you could use git diff to view the differences between the two files:\ngit diff user-data.csv user-data.corrected.csv Output:\nYou can see the exact lines that were deleted and the lines they were replaced with. This is a less screen you can navigate with the arrow keys, j (up) and k (down) keys and type q to exit.\n  sed substitute ‘spectrum’ with ‘Spectrum’ The file needs more corrections.\nRun a substitute command \u0026 write:\nsed -i 's/spectrum/Spectrum/' user-data.corrected.csv Validation grep 'spectrum' user-data.corrected.csv We should not see any records as the instances of spectrum were replaced by Spectrum\n Bonus We leave it up to you to run grep 'Spectrum' user-data.corrected.csv or git diff user-data.csv user-data.corrected.csv to further confirm the changes.\n  sed substitute ‘Stephens-Griffin’ with ‘Stephens-Griffin-Ferguson’ Run a substitute command \u0026 write:\nsed -i 's/Stephens-Griffin/Stephens-Griffin-Ferguson/' user-data.corrected.csv Validation grep 'Stephens-Griffin-Ferguson' user-data.corrected.csv Output:\n Bonus You can run any sed scripts and edit the file in place by using the -i flag. This way you wouldn’t need to read a file and then write out the same file.\nInstead of:\nsed 's/Stephens-Griffin/Stephens-Griffin-Ferguson/' user-data.corrected.csv \u003e user-data.corrected.csv This works:\nsed -i 's/Stephens-Griffin/Stephens-Griffin-Ferguson/' user-data.corrected.csv    ","description":"","tags":null,"title":"Substitute: Correct user-data.csv","uri":"/userspace-applications/walkthrough/sed/substitute-correct-user-data/"},{"content":"Regular Expression Line Begin Anchor: ^ You can match the beginning of a line with the Regular Expression line begin anchor: ^.\nEarlier grep 'Paul' matched lines that had 'Paul' at any point in the line. If you want to match 'Paul' at the very beginning of each line you could use the line begin anchor: ^.\nMatch '^Paul' grep '^Paul' user.csv Output:\nTake note that Bianca,Paul,... is not in our matched lines.\nMatch '^Paul,' grep '^Paul,' user.csv Output:\nTake note that Paula,Richardson,... is not in our matched lines.\n Note Using the RegEx line begin anchor you have already created a pattern that is more effective than just searching for the string by itself.\n  ","description":"","tags":null,"title":"Regex: Line Begin Anchor","uri":"/userspace-applications/walkthrough/grep/regex-line-begin-anchor/"},{"content":"Name  Wget - The non-interactive network downloader.\n Purpose Download files over a network.\nYou can use it to download files over private networks like your home, school, or work network.\nYou can use it to download files over public networks like the internet.\n Note You will only be seeing examples of downloading files over the internet.\n  Usage wget [url] Using wget you can download the file using its unique URL. The downloaded file can be any format.\nSome examples:\n HTML File: .html Debian Package File: .deb Comma Separated Values: .csv Python: .py Shell: .sh Zipped Directory: .zip Archived Directory: .tar.gz Image: .png, .jpeg, .jpg etc…  Example Make a wget request for the file at https://www.launchcode.org:\nwget https://www.launchcode.org Results:\nAfter making the wget request you can see a new file was downloaded and exists in the pictured user’s home directory: index.html.\n Bonus You can explore the contents of the newly downloaded index.html with the cat command.\n  Practice Files For your convenience we have provided files for you to practice on directly with this curriculum.\n Practice Files hello.py (21 B) hello.sh (32 B) hello.txt (12 B) roster.csv (179 B)   By hovering over the files you can see the URL of the specific resource, in the bottom left corner of your web browser.\nThe url from the picture above is: localhost:1313/userspace-applications/walkthrough/wget/_index.files/hello.py\n Warning The URL has the following format: protocol://domain/path to future proof this curriculum we will simply provide the path to each of the files, you will be responsible for providing the protocol \u0026 domain. So the example picture from above would be: /userspace-applications/walkthrough/wget/_index.files/hello.py, however you would need to add the protocol, and domain before executing the command.\n  Download hello.txt Craft a wget request to download the hello.txt file:\nwget [protocol]://[domain]/userspace-applications/walkthrough/wget/_index.files/hello.txt Command output:\nValidation Check the contents of the downloaded file with cat:\ncat hello.txt Command output:\nDownload hello.sh Craft a wget request to download the hello.sh file:\nwget [protocol]://[domain]/userspace-applications/walkthrough/wget/_index.files/hello.sh Command output:\nValidation Check the contents of the downloaded file with cat:\ncat hello.sh Command output:\nThis file happens to be a bash script that you can execute with the bash command:\nbash hello.sh Command output:\nDownload hello.py Craft a wget request to download the hello.py file:\nwget [protocol]://[domain]/userspace-applications/walkthrough/wget/_index.files/hello.py` Command output:\nValidation Check the contents of the downloaded file with cat:\ncat hello.py This file happens to be a python script that you can execute with the python3 interpreter:\npython3 hello.py Command output:\nDownload roster.csv Craft a wget request to download the roster.csv file:\nwget [protocol]://[domain]/userspace-applications/walkthrough/wget/_index.files/roster.csv Command output:\nValidation Check the contents of the file with cat:\ncat roster.csv Outside Example (Imgur) Let’s find the link for a grumpy cat photo: https://imgur.com/gallery/Xl0W2iX, open dev tools, find src= of the image which is: https://i.imgur.com/Xl0W2iX.jpeg.\nLet’s request that specific file with wget.\nwget https://i.imgur.com/Xl0W2iX.jpeg Validation wget downloaded a file named Xl0W2iX.jpeg, let’s open it in Firefox and see the photo.\n Note To open a file in Firefox, first open the browser, then hit ctrl + o to open a new file, then select the file you just downloaded in your home directory: Xl0W2iX.jpeg.\n  Recap We can use the wget tool to download files from the internet.\n","description":"","tags":null,"title":"wget","uri":"/userspace-applications/walkthrough/wget/"},{"content":"Viewing Branches While inside of a git project directory git branch command is very useful.\nNavigate your terminal to the py-demo-web-logs project you cloned in the previous walkthrough.\nRun the command git branch.\nRunning the git branch command without an argument will show you the current branch you are working on and any additional local branches in your local repository (this project only has one branch in the local repository).\n Bonus If you would like to view all branches in the local and all remote repositories you can add the -a tag at the end of the branch command: git branch -a. Try it out! Notice the remote branch bug-fix-solution exists on the remote repository named origin, but is not a part of the local repository.\n  Creating a new Branch The main.py file within this project currently contains a bug. You are going to create a new branch to fix the bug and stage that change for commit.\nYou will need to:\n create a new branch view the new branch  Run the command git branch bug-fix.\nCheck that the branch has been created using the git branch command. Notice the new branch was created, but the currently checked out branch is still the master branch as indicated by the asterisk and green text.\nRecap:  View existing branches with git branch  View all branches (including remote) with git branch -a   Creating a new branch with git branch [new-branch-name]  ","description":"","tags":null,"title":"Creating Branches","uri":"/git/walkthrough/git-branching/creating-branches/"},{"content":"In this class we will be using Ubuntu Desktop 22.04 LTS, you can find its download on their website.\n Note The Ubuntu ISO that you will be using is 3.4 GB in size. You will also be allocating 12.00 GB of space onto our Virtual Machine Image. Please ensure that you have a minimum of 16 GB of free space on your host machine before moving forward with the next steps in this walkthrough.\n  Download Image Click the green Download button to start the download. It is a large file and will take some time.\nYou will likely have to confirm the download, in the picture below the user will need to click Save File for the file to be downloaded onto the host computer.\nRegardless of your host OS we will all be using a similar file ubuntu-22.04-desktop-*.iso. An .iso file is a Disk Image which is the instruction for installing an Operating System. We will be using this file inside of Virtualbox to create an isolated Ubuntu 22.04 virtual operating system inside of our host computer.\n","description":"","tags":null,"title":"Download Ubuntu Image","uri":"/configurations/ubuntu/download-ubuntu-image/"},{"content":"Setup Project repository: py-demo-web-logs-continued\n  Fork the project repository to you your personal github account.\n  Clone your forked repository onto your personal machine.\n  Code Review  Note In the example below we are cloning the github repo into the home/student/Desktop directory.\n  Run the command git clone https://github.com/[your-github-username]/py-demo-web-logs-continued in your preferred directory.\nView existing branches This repository has three existing branches:\n master new-feature new-function  Run the command git-branch-a to view all existing local and remote branches.\nTest Existing Code The master branch main.py file currently prints information to STDOUT. You can check this behavior by running the main.py file within your directory.\nRun the command python3 main.py within your py-demo-logs-continued directory.\nBranch: new-feature Paul has come up with a solution to write the information inside of main.py to a file when run instead of only printing to STDOUT.\nCheckout to the new-feature branch to test the behavior.\n run the command git checkout new-feature run the command python3 main.py run the ls command to check that a file was written to your directory run the cat command to print the contents of web.log to Stdout lastly, remove the file as we no longer need it  Branch new-function John has also come up with a solution to write the information inside of main.py to a file but has created a function and called that function to handle the work. John also added in a newline character so that a newline is always triggered after the information has been displayed.\nCheckout to the new-function branch to test the behavior.\n run the command git checkout new-function run the command python3 main.py run the ls command to check that a file was written to your directory run the cat command to print the contents of web.log to Stdout lastly, remove the file as we no longer need it  Recap  Reviewed existing code inside of master, new-feature, and new-function branches  Now that you are familiar with what code is inside of each branch you are going to need to merge all existing branches together.\nLets begin with the traditional git merge in the next walkthrough.\n","description":"","tags":null,"title":"Review Existing Code","uri":"/git/walkthrough/merging/code-review/"},{"content":"Review: Creating a Local Git Repo A common git task is to create a new directory and then initialize a git repository inside of the directory. This is likely a task you have done before, but we will be reviewing it together.\nFor this example you will create a new directory inside of your user home directory called local-repository.\n cd to your user home directory (home/student) make a folder called local-repository cd into your newly created directory  Now you will need to initialize git inside of this new directory you created with the git init command.\n Warning Make sure to cd into your newly created directory before running the git init command inside of your terminal.\n  Running the above command creates a new subdirectory named local-repository/.git/. This file holds all of the required repository files.\n Bonus After running the git init command you may notice that if you type in the ls command it does not show the .git folder inside of our directory. Remember that you can use the ls -a command to show all folders within a directory, including hidden ones.\n  Review: Creating a Remote Git Repo There are multiple ways to create a remote repository on git. The simplest way of doing so is to use GitHub. After logging in, navigate to the repositories tab and click the green New button.\nThe new repository page provides a wizard with a few options to create the new repository. The only required option is to provide the remote repository with a name. For this walkthrough you will use the name remote-repository.\n Bonus A breakdown of the remaining options:\n Description: Provide the remote repo with a description Public or Private repository: Public (anyone on the internet can access), Private (only those with proper authentication can access) Add a README file: File to provide information about the project. Add .gitignore: File that instructs the local \u0026 remote repository to ignore certain files or directories. Files will be completely ignored when performing git commands (likeadding, commiting, and pushing). Choose a license: The license for the project. We will not be covering licenses in this course. If you would like to know more please visit the Github documentation on Licensing a Repository    For this walkthrough you should only provide this repo with a name and leave the optional settings as they were defaulted.\nClick the Create repository button.\nNew Empty Repository After clicking the Create repository button you should see the following view:\nThis page provides you with instructions for using this remote repository.\nYou can:\n create a new local repository from the command line, and add this remote repository to the local repository. push an existing local repository to this empty remote repository, after adding this remote repository to your local repository. import code from another repository.  As you have already completed the steps of the first option, we will be walking through that option.\nWe already created the directory (local-repository) and initialized it as a local repository (local-repository/.git).\nWe now need to add the new remote repository to our local repository. This is how it knows where to push and pull from.\nAdding a Remote Repo to an existing Local Repo Jump back over to the directory inside the terminal where you created a local repository.\nOnce inside of the directory we can run the following command:\ngit remote add origin https://github.com/\"github-username\"/remote-repository.git\n Note The above command is adding a new remote repository by the name of “origin” to our existing local repository. You can have as many remote repositories connected to a local repo as you would like. To add another remote you would just give it a different name. For example: git remote add conclusion https://github.com/\"github-username\"/remote-repository.git. Think of the terms “origin” and “conclusion” in this example as variables. You are giving the remote repo a name for git to reference when pushing and pulling code.\n  The second command in the image above is: git remote -v. This command will show you all of the remote repositories connected to your local repository.\nYour terminal should output the following information about our remote repo:\n origin https://github.com/github-username/remote-repository.git (fetch) origin https://github.com/github-username/remote-repository.git (push)  Stage, Commit, and Push Local Changes Now that you have added you remote repository (origin) to your local repository you can begin to synchronize folders and files between the two. Lets add an example-folder with an example-file inside of it to push to our new remote.\nIn the picture above we created a new folder called example-folder and added a file to that folder called example-file. Lets add a small message inside of our example-file using nano.\ninside of your terminal run the command nano example-file.\nFeel free to write whatever message you would like. Just remember to write the file before exiting. You can do so using ctrl+O to “Write Out”. Hit the enter key to save the file name and ctrl+x to exit nano.\nNow that we have made some changes to our project directory we want to stage them for our first commit to the remote repository.\nChange back into the root folder of this project directory using the cd .. command.\nStaging Now that we are inside of the root folder we can check any changes that have been made using the git status command.\nAs you can see there are untracked files inside of our project directory. We want to stage these changes for a commit using the git add command.\nType in the command git add example-folder/ and hit the enter key. You will notice that there will not be any output after hitting enter. But if you type in git status once more you will see that there are now changes to be committed, in this case new file: example-folder/example-file.\n Bonus There are a couple of ways you can add files to staging. If you want to be specific like in the example above you type out the path of what folders or files you want to include. If you would like to add all folders and files changed into staging you can use the command git add .. This will add all untracked files into staging so that you are able to commit them all at once. This is very useful if you only have a small amount of files that were changed. However if you have a large portion of untracked files you most likely want to commit them separately so that you can be more specific with your commit messages.\n  Commit to Local Repository Now that you have changes ready to be committed you can do so with the command git commit. There are a multiple things to consider when committing code to a new project repository. So before you do so lets touch base on them.\n Meaningful Commit messages: You want your commit messages to be meaningful so that you or anyone else working on the project has a good idea of what changes were made for any given commit. Title, and Body of Commit: Ideally every commit has a title and a body explaining what changes were made to the file.  After considering the above lets make our first-commit. All commits usually have the following structure: git commit -m \"title of commit\" -m \"body message\"\nEnter the following command git commit -m \"first-commit\" -m \"added an example-folder with an example-fle containing a message\".\n Note In some instances you may want to create a commit with just a title. In this case you would simply use the git commit -m \"title\" command. We recommend providing titles, and bodies to your commits, but it is not necessary.\n  Git Log Now that you have made a commit you can check to see what the commit looks like using the git log command.\nAs you can see the log shows us that a commit was made to the master branch from a specific Author on a specific Date. Below that you can see what the title of the commit was in addition to a description of what was included.\nPush Local Changes to Remote Repo The final step is to push the changes that we staged and committed in our local repository to the remote repository. To accomplish this you must use the git push command specifying what branch you want to push the changes to.\nEnter git push origin master into your terminal.\n Note The above command is pushing changes from your local repository to the remote repository named origin onto the branch named master. In this case your remote repository doesn’t have any branches, or files. This push will create the branch master with all committed work to the remote repository.\n  You will be asked for your username and password.\nEnter your username and password for the changes to be pushed into the remote repository.\nYour remote repository should now contain the added files and changes made!\nYou can also view your commit by clicking on the 1 commit section to view all commits inside of the remote repository.\nRecap: This walkthrough was a refresher on the following:\n Creating a local repository  git init   Creating a remote repository on github Adding a remote repo to our local repo  git remote add \u003cremote-reference-name\u003e \u003cremote-repository-url\u003e   Staging, Committing, and Pushing local changes to a remote repository  git add, git commit, git push    ","description":"","tags":null,"title":"Review: Basic Git Workflow","uri":"/git/walkthrough/basic-git-workflow/"},{"content":"Get Organized What needs to happen for the React project to be deployed?\nVirtualBox  VirtualBox Image created VirtualBox First time setup completed  Machine State  git must be installed web server must be installed  Project Artifacts The artifacts are already built, they just need to be installed onto the machine with git.\n use git to clone build artifacts   Note Build artifacts for this script: https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts\n  Web Server Configuration caddy or nginx must be configured to catch HTTP requests and respond as a file_server, and then must be reloaded.\nAt this point the react project should be accessible in your browser.\nFull Script Solution   Click Here for Solution  #!/bin/bash  # Install Dependencies  ## Update Package Repositories sudo apt update -y  ## Install Git sudo apt install git  ## Install Caddy  ### Install Curl (Needed to install Caddy) sudo apt install -y curl  curl -1sLf \\  'https://dl.cloudsmith.io/public/caddy/stable/cfg/setup/bash.deb.sh' \\  | sudo bash  sudo apt update -y sudo apt install caddy  ## Cloning Build Artifacts  git clone https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts  ## Configure Web Server  ( cat \u003c\u003c'EOF' https://localhost { root * /home/student/react-tic-tac-toe-build-artifacts/ file_server } EOF ) \u003e Caddyfile  sudo mv Caddyfile /etc/caddy/Caddyfile  sudo systemctl stop caddy  sudo caddy start  ## Reload Caddy sudo caddy reload --config /etc/caddy/Caddyfile    Check Browser ","description":"","tags":null,"title":"React Initialization Script","uri":"/final-project/react-initialization-script/"},{"content":"Caddy is a production grade web server which we will use in the Web Servers chapter.\nLet’s install it now.\nhttps://caddyserver.com/docs/install#debian-ubuntu-raspbian\n caddy  sudo systemctl disable caddy sudo systemctl stop caddy    ","description":"","tags":null,"title":"Caddy Installation","uri":"/package-manager/exercises/caddy/"},{"content":"Name  chmod - change file mode bits\n Usage The chmod command allows you to change the permissions on any given file so that you can update the read, write, and execute status for the file owner, group and all other users.\nchmod [OPTION] [file-name] Chmod Numerical Expressions When changing permissions of a file with the chmod command you must understand the numerical expressions for each type. Each option has a binary representation that allows you to create a numerical value to express all of the possible selections.\n Read (r) is represented by the number 4. Write (w) is represented by the number 2. Execute (x) is represented by the number 1.  You can combine or add these numbers together to represent a combination to set explicit file permissions.\nIf you wanted to provide a file with Read and Write permissions you would assign a 6 (adding Read: 4 and Write: 2) to the owner, group, or all others.\nSee the table below for more explanation:\n   Chmod Description     7 4(r) + 2(w) + 1(x) = 7 rwx: read, write and execute   6 4(r) + 2(w) = 6 rw-: read and write   5 4(r) + 1(x) = 5 r-x: read and execute   4 4(r) r--: read only   3 2(w) + 1(x) = 3 -wx: write and execute   2 2(w) -w-: write only   1 1(x) --x: execute only   0 0 --- : none    Examples Navigate to your desktop and create a new file called chmod-example.\ntouch chmod-example Check the permissions of the newly created file:\nls -l Output:\nYou will notice the file currently has the following permissions:\n Read and Write for the student owner Read and Write for the student group Read only for all others  Pick your favorite editor and add the following code to the chmod-example file:\n#!/bin/bash  echo \"Hello chmod example!\" Write the changes to the file and exit the editor.\nRead Only Permissions Now that you have created a new file and viewed the existing permissions it is time to use chmod command to change them.\nChange the permissions of the chmod-example file so that all users only have read permissions:\nchmod 444 chmod-example Output:\nThe above command can be broken down as follows:\n chmod: the command name 4: read only for student owner 4: read only for student group 4: read only for all other users  This is confirmed when viewing the file permissions of chmod-example: -r--r--r--.\n Bonus If you were to try and edit the file again you would get a message notifying you that you are trying to edit a readonly file.\n  Write Only Permissions Change the permissions of the chmod-example file so that all users only have write permissions:\nchmod 222 chmod-example Output:\nExecute Only Permissions Change the permissions of the chmod-example file so that all users only have execute permissions:\nchmod 111 chmod-example Output:\n Note When a file is changed to have execute permissions on a Ubuntu operating system you will notice that the color of the file has been changed to green. This quality of life improvement is a part of the terminal emulator application that is hosting our CLI shell.\n  Read, Write, and Execute In order to give a file owner read, write, and execute permissions, but restrict the group and all other users to only execute you can execute the following command:\nchmod 711 chmod-example Output:\nThe above 711 chmod options provide the student user with read, write, and execute permissions while leaving the student group and all others with only execute permissions.\nExecute the file Now that the current user student has read, write, and execute permissions on the chmod-example you can execute the file directly!\n./chmod-example Recap:  chmod command  chmod [OPTIONS] file-name   Read only permissions: r-- (4) Write only permissions: -w- (2) Execute only permissions: --x (1) Read, Write, and Execute: rwx (7)  ","description":"","tags":null,"title":"Changing File Permissions","uri":"/file-permissions/walkthrough/chmod/"},{"content":"Script Requirements:  Get Dataset located at https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv  write it to a file called user-data in your home directory.   Create a new directory called technical-user-data inside of the home directory Filter the Data inside of user-data to include only lines matching Paul and write the results to a file called paul-data.csv inside of the technical-user-data directory Filter the Data inside of the paul-data.csv file to only include results with Centene as the employer and write to a new file called paul-employer-centene.csv inside of the technical-user-data directory Filter the Data inside of the paul-employer-centene.csv file to only include users with emails ending with example.net to a new file called final-paul-user-data.csv inside of the technical-user-data directory    Click Here for Answer  #!/bin/bash  curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e ~/user-data  mkdir ~/technical-user-data  cat ~/user-data | grep \"^Paul,\" \u003e ~/technical-user-data/paul-data.csv  cat ~/technical-user-data/paul-data.csv | grep \"Centene$\" \u003e ~/technical-user-data/paul-employer-centene.csv  cat ~/technical-user-data/paul-employer-centene.csv | grep \"@example\\.net\" \u003e ~/technical-user-data/final-paul-user-data.csv    ","description":"","tags":null,"title":"Scripting Grep","uri":"/bash-scripting/exercises/grep-script/"},{"content":"Creating Bash Variables Bash is able to hold values within a named variable similar to programming languages like Java, JavaScript, Python, and many more.\nNotice how bash uses the equal sign (=) as an assignment operator.\nBash Python JavaScript Java  name=\"John\"   name = \"Paul\"   let name = \"Paul\";   String name = \"John\";      Note Similar to Python, Bash will respect any type of value you assign to a variable.\n  Syntax for initializing a variable in bash:\nvariable=value_to_hold Two notes about bash variables:\n Bash variables do not support whitespace on either side of the equals or = sign. To reference a bash variable you need to use a $ in front of the variable name.  Creating a Variable Create a new file called example-variable.sh\nname=\"Paul\" echo $name Add the above code to the file.\nRun the command bash example-variable.sh\nMore Examples Create a file called multiple-variables.sh\n#!/bin/bash  ## Variable holding the string \"Ubuntu\" linux_distro=\"Ubuntu\"  ##Variable holding the number 23 number=23  ##Arraylist holding multiple strings language_list=(\"Bash\" \"Python\" \"JavaScript\" \"Java\")  echo \"Linux Distribution: \" $linux_distro echo \"Michael Jordan: \" $number echo \"Programming Langauges :\" \"${language_list[@]}\" Add the above code to the file.\nRun the command bash multiple-variables.sh\nRecap: How to create variables in Bash:\nvariable=value_to_hold  Bash variables are not type specfic Reference a bash variable with the $  ","description":"","tags":null,"title":"Variables","uri":"/bash-scripting/walkthrough/bash-variables/"},{"content":"Redirect STDOUT Append to File Bash also provides a STDOUT redirection append to file operator. In this case the contents of the existing file would not be overwritten, but instead a new line(s) would be added (append) at the end of the file.\nLet’s try this out using the echo command:\necho \"Hello, world!\" \u003e\u003e hello-from-bash.txt Output and Validation:\nSimilarly to the write redirection operator, the append operator created a new file and added the contents from STDOUT to the file.\nThe difference is the file wasn’t overwritten with the contents of STDOUT.\nThis can be tested by executing another append redirection from bash:\necho \"Good morning!\" \u003e\u003e hello-from-bash.txt Output and Validation\nThe STDOUT redirect append operator simply added the text to the contents of the file.\n","description":"","tags":null,"title":"Redirect STDOUT Append File","uri":"/bash-streams-redirection-pipe/walkthrough/redirect-stdout-append-file/"},{"content":"Saving History as myhistory.txt Using the history command and the redirection write operator \u003e, create a new file named myhistory.txt that contains the full record of your history.\nSolution   CLICK FOR ANSWER  history \u003e myhistory.txt    Verification of myhistory.txt How can you verify that myhistory.txt contains the history of your current shell?   CLICK FOR ANSWER  cat myhistory.txt Example trimmed output:\n 908 ls  909 clear  910 echo \"Paul\" \u003e myname.txt  911 ls  912 cat myname.txt  913 echo \"firstName=Paul\" \u003e myname.txt  914 cat myname.txt  915 echo \"lastName=Matthews\" \u003e\u003e myname.txt  916 cat myname.txt  917 history \u003e myhistory.txt    ","description":"","tags":null,"title":"Redirection: Saving History","uri":"/bash-streams-redirection-pipe/exercises/redirection-history/"},{"content":"Writing and Quitting  Note When entering commands like :w and :q into vim through normal mode you are technically in Command Line Mode. The only way to access Command Line Mode is through Normal mode which is what allows you to enter commands via the Command Line.\n  vim commands can be sent while in normal mode. This article will cover the write and quit commands.\nWrite Command To write a file type :w:\n Note While in command mode any typing will be displayed at the bottom of the terminal window. The above picture shows :w.\n  After typing :w simply hit enter to submit the command to vim:\nThe text at the bottom of the terminal window changed after submitting the write command.\nIt reads:\n\"temp-file.txt\" [New] 0L, 0C written This is a notification from vim saying the file was successfully written with so many lines and characters, in this case zero as no content has been added yet.\nQuit Command To exit a file enter the :q command:\nAfter executing the command your terminal window will return back to the bash shell:\nWritten File Validation Check that the file was written by looking for the file name after executing the ls command:\nCombining Commands  Bonus In vim commands can be combined.\nThe write and quit commands can be combined by typing and entering :wq.\n  ","description":"","tags":null,"title":"Normal Mode Command: Writing and Quitting","uri":"/userspace-applications/walkthrough/vim/command-write-quit/"},{"content":"Caddyfile Configuration Caddy can be configured in multiple ways. The preferred way is by creating and managing a configuration file named Caddyfile.\nView Default Config File The default Caddyfile file that comes with the initial Caddy installation can be located at /etc/caddy/Caddyfile. Take a look at the file with:\ncat /etc/caddy/Caddyfile Contents of /etc/caddy/Caddyfile\n# The Caddyfile is an easy way to configure your Caddy web server. # # Unless the file starts with a global options block, the first # uncommented line is always the address of your site. # # To use your own domain name (with automatic HTTPS), first make # sure your domain's A/AAAA DNS records are properly pointed to # this machine's public IP, then replace \":80\" below with your # domain name.  :80 {# Set this path to your site's directory. \troot * /usr/share/caddy# Enable the static file server. \tfile_server# Another common task is to set up a reverse proxy: # reverse_proxy localhost:8080 # Or serve a PHP site through php-fpm: # php_fastcgi localhost:9000 }# Refer to the Caddy docs for more information: # https://caddyserver.com/docs/caddyfile Lots of lines within this file are commented out notes. This default Caddyfile is meant to serve as an example to guide the configuration needs of the user.\nIgnoring the commented out lines the file contents are:\n:80 {  root * /usr/share/caddy  file_server } This particular configuartion file is:\n Listening on port 80 (the default HTTP port) Using the path /usr/share/caddy for the site directory Enabling the static file server with the file_server directive  This specific configuraiton is stating that all requests made to port 80 are requesting files at the directory /usr/share/caddy/. Whatever files live in that directory will be matched up with any HTTP requests that hit this web server on port 80.\n Note In the following articles you will edit and create new Caddyfiles for a static website and reverse proxy\n  ","description":"","tags":null,"title":"Caddyfile","uri":"/web-server/caddy/caddyfile/"},{"content":"Nginx Exercises The Nginx exercises include deploying a React, Spring Boot, and .NET application using the nginx.service.\nReact Exercise Spring Boot Exercise .NET Exercise  ","description":"","tags":null,"title":"Nginx Exercises","uri":"/web-server/exercises/nginx-exercises/"},{"content":"  Warning This article assumes NGINX is installed, and the nginx.service is currently running. The nginx.service can be started by entering the following command:\nsystemctl start nginx    NGINX Configuration NGINX is predominately driven by configuration files.\nTo configure NGINX to server static files, or to reverse proxy to a running web application framework NGINX requires a valid configuration file that instructs the NGINX web server on how to behave.\nNGINX configuration files end with the suffix .conf.\nViewing Default Configuration File By default a newly installed NGINX web server is configured to serve an example static HTML file.\n Note You can view the response made by making a web request to localhost in your browser, or with curl:\ncurl localhost This was covered in the previous article.\n  The configuration file responsible for this NGINX web server behavior is located at: /etc/nginx/conf.d/default.conf. Take a look at the file with:\ncat /etc/nginx/conf.d/default.conf Contents of /etc/nginx/conf.d/default.conf:\nserver {  listen 80;  server_name localhost;   #access_log /var/log/nginx/host.access.log main;   location / {  root /usr/share/nginx/html;  index index.html index.htm;  }   #error_page 404 /404.html;   # redirect server error pages to the static page /50x.html  #  error_page 500 502 503 504 /50x.html  location = /50x.html {  root /usr/share/nginx/html;  }   # proxy the PHP scripts to Apache listening on 127.0.0.1:80  #  #location ~ \\.php$ {  # proxy_pass http://127.0.0.1;  #}   # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000  #  #location ~ \\.php$ {  # root html;  # fastcgi_pass 127.0.0.1:9000;  # fastcgi_index index.php;  # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;  # include fastcgi_params;  #}   # deny access to .htaccess files, if Apache's document root  # concurs with nginx's one  #  #location ~ /\\.ht {  # deny all;  #} } There are many commented out notes in the default.conf file. NGINX provides this file with examples to guide the configuration in a way that serve the needs of the user.\nIgnoring the commented out lines the file contents are:\nserver {  listen 80;  server_name localhost;   location / {  root /usr/share/nginx/html;  index index.html index.htm;  }   error_page 500 502 503 504 /50x.html  location = /50x.html {  root /usr/share/nginx/html;  } This configuration file:\n is listening on port 80 (the default HTTP port) is named localhost any requests made to localhost:80:  will be served from the root location of /usr/share/nginx/html (on this computer’s file system) if the HTTP request is missing a file extension from the path: index.html will be added and then index.html added before returning a 400 level HTTP status code.    To NGINX this means an HTTP request made to localhost:80/ would result in an HTTP response including the file located at /user/share/nginx/html/index.html.\nAdditional configuration instructs NGINX on handling HTTP Status Codes 500, 502, 503 and 504. In the case of a 5XX level error NGINX should respond with the corresponding 50x.html file found in /usr/share/nginx/html.\n Note In the following articles you will edit the existing configuration file and add new configuration files.\n  Configuration File Location NGINX can be configured to load .conf files from many different locations. It is a best practice to store any custom .conf in the /etc/nginx/conf.d directory.\nTop Level Configuration File In addition to the user-defined configuration files there is a top level NGINX configuration file found at: /etc/nginx/nginx.conf.\nThis file contains high level configurations about NGINX itself, not for creating a new web server definition. This course will not cover the top level configuration file.\n","description":"","tags":null,"title":"nginx.conf","uri":"/web-server/nginx/conf/"},{"content":"Web Servers  Purpose Program that allows you to serve web pages to the end user\n Protocols HTTP: Hypertext Transfer Protocol\nHTTPS: Hypertext Transfer Protocol Secure\n Web Servers Covered Caddy: Serve files and reverse proxy, automatic HTTPS\nNginx: Serve files and reverse proxy, no automatic HTTPS\nBoth of the above web servers can accomplish the same tasks\n Use Cases This course utilizes Caddy and NGINX to server static files as web applications for the following:\n React Project Spring Boot Project Angular Project C# Project Python Project  Caddy - User friendly, less configuration, newer technology (released in 2015)\nNGINX - Many organizations still use Nginx (released in 2004)\nThis Linux Course curriculum is currently being served with a Caddyfile\n Caddy Requires a Caddyfile to be configured in order to serve web applications\ndefault Caddyfile located at /etc/caddy/Caddyfile\nBest practice is to store your Caddyfile in the default location\n NGINX Requires a .conf (config) file to be configured in order to server web applications\ndefault .conf file located at /etc/nginx/conf.d/default.conf\nBest practice to store any custom .conf files at /etc/nginx/conf.d/\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/web-server/slides/fullscreen/"},{"content":"Install Build Dependencies: Clone React Build Artifacts: Clone the following repository to the home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/spring-todo-mvc-artifact How do you deploy the spring-todo-mvc project using Caddy?\n  Click Here for Answer  Ensure the caddy service is running:\nsystemctl status caddy Start the caddy service if it is inactive:\nsudo systemctl start caddy Start the Spring Boot project:\njava -jar spring-todo-mvc-artifact/todo-mvc.jar Create a Caddyfile\n You can create the Caddyfile anywhere you would like. For this exercise it was created inside of the home directory.  Add the following code to the Caddyfile\n## Default localhost port https://localhost {  reverse_proxy http://localhost:8080 } Reload the Caddy Service:\ncaddy reload Open Localhost in the browser:\n  ","description":"","tags":null,"title":"Spring Boot Exercise","uri":"/web-server/exercises/caddy-exercises/spring-boot/"},{"content":"Dependencies  Note This Spring Todo MVC application requires openjdk-11-jre to run. You should already have this on your machine. If you do not feel free to install it with apt.\n  Deploy Artifacts (GitHub) You can find the artifacts for this project at the Spring Todo MVC artifacts GitHub repo\nInstructions Using the project dependencies and the deploy artifacts:\n start the application server configure NGINX to serve as a reverse proxy to the running application server  Questions \u0026 Answers How can the application server be started with the java CLI?   CLICK FOR ANSWER  java -jar /home/student/spring-todo-mvc-artifact/todo-mvc.jar    What port was the application server running on?   CLICK FOR ANSWER  8080\n  What did the NGINX configuration need to contain to serve as a reverse proxy?   CLICK FOR ANSWER  server {  listen 80;  server_name localhost;   location / {  proxy_pass http://localhost:8080;  } }    What command was used to reload NGINX after a change was made to the configuration file?   CLICK FOR ANSWER  sudo nginx -s reload    ","description":"","tags":null,"title":"Spring Boot Exercise","uri":"/web-server/exercises/nginx-exercises/spring-boot/"},{"content":"Userspace Applications  wget GNU software package used to retreive files using HTTP, HTTPS, FTP, and FTPS\n Usage with wget you can download a file from the url holding that file\nThe download can be any format\nOnce downloaded you are able to manipulate the file as you see fit\n curl tool used to craft HTTP and HTTPS requests while also displaying responses\nOpen source software\n Usage Allows the user to transfer data from within your terminal or by the use of scripts\nGreat for testing APIs using HTTP methods GET, POST, PATCH, DELETE, and PUT requests\n grep tool used to search content (using words and regular expressions)\n Usage Search for file names matching a specific pattern in a directory\nSearch contents of a file for specific patterns\nSearch web request data for lines matching specific patterns\n Patterns A pattern is written as a regular expression or RegEx as you may be more familiar with\nThis can be:\na single character\na word\nan entire phrase\nall of the above using the tools / syntax defined by regular expressions\n sed tool used to edit streams of data (substitute)\n Usage search and replace\nadd content before or after specific patterns\ndelete lines\nadd lines\n vim tool used to edit files within your terminal\n Usage Allows the user to edit files within your terminal\nCreate new files\nEdit existing files\nRead files\n Why it is Useful Vim and other similar tools are useful when working inside of a remote server\nThe reason being is that the remote server has no GUI\nNo provided text editor that you are comfortable with\n Modes Normal - mainly used for navigation\nVisual - making changes to selected text\nInsert - allows user to insert new characters or remove them\nYou may see additional modes listed inside of this curriculum but the two modes you are expected to learn and be comfortable with are Normal and Insert modes\n Vimtutor type “vimtutor” in your terminal and hit enter to begin a vim tutorial\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/userspace-applications/slides/fullscreen/"},{"content":"systemd  Purpose Responsible for initializing and managing daemons and services\n Interacting with systemd Users interact with systemd by using the systemctl package and defining unit files\nsystemctl provides the end user access to information and control overall services, daemons, and unit files\n Unit Files Unit files are used to complete a default or custom service\nEach systems unit files are stored in the /lib/systemd/system directory\nIf you ever wish to modify the way any given unit functions you would edit the unit file inside of /etc/systemd/system\n Unit Files Continued A common use for modifying a unit file would be to start or stop a service at a desired machine state (power on, power off, user login, user logout)\nOne major upside to this is that if your server were to ever fail, your Unit file will restart the service on reboot\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/systemd/slides/fullscreen/"},{"content":"Bash Command Basics This Bash shell is expecting text based commands. However, we must follow the rules for inputting the commands.\nAll Bash commands follow this basic pattern: command-name --option(s) argument(s).\n Note The previous command is non-executable and serves only as an example of command structure.\n  Most commands have at least one argument, however they can have no arguments, provide default arguments, or sometimes allow for multiple arguments.\nBash command options are similar with regards to Bash command arguments. You won’t always need an option, however they provide you with options for changing how the command will be executed, or how the output will be displayed. You may use no options, one options, or many options.\n","description":"","tags":null,"title":"Bash Command Basics","uri":"/bash-introduction/walkthrough/bash-command-basics/"},{"content":"Bash: Introduction  Bash Bash is the GNU Project’s shell.\nBash stands for Borne Again Shell.\nBash is a text based shell.\n GNU GNU stands for GNU is Not Unix. A confusing, but informative recursive acronym.\nGNU contains many programs that are included with the Linux kernel, one of which is the default shell for Ubuntu: Bash.\n Shell A shell is an interface between a user and the kernel.\nThere are two different types of shells: text based and graphical.\nThe Ubuntu graphical windows management shell is called GNOME. The Ubuntu text based shell is called Bash.\n Terminal Emulator In order to access the Bash shell, which is text based in nature, we must open up an application that can display output and receive our Bash commands.\nThe program that manages the input, output, window, minimize window, maximize window, close window, keyboard press events, and mouse events is called a terminal emulator.\nThe Bash shell we will be using throughout this class will be presented to us in a terminal emulator.\n Terminal In the version of Ubuntu we are using the terminal emulator is simply named terminal. In other Linux distributions the terminal emulator will likely be named something else.\nTerminal emulators are named such because they are emulating the text-based terminals which used to be the only way to interface with a computer.\n Bash Shell The Bash shell is extraordinarily powerful. Almost everything that can be accomplished using a Linux distribution can be completed using the Bash shell.\n Bash Commands Being a text based shell, Bash is expecting us to invoke various commands.\nThese commands may include arguments and options.\n General Bash Command Structure command --option(s) argument\nThe structure is consistent across the commands and programs we will be invoking.\n Example ls -la /home/student\nThe command ls is being invoked with the options -l and -a upon the argument /home/student.\n Bash Arguments A Bash command may require no arguments, one argument only, or many arguments.\n No Argument Example pwd\nThe print working directory command takes no arguments.\n Default Argument Example ls\nThe list contents command will automatically use the current working directory if no arguments are provided. This is known as a default argument.\n One Argument Example ls /home/student\nThe ls command has been provided a specific directory in which we want the contents of listed. Instead of using the current working directory, ls will use the provided directory instead.\n Multiple Argument Example rename /home/student/example.file new-name.file\nTwo arguments were provided to the rename command. The first argument is the existing file we want to modify. The second argument is the new name we want the file to have.\n Bash Options A Bash command may be presented with any number of options. The options may modify the command, provide additional information to the command, or change the output of the command.\nOptions are indicated by using double hyphens (--option-name) or single short-hand hyphens (-o).\n Bash Double Hyphen Option Example ls --all\nPrint all contents of directory, including any hidden files or directories.\n Bash Single Hyphen Option Example ls -a\n-a is the short-hand version of the --all option for the ls command.\nNot all commands have both a short and full version. You can learn about the various options by viewing the Reference Manual for a given command.\n Bash Combining Options ls -la\nYou can oftentimes combine multiple options together. The -a flag will list all files/directories including hidden ones.\nThe -l option displays the output in a long format providing more information about the files and directories.\nThe short-hand options can be combined together behind a single hyphen.\n Bash Shell Variables The Bash shell has various variables that contain information useful to Bash. They are indicated by the following pattern:\n$VARIABLE_NAME\n $BASH The $BASH shell variable contains the absolute path to the shell this session is using.\n $HOME The $HOME shell variable contains the absolute path to the home directory of the user that initiated the Bash shell.\n $PATH The $PATH shell variable contains a collection of all the tools currently accessible to this current Bash Shell session.\n Bash Command Reference Manuals To learn more about any Bash command you read its Reference Manual.\nYou can access the Reference Manual by entering man command-name in your Bash Shell.\nThis will open up the Manual in your terminal. You can explore the provided information with the directional keys on your keyboard. You can exit the Manual by pressing the q key.\n Walkthrough Your Walkthrough will take you through some of the basic Bash commands you will be using regularly.\nThroughout this class we will continue to learn more about Bash as it is a key tool in most Linux distributions.\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/bash-introduction/slides/fullscreen/"},{"content":"Windows Installation Instructions Windows - Download The direct link for the Windows VirtualBox download can be found here\n Warning Upon clicking the link a download will begin of the .exe file needed to install VirtualBox on a Windows system.\n  Windows - Installation Run the .exe file An executable file is a file with a predetermined set of instructions that our operating system will execute once we click it.\nDouble click the .exe file that we downloaded from the first step in this article. If you are having trouble locating the file it is more than likely located in your downloads folder.\nThis will start the installation process for VirtualBox and open up the installation wizard.\nSetup Wizard Once you have the wizard open hit the Next button.\nFile Location and Structure For File Location we will be using the default settings.\nDouble check that your settings look similar to the image below. These are the default settings for the setup wizard and you should not change them.\nAfter confirming, click the Next button.\nOptional Settings The next portion of the wizard will provide options for your installation including the following\n Create start menu entries Create a shortcut on the desktop Create a shortcut in the Quick Launch Bar Register file associations  For this configuration article we will be accepting all of the default options for the values listed above.\nAfter confirming your selections click the Next button.\n Note If you feel strongly about not including a start menu, shortcut, quick launch shortcut, or registering file associations feel free to unselect the appropriate box. However all of the articles in this course assume you left the options with their default values.\n  Network Interfaces In the following section we will install the VirtualBox Networking feature.\n Warning Once you click yes to install the VirtualBox networking feature your network connection will be lost temporarily. It goes down momentarily as it is being re-configured to allow any VirtualBox images to share access to your host OS configured network.\n  Click the Yes button to continue.\nReady to Install The setup portion of this installation process has been completed. The next step is to begin the actual installation.\nOnce you have the “Ready to Install” window open click the Install button.\nUser Account Control  Bonus After clicking the Install button you should receive a windows notification bringing up a separate User Account Control window. This will ask you to allow VirtualBox to make changes to your device. We need to select yes or the install will fail.\n  Windows Security Check After allowing VirtualBox to make changes to your device you will be prompted once more asking if you would like to install the device software.\n Note The “Windows Security” window contains an option to “Always trust software from “Oracle Corporation”. It is your decision whether or not you would like to leave it selected or unselect that option. This will not affect your installation process. For the purposes of this article we left the checkbox selected.\n  Click the Install button.\nUpon clicking the Install button your installation will run the various files and scripts to complete the installation. It will take a few moments for the installation to complete.\nFinish Installation Once your installation has complete you will have a window notification. This window will automatically open VirtualBox after clicking the Finish button.\n Note You may receive a notification that a new version of VirtualBox is available. You can just click ok to close this message.\n  Validate Installation Now that our installation is complete we can open up VirtualBox. If you are having trouble locating VirtualBox it is in your C:\\Program Files\\Oracle\\VirtualBox\\ directory.\n Note You may see a popup window about a newer version of VirtualBox that is available. Click the Ok or x window button to close the popup.   Summary In this article we downloaded and installed Oracle VirtualBox onto our host computers. In the next configuration article we will be using VirtualBox to create a virtual machine image of Ubuntu, which will be the Linux distribution used in this class.\nLook over the Ubuntu Configuration Article to complete the configurations necessary for this course.\n","description":"","tags":null,"title":"Windows Installation","uri":"/configurations/virtualbox/windows-instructions/"},{"content":"Usage A crontab is a file that holds the instructions for the cron daemon.\nEach cronjob within the crontab will run a specific command at a specific time based on the crontab configuration.\n Commands:  crontab \u003cfilename\u003e: command to run cron-jobs within a separate file as an argument crontab -e: edit current user’s crontab crontab -l: list current user’s crontab crontab -r: delete user’s crontab crontab -i: prompt before deleting user’s crontab    Open crontab View the crontab file with the follwing command:\ncrontab -e Output:\nThe default user crontab seen from the previous command will look similar to the above screenshot.\n Bonus The global crontab config file can be viewed with the following command:\nsudo vim /etc/crontab In addition to the five time parameters, and command to execute, the global crontab config file requires the user that will execute the command\n* * * * * user-name command-to-run The file was opened with vim and can be closed with :q.\n  ","description":"","tags":null,"title":"Crontab","uri":"/cron/walkthrough/crontab/"},{"content":"Name  Cron - daemon to execute scheduled commands\n Purpose Execute a command to be run at a specific time or interval.\nTime interval options:\n minute hour day-of-month month day-of-week  Setup For the distribution of Ubuntu used in this class cron comes as a preinstalled and configured package.\nValidation The location of the tools used in this chapter can be viewed with the following commands:\nwhich cron which crontab ","description":"","tags":null,"title":"Walkthrough","uri":"/cron/walkthrough/"},{"content":"This is a bonus exercise. We didn’t cover git revert, however it’s a powerful tool.\nGit revert  git-revert - Revert some existing commits\n Git revert will allow us to undo a commit.\nSay for example you accidentally deleted some important directories in your local repository, you then committed the changes, and pushed them to your remote repository.\nNow both your local and remote repositories are missing the files in the directories you deleted!\nIf only we could go back in time and undo the commit that deleted the directories.\nWe can with git revert.\nExample Repo Look at the history of the example repo to see this illustrated.\nCommits 2 and 3 introduced two new directories with very important stuff.\nCommit 4 removed the directories accidentally.\nLet’s walk through the steps to revert commit 4.\nFork Example Repo First fork the remote repo controlled by LaunchCodeTechnicalTraining to your own personal account.\n  CLICK FOR ANSWER    Clone Example Repo Clone your remote repository.\n  CLICK FOR ANSWER  cd ~ git clone [your-remote-repo] My remote repo was https://github.com/pdmxdd/revert-example. Yours should be similar, but have your username in place of pdmxdd.\n  Revert Commit 4 View Commit Log   CLICK FOR ANSWER  cd ~ cd revert-example git log The offending commit id is: e92bf70cc84ed20b5e9583865753f5cc06c34b87.\n  Revert Commit Now using the commit id revert the commit. This will create a new commit that reverts the commit in question.\n  CLICK FOR ANSWER  cd ~ cd revert-example git revert e92bf70cc84ed20b5e9583865753f5cc06c34b87 Save the default commit message that comes up and exit.\n  Check Log for New Commit The revert should have created a brand new commit that reverts the previous commit. The log should reflect this.\n  CLICK FOR ANSWER  cd ~ cd revert-example git log   Check Project Directory for Missing Directories Check the contents of the revert-example directory to see that the new directories exist again.\n  CLICK FOR ANSWER  cd ~ cd revert-example ls    Push Although we have reverted the commits on our local repo. We need to push them to update our remote repo.\n  CLICK FOR ANSWER  git push origin master    ","description":"","tags":null,"title":"Bonus: Git Revert","uri":"/git/exercises/git-revert/"},{"content":"Git  Git Review Version Control Software created by Linux Torvalds\nSimilar to the Linux Kernel (also created by Torvalds) it is open source software\n Basic Workflow Adding changes to staging\nCommitting changes to local git repo\nPushing changes from local repo to remote\n Creating a Local Repo git init (within project directory) will initialize a git repository in your current directory\nThis allows you to begin controlling “versions” of your project\n Branches Branches allow you to diverge from your master or main branch of development\nYou are able to create a new branch in multiple ways:\ngit branch new-branch-name\ngit checkout -b new-branch-name\n Merging This course will cover two different types of merging strategies\nTraditional merge with git merge\nmerging with git rebase\n Traditional Merge Using the traditional merge strategy allows you to keep the original history of commits in-tact\nIt also means that you will be working directly on your main or master branch of development\n Git Rebase git rebase will reapply commits from your current branch on top of the target branch\nYou are working with a feature branch and conflits are handled prior to merging directly into your main or master branch of development\nA rebase does alter the history of the feature branch\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/git/slides/fullscreen/"},{"content":"Reading Package Repositories We can view all of the managed package repositories with the apt CLI by using the list argument.\napt list There are so many package repositories they exceed the number of lines our terminal will render significantly.\n Bonus You can redirect the output from the apt list command directly into less by using the Bash Pipe operator (|). You would need to enter: apt list | less. This gives us the ability to manually scroll through the entire list. We will learn more about various Bash operators in a future article.\n  The Source of apt list Everything is a file in Linux. So let’s look for the source of the apt list command.\nsudo find /etc -name apt\nLet’s take a look inside the /etc/apt directory.\nls /etc/apt\nThere’s a few things here. But let’s take a look at /etc/apt/sources.list.\ncat /etc/apt/sources.list\nThe /etc/apt/sources.list file contains some important statements that are directing the APT package manager on where to find the list of packages!\n Note Many of the lines of this file are commented out with the number sign (#). Some of these are comments explaining the various sections, and some of them are alternate lines you could use instead. There’s even an interesting section that reads: Additional repositories that can be easily added by uncommenting some lines! We won’t be using any of the packages from that repository in this class, but feel free to follow the link to get an idea of the available packages.\n  User Added Repositories If you were to add repositories outside of the base Ubuntu repositories you would do so in the /etc/apt/sources.list.d directory.\n Note We will see an example of this in the Adding Additional Repositories section.\n  Ubuntu Packages Website Accessing the external documentation is always a good idea.\nTrying to wrap our head around all of the package repositories on our machine is a daunting task.\nLet’s take a look at the Ubuntu Packages Homepage.\nIt provides a list of various Ubuntu versions, we are using 22.04 the canonical name is jammy.\n Bonus If you have forgotten your version of Ubuntu there are many ways to figure it out from your computer. There is a lsb_release command that displays distribution specific information. Try running lsb_release -a from your Bash shell:   Upon looking at the webpage for the jammy repositories we can see they are organized by easier to digest sections.\n","description":"","tags":null,"title":"Reading Package Repositories","uri":"/package-manager/walkthrough/read-packages-repositories/"},{"content":"Package Manager A key aspect of a Linux distribution is the Package Manager.\nA distribution’s package manager is the preferred tool for managing software on the computer.\n Package A Package is software and additional metadata.\nThe additional metadata includes: dependencies, version, origin, essential to operating system, conflicts, source, and more.\nThe package contains the executable software and additional data for managing the software.\n Under the Hood A package is a collection of compressed files that can easily be made into executable files. Many packages are configured to work directly with a package manager. However, it is possible to manually build packages to access the executable software.\nFor Debian based (like Ubuntu) distributions you will regularly find .deb packages.\nFor RedHat based (like CentOS) distributions you will regularly find .rpm packages.\nManual packages are commonly bundled together as a .tar file.\n Package Repository All packages that are managed directly by a package manager have an associated repository. This is the web location in which the package files can be downloaded.\nPart of the Package Manager’s responsibilities is in maintaining these package repository lists.\nFor the major linux distributions there are thousands of repositories. Many of which are maintained by the linux distribution themselves.\n Package Repositories in Ubuntu Checkout the list of Packages managed by Ubuntu for Ubuntu 22.04 (jammy)\nThis is the list of official Ubuntu Packages. You can add new package repositories from parties outside of Ubuntu, which would give you access to even more packages.\n Common Package Managers The majority of Debian based distributions use APT (Advanced Package Tool).\nThe majority of RedHat based distributions use RPM (RPM Package Manager).\nThese are the predominate underlying package managers in the Linux world. However, they are low level tools used directly by the operating system. End users interface with these tools with various text-based or graphical clients.\n Package Manager Clients For APT we have the CLI’s named apt and apt-get / apt-cache.\nFor RPM there are the CLI’s named rpm and yum.\nMost linux distributions that come with a graphical windows system also provide a graphical client to access the underlying package manager (Ubuntu Software in Ubuntu 22.04).\nWe will only be using the CLI options from our Bash shell’s.\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/package-manager/slides/fullscreen/"},{"content":"Questions \u0026 Answers What is the purpose of curl?   CLICK FOR ANSWER  To craft HTTP(s) requests and receive HTTP(s) responses allowing you to transfer data from or to a server.\n  How do you make a GET request to www.google.com?   CLICK FOR ANSWER  curl www.google.com    How do you change the HTTP request method using curl?   CLICK FOR ANSWER  With the -X option.\nGet curl -X GET [URL] Post curl -X POST [URL] Put curl -X PUT [URL] Patch curl -X PATCH [URL] Delete curl -X DELETE [URL]    How do you include a request header with curl?   CLICK FOR ANSWER  With the -H option.\nAdding a Content-Type: application/json header curl -X POST [URL] -H 'Content-Type:application/json'    How do you include a request body with curl?   CLICK FOR ANSWER  With the -d option.\nAdding a JSON request body curl -X POST [URL] -d '{\"animalType\": \"dog\", \"name\": \"Bernie\", \"age\": 6}'    ","description":"","tags":null,"title":"Curl Exercises","uri":"/userspace-applications/exercises/curl/"},{"content":"Walkthrough  wget (GNU) curl (cURL community) grep (GNU) sed (GNU) vim: light basics (command mode, insert mode, directional navigation, exiting file from command mode, saving from command mode, searching for words in command mode) awk mail-utils (GNU) systemctl (systemd Red Hat) journalctl (systemd Red Hat)  will also learn\n git (Linus Torvalds and git community)  have already learned\n  find (GNU)\n  cat (GNU)\n  less (GNU)\n  way more link back\n  Userspace applications\n where do they come from?  GNU other sources (many of which are open source)      Content Links wget curl grep sed vim  ","description":"","tags":null,"title":"Walkthrough","uri":"/userspace-applications/walkthrough/"},{"content":"Create a new Bash Alias  add a new bash alias called allhomecontents which shows all files (including hidden files) to your ~/.bashrc profile  source the new file run the new alias    Questions \u0026 Answers What is a Bash Alias?   CLICK FOR ANSWER  A Bash Alias is a command shortcut. It allows you to create a new command name that will run whatever command or collection of commands you want.\n  When you invoke the allhomecontents alias what command is being run?   CLICK FOR ANSWER  ls\n  For the previous answer did you include any options to be run with that command?   CLICK FOR ANSWER  Yes. The -a option so all files, including hidden files, would be displayed.\n  ","description":"","tags":null,"title":"Bash Alias","uri":"/file-system/exercises/bash-alias/"},{"content":"Creation Commands In your learning journey you have very likely heard the acronym CRUD. Which stands for:\n Create Read Update Delete  This is the collection of actions you can perform on any given record, object, or in the case of Linux: files/directories.\nIn the following sections we will be learning about, and practicing, some commands that can be used to perform CRUD actions on files and directories from our Bash shell.\nCreate Directory You can create a new directory with the mkdir command. Let’s use it to create a new directory named temp in our home directory. With your current working directory as your home directory enter:\nmkdir temp\nWhen mkdir runs successfully there is no standard output (STDOUT) displayed to the user. To see the new directory you can run the ls command to see the contents that were created in the current working directory.\n Note You can use absolute or relative paths with the mkdir command.\n  Create File You can create a new empty file with the touch command. In our home directory let’s create a new file called temp.file.\ntouch temp.file\nAgain, a successful touch command will provide no message to standard output (STDOUT). To see the new temp.file you will need to run the ls command as shown in the picture.\nCreating Hidden Files/Directories A hidden file or directory is denoted by the name starting with a period (.). We can create hidden files and directories using the exact command above, but adding the period (.) to the file name.\nHidden Directory From your home directory create a new hidden-directory:\nmkdir .hidden-directory\nTo see this new hidden directory we will need to run the ls command with the the -a option so all files are displayed.\nYou may have to look for it, but you should find the new .hidden-directory that resulted from the execution of the mkdir command.\nHidden File Let’s change into the new .hidden-directory.\nNow create a new hidden file named .hidden.file.\ntouch .hidden.file\nTo see the hidden file you will again need to run:\nls -a\n","description":"","tags":null,"title":"Creation Commands","uri":"/file-system/walkthrough/creation-commands/"},{"content":"Bash: Filesystem  The Linux Filesystem (FS) The file system is a part of the Linux kernel.\nIn Linux everything is a file. That is to say directories, files, links, and a few other Linux tools are all files and are a part of the file system.\nKnowing the basics of the Linux FS hierarchy, Bash shell FS navigation commands, and how to perform actions on files is a fundamental aspect of using Linux.\n Filesystem Hierarchy The Linux FS begins with the root (/) directory. This is the top level directory that contains all other directories and files that are a part of the operating system.\nIf you understand the general purpose of top level directories inside of the root directory, you will have a good idea where various files live.\n Required root Directories According to the Linux Documentation Project the Linux FS is required to have the following directories inside of the root directory.\n /bin, /boot, /dev /etc, /lib, /media /mnt, /opt, /sbin /srv, /tmp, /usr  In this class you are expected to know the purpose and use of the files in /bin, /etc, /usr and the often utilized /home directories.\n /bin Essential command binaries Contains useful commands that are used by both the system administrator and non-privileged users.\nContains shells like bash. Contains commonly used shell commands like cp, mv, rm, cat, ls.\nThe tools found in /bin are separate from many of the other user tools as they are crucial for servicing the operating system if other areas become corrupted.\n /etc Host-specific system configuration The container for all system related configuration files. These files are used to control the operation of all programs.\nExample files hostname (name of computer), timezone (timezone of computer), environment (the contents that control the $PATH shell variable).\n /usr User binaries, documentation, libraries, header files, etc The container for programs and files that are shared across all users of the computer.\nMany of the applications we will learn about in this class are found in /usr.\nExamples include nano, python3, man, and which.\n /home multi-user data and applications Linux distributions are allowed to add additional directories to the root directory. Ubuntu, and some other Linux distros add /home.\n/home is the location of all individual user data and applications.\nSome Linux distributions create the /home directory within the /usr directory.\n Other Root Level Directories Check the slides below for the top level description of the remaining TLDP top level directories.\nWe will not be covering the details of these directories, however you can learn more at the Linux Filesystem Hierarchy from TLDP.\n /boot Static files of the bootloader\n /dev Device files\n /lib Essential shared libraries and kernel modules\n /media Mount point for removable media\n /mnt Mount point for mounting a filesystem temporarily.\nFlash drive, or external hard drive, among others\n /opt Add-on application software packages\n /sbin Essential system binaries\n /srv Data for services provided by this system\n /tmp Temporary files\n Bash File System Command Review pwd: print working (current) directory\nls: list contents of current directory\nThese two commands will help you get your bearings as you move away from your home directory.\n Navigating the File System Changing the working (current) directory is a common and useful action while in a Bash shell.\nYou can change the current directory with the cd shell builtin command.\nIt takes an optional argument in the form of the directory which is used to update the current working path.\n cd examples  cd /home/student/Documents: absolute path cd Documents: relative path cd .Documents: relative path cd ~: the “~” key is a shortcut for $HOME cd: default argument is $HOME cd ..: change to parent directory   Creating Directories mkdir [new-dir-name]: make directory\nmkdir works with both relative and absolute paths.\n mkdir examples   mkdir ~/new-dir: creates a new directory in the home directory\n  mkdir new-dir: creates a new directory in the current working directory\n  mkdir /home/student/Documents/new-dir: creates a new directory using the absolute path provided\n   Creating Empty Files  touch new-file.txt: create a new empty file named new-file.txt in the current working directory. nano new-file.txt: open the file named new-file.txt in nano editor.   touch actually updates timestamps touch can be used to create new empty files, but it’s main purpose is to update an existing file’s timestamp.\nYou can try this out by creating a new file with touch example-file checking the last file modified date with ls -l and then waiting a few minutes and then running touch example-file again.\n Displaying the Contents of a File Reading the contents of a file is always handy. In a terminal you can either take the entire contents and dump it into STDOUT with cat.\nOr you can break the output into chunks and scroll through them manually with less.\n cat example cat /etc/hostname: display the contents of /etc/hostname in the terminal window.\n less example less /etc/hostname: open the contents of /etc/hostname in chunks in an interactive terminal window.\nless works by breaking the file into smaller chunks and then displaying one chunk at a time. This way even very large files can be displayed as only one chunk of the file must be loaded into active memory (RAM) at a time.\nless is the default tool when using the man command to access a package’s Manual Reference Page.\n Searching for Files find [location] -name file-name\n Moving Files and Directories mv file new-location/: will move file to new-location/file.\n Using mv to rename files/directories You can use the mv command to rename files and directories in place, or change their name when moving to a new location.\n mv file file2: will rename file to file2 mv file Documents/file2: will move and rename file to Documents/file2   Deleting Files rm [file-name]: relative or absolute path\n rm temp-file rm Documents/file2 rm /home/student/Documents/file2   Deleting Directories rm will also delete directories, but it must first delete any contents inside of the directory.\nYou can trigger this behavior with the -r option.\nrm -r Documents: delete the Documents directory and all files/directories in the Documents directory.\nYou can stop it from asking about every document by adding the --force option. This can cause some nasty effects if used on the wrong directory.\n Editing the contents of a File using Nano nano is a terminal text editing program.\nnano filename: will open the existing filename or create a new file and open it for content.\n Saving file from Nano  ctrl+o: write file   Exiting Nano  ctrl + x: exit file, will prompt for save if changes are detected   Creating aliases alias whereami=pwd\nshow whoami make a whereami alias\n ~/.bashrc file run for every new shell session initiated by user.\nThis where you can add things to permanently add them to your shell.\nYou can also add any shell customizations here.\n Adding whereami alias to ~/.bashrc nano ~/.bashrc\nscroll to bottom of file\nadd:\n# My aliases: alias whereami=pwd source ~/.bashrc\n sudo Execute a command as another user.\nSuper (root) user is the default argument.\n","description":"","tags":null,"title":"Slides: Fullscreen","uri":"/file-system/slides/fullscreen/"},{"content":"  Note The slides found at this location are meant to be used in personal reference. If you are reading these slides for the first time, or are presenting these slides we recommended using the Fullscreen option found below.\n  Linux Welcome! This course will be exploring Linux. The course will cover many key elements of Linux, some of the problems you can solve using this tool, and most importantly you will be getting hands on practice with this very commonly used tool.\nBrief History Linux started as a passion project by Linus Torvalds. He was a fan of the open source operating system Minix and modeled aspects of his new kernel after Minix.\nA kernel is the fundamental aspect of an Operating System. The kernel interfaces with hardware, manages memory, devices, and contains a File System. In essence all actions performed by a computer are handled by the kernel.\nLinux is now and has always been a kernel not a full operating system. In order to be an operating system that could be effectively used by people Linus packaged his Linux kernel with Bash (a shell) and GCC (a C compiler). Still to this day the Linux kernel comes bundled together with various tools to make a variety of custom built operating systems commonly called Linux distributions.\n Note One of the first Linux distributions was Debian GNU/Linux. It contained the Linux kernel and many different GNU tools like Bash and GCC. The GNU/Linux distinction is important as it emphasizes the GNU tools that are used in combination with the Linux kernel. However, throughout this course we will simply refer to the combination of tools that makeup the various GNU/Linux operating systems as Linux.\n  The popularity of Linux grew steadily over the years as more tools were developed for or implemented to run using the Linux kernel. The open source nature of the Linux Kernel and GNU projects allowed for highly customized and varied Linux distributions.\nSome of the ways these Linux distributions are used:\n personal use operating system (like MacOS or Windows) mobile devices (Android) embedded systems (like car computers, or single board computers) Cloud Computing: Linux distributions dominate the various cloud services that power the internet  Linux’s popularity especially as it pertains to the web and cloud computing makes it an attractive tool to learn about as you continue your journey in technology.\nThis course is not designed to dive deeply into the kernel. The majority of time will be spent focusing on how this tool can be used to build solutions in the tech industry. You will learn how to install and configure various web servers, providing you with the knowledge needed to bring your web applications to the internet.\nMajor Concepts \u0026 Key Terminology  Linux GNU Kernel Shell Terminal FileSystem  Content Links  ","description":"","tags":null,"title":"Introduction","uri":"/introduction/"},{"content":"Regular Expression Line End Anchor: $ You can match the end of a line with the Regular Expression line end anchor $.\nIn the case of this specific data-set company names come at the end of each line.\nMatch 's$' Let’s match all lines that end with the letter s:\ngrep 's$' user.csv Output:\nAny line that ends with the letter s has been matched, in the case of this dataset Express Scripts and Edward Jones both match our provided pattern.\nMatch 'Accenture$' Since the last entry in each record is a company name let’s match all records that have Accenture as the company:\ngrep 'Accenture$' user.csv Every line that ends with Accenture is a part of the output from this grep command.\n Note This is another simple RegEx concept and syntax you can use to create better matching patterns.\n  ","description":"","tags":null,"title":"Regex: Line End Anchor","uri":"/userspace-applications/walkthrough/grep/regex-line-end-anchor/"},{"content":"Name  curl - transfer a URL\n Purpose To craft HTTP(s) requests and receive HTTP(s) responses allowing transference of data to or from a server.\nUsage curl [url] Make and receive web requests.\n Bonus Outside of making general web requests curl is great for debugging and troubleshooting web application servers and APIs.\n  Example Make a curl request to google.com receiving an HTML object as a response.\ncurl www.google.com Result:  Bonus If a GET request is sent to “google.com” a notification about the document being moved will be received. Running the request again with the -L option would instruct curl to follow the redirect to the new location.\n  The default HTTP method argument in curl is HTTP GET request. To send other types of requests curl requires the type of HTTP request method to be provided by adding the -X [HTTP METHOD] option.\ncurl Options:  -H or --header: Specifies an extra header to include in any HTTP request being sent to a server. You can specify any amount of extra headers. -X [HTTP METHOD] or --request [HTTP METHOD]: specify what type of HTTP request you want to send to the server. -s or --silent: Silent mode. When added to a curl request you will not see a progress meter or any error messages. -d or data \u003cdata\u003e: Sends specific data in a POST request to the HTTP server.  Setup This article utilizes the Java Spring Rest API.\n Warning This project includes a .jar file which requires the openjdk-11-jre package to be executed. The openjdk-11-jre package was installed as one of the exercises in the package manager chapter.\nIf you are missing this package you can install it with:\nsudo apt update -y sudo apt install openjdk-11-jre Validation:\n  Clone Project Repository Clone the project repository to your home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/spring-todo-api-jar Validation Look at the home directory contents for the newly created spring-todo-api-jar/ directory:\nls Output:\nRun the Application We will be using Java Runtime Environment (openjdk-11-jre) to run the included .jar file.\nChange to the project directory and run the application with:\njava -jar todo-api.jar Output:\nThe command executed the .jar file which started the Tomcat development server of the project. It will stay attached to this terminal window until we are done with this article.\n Note You can stop the Tomcat development server with ctrl+c.\nNotice the terminal is back under the command of the user as displayed by the last line:\nstudent@student-VirtualBox:~/spring-todo-api-jar    Activity  Warning The Tomcat server will need to be running through the entire curl activity. The output seen will be different if the Tomcat server is not running. Verify the spring-todo-api .jar file is running by going through the Setup steps of this article.\n  To practice curl we will be sending requests to the spring-todo-api. It is a RESTful API that accepts HTTP GET, POST, PATCH, and DELETE requests.\nThe spring-todo-api allows the following requests:\n GET /todos: request a JSON list of all existing todo items POST /todos \u0026 JSON Request Body of a new Todo Item: create a new todo item PATCH /todos/{id}: changed the completed status of a todo item to true of the path variable {id} DELETE /todos/{id}: delete the todo item of path variable {id}  Make a GET request with JSON attached Making a GET request to the spring-todo-api will result in a list of all of the recorded todo items. As the project has just started we expect to see an empty JSON list: [].\ncurl localhost:8080/todos -H Content-Type:application/json Output:\n[] is the expected output for this first request.\nMake a POST request with JSON attached Making a POST request to the spring-todo-api and including a JSON representation of a new todo item should save the item in the todo list.\nAs this is a POST request the -X POST option will need to be provided.\nAlso a JSON representation of a new todo item will need to be sent in as the request body as indicated by the -d option followed by a JSON string representation of a new todo item.\ncurl -X POST localhost:8080/todos -H Content-Type:application/json -d '{\"text\":\"the first task\"}' Output:\nThe spring-todo-api is configured to return a JSON response of the newly created todo item, in this case:\n{\"id\": 1, \"text\": \"the first todo\", \"completed\": false}   Bonus At this point as many todo items could be created by executing additional POST requests with valid JSON bodies.\n  Make a PATCH request with JSON attached Making a PATCH request requires a path variable of an existing todo item id. The API changes the completed parameter of the specific todo item (as identified by the id) to true.\nIn this case execute a PATCH request to first todo item created that has the id of 1:\ncurl -X PATCH localhost:8080/todos/1 -H 'Content-Type:application/json' Output:\nThe spring-todo-api responded with the JSON representation of the newly updated todo item:\n{\"id\": 1, \"text\": \"the first todo\", \"completed\": true} The \"completed\" property of the todo item was set to true from the original value of false.\n Note Any existing todo item can have it’s completed set to true by sending a PATCH request and the id of the todo item to change. This is accomplished by replacing the {id} portion of the above curl request which is represented with a “1” with a different existing todo id.\n  Validation: You have created a new todo through a POST request and made a minor update with a PATCH request. Check your changes with another GET request:\ncurl localhost:8080/todos The GET requests returns a list of all todo items that currently exist. In this case one completed item exists.\nMake a DELETE request Making a DELETE request requires a valid todo item id, but is otherwise similar to the PATCH request.\nDelete the existing todo item that we recently marked as complete:\ncurl -X DELETE localhost:8080/todos/1 The spring-todo-api does not return a JSON body as the the item was deleted. However, a new GET request will\nOutput:\n Note Additional todo items would be deleted by any DELETE requests that contain valid todo item ids.\n  Recap:  curl: tool to transfer data to or from a server. curl options:  -H or --headers: Specify headers for request -X or --request: Specify what type of request you want to make -s or --silent: Hide progress and error messages -d or --data: Data included in POST request   Send HTTP requests to an existing REST API  GET: Retrieve data from desired resource POST: Submit data to desired resource PATCH: Replace data of a desired resource DELETE: Delete target resource    ","description":"","tags":null,"title":"curl","uri":"/userspace-applications/walkthrough/curl/"},{"content":"Before viewing the NGINX unit file you need to know where the unit file lives.\nChecking Status Check the status of the NGINX service:\nsystemctl status nginx The output contains all of the status information about the service. The location of the unit file is recorded as a part of the status command:\nLoaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset:\u003e The unit file that defines the nginx.service can be viewed at: /lib/systemd/system/nginx.service.\nPrint the contents of the file to STDOUT with cat:\ncat /lib/systemd/system/nginx.service Output:\n[Unit] Description=nginx - high performance web server Documentation=https://nginx.org/en/docs After=network-online.target remote-fs.target nss-lookup.target Wants=network-online.target  [Service] Type=forking PIDFile=/var/run/nginx.pid ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf ExecReload=/bin/sh -c \"/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)\" ExecStop=/bin/sh -c \"/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)\"  [Install] WantedBy=multi-user.target This course will not cover systemd in great depth.\nWhat it will cover is understanding how:\n a unit is defined to start and stop a service to configure a service to start automatically on boot to configure a service to restart itself when it fails.  [Unit] The unit is defined by the [Unit] section of the unit file.\n[Unit] Description=nginx - high performance web server Documentation=https://nginx.org/en/docs After=network-online.target remote-fs.target nss-lookup.target Wants=network-online.target This section contains metadata about the unit like it’s description, and where the documentation can be found.\n Bonus The [Unit] section also defines the relationship between this and any other units. This goes beyond the scope of this class. This explains why the After= and Want= directives are found in the [Unit] section of the NGINX unit file.\n  [Service] The [Service] section of the unit file provides configuration information to the service associated with this unit file.\n[Service] Type=forking PIDFile=/var/run/nginx.pid ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf ExecReload=/bin/sh -c \"/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)\" ExecStop=/bin/sh -c \"/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)\" From the NGINX unit file:\n Type=: the type of service to be created PIDFile=: the file where the process id should be stored ExecStart=: the shell command used when the start command is provided ExecReload=: the shell command used when the reload command is provided ExecStop=: the shell command used when the stop command is provided  In this course we are most concerned with the ExecStart= directive, and will be accepting the default values for the remaining directives as we don’t need to provide any additional configuration other than the default configuration for those directives.\nFor the NGINX service the ExecStart= directive is associated with the shell command: /usr/sbin/nginx -c /etc/nginx/nginx.conf.\nThe absolute path to the nginx package has been provided, this way their is no ambiguity on which version of nginx should be used to start this service.\nYou can view what this command does by viewing the help of the nginx package:\nnginx -help Output:\n Bonus You could also execute the absolute path of the nginx package as it’s defined in the unit file:\n/usr/sbin/nginx -help   So the ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf is simply starting the NGINX webserver and telling it which configuration file to use!\n[Install] The [Install] section configures how the unit should behave when enabled or disabled.\n[Install] WantedBy=multi-user.target From the NGINX unit file:\n WantedBy=: marks this unit as a dependency for the listed argument  Before the argument multi-user.target can be completed the service defined by this unit file must be created.\n Bonus The argument provided to the WantedBy= directive can be a valid unit or a computer run level. The multi-user.target is a run level created when a user can be prompted to login to the machine. This is the only run level we will define in this course, however many other targets may be appropriate for different applications.\n  ","description":"","tags":null,"title":"Webserver: Nginx Unit File","uri":"/systemd/walkthrough/webserver-nginx-unit-file/"},{"content":"Changing Branches Now that you have a new branch to work with you can switch or checkout the branch by using the git checkout command.\nRun the command git checkout bug-fix.\nOnce more check your current branch status with the git branch command.\nRunning the Python Program Run the main.py program within py-demo-web-logs to view the output:\nYou will notice that the current output has the following issues:\n ip: /home/student home-dir: 127.0.1.1  These two values should be swapped.\nFix the Bug Open up the main.py file with nano or vim and change the print statement to look like the following:\nprint(\"{}: {}@{} ip: {} home-dir: {}\".format(ts, user, hostname, local_ip, home_dir))\nWrite the changes and exit back to the terminal.\n Warning Make sure to write/save your changes before exiting!\n  Now if you run the main.py program again you should see that the error has been fixed!\n Bonus If you would like to check that the changes you made are correct you can run the command git checkout master and then run the command git checkout bug-fix-solution to view the file it contains and compare it to the change you made on the bug-fix branch.\n  Recap:  Changing branches with the git checkout command  Making minor changes to existing files    ","description":"","tags":null,"title":"Changing Branches","uri":"/git/walkthrough/git-branching/changing-branches/"},{"content":"Forking a Repository A fork is a copy of a pre-existing repository.\nThe major benefit of working with a forked repo is that any changes you make won’t directly affect the original repository you forked. You are free to make changes to files and directories and push those changes to your forked repo. This can be very useful for your own experimentation or ideas you have that you want to add to a pre-existing project.\n Note You can submit a pull request to the original project repository of your forked repository. Once you have made changes (preferably on a new branch: not master) you can submit that pull request through your GitHub repo homepage. This is one way to contribute to a project as as an outside contributor.\n  To fork a repository you must visit the desired github project url and click on the Fork button located near the top right portion of your window.\nClick the fork button. This will be the repository you use in the remainder of the git chapter walkthroughs: branching and merging.\nSelect Destination After clicking the fork button github will provide you with options for the destination of the fork. Select your own personal Github user account as the location.\n Note If you previously forked the project when you click the Fork button it will simply redirect you to your already forked version. Similarly, if you have a repository with the same name of the fork target GitHub will prompt you to enter a new name for this forked repository.\n  Repository Forked After selecting your own github repository you will now see that the repo has been forked and the new repo signature is your-user-name/py-demo-web-logs and that is has been forked from LaunchCodeTechnicalTraining/py-demo-web-logs\nRecap This brief walkthrough is meant to serve as a reminder that you are able to fork a repository in its current state to a desired location.\nThis allows you to make changes to projects that you do not have write access to and potentially contribute to a public project.\nMore Information If you would like more information on forking a repo you can always view the Github Docs on forking.\n","description":"","tags":null,"title":"Forking a Repository","uri":"/git/walkthrough/forking/"},{"content":"Traditional Git Merge  Note You will be using py-demo-web-logs-continued as the github repository for this walkthrough.\n  Using the git merge command is the traditional way to merge development branches into your master branch of development.\nThe main benefits of git merge is that you will keep the original history of the master branch in tact. The downside is that you will be working directly on the master branch and any mistakes or unwanted changes will cause problems.\n  Fork the repository:https://github.com/[your-github-username]/py-demo-web-logs-continued to you your personal github account if you have not done so already.\n  Clone the forked repository:https://github.com/[your-github-username]/py-demo-web-logs-continued onto your personal machine.\n   Note In the example below we are cloning the github repo into the home/student/Desktop directory.\n  Run the command: git clone https://github.com/[your-github-username]/py-demo-web-logs-continued in the directory you cloned your repository.\ngit merge The git merge joins two or more development histories together. When you perform a merge you are merging the target branch into the currently checked out branch.\nThe command to merge the target-branch into the currently checked out branch would be:\ngit merge [target-branch].\nMerge new-feature Branch into master Open up the py-demo-web-logs-continued project directory inside of your terminal.\nCheck the existing branches:\nRun the command git branch -a\nYou are going to merge the new-feature branch and the new-function branch into master.\nActual Merge Lets start with by merging new-feature branch into the master branch:\n Warning Make sure the currently checked out branch is master before running the next command.\n  While on the master branch run the command: git merge origin/new-feature\n Bonus Notice that the above example uses the remote name origin when merging. The remote branches had not yet existed on the local machine when I ran this command. If you already had checked out these remote branches you could have left off the remote name origin and simply run: git merge new-feature.\n  The merge was successful! Remember to update your remote master branch:\nRun the command git push origin master.\nMerge new-function Branch Now that you have merged the new-feature branch into master its time to merge the new-function branch. Since both of these branches made edits to the same files you are going to have a merge conflict.\nRun the command git merge origin/new-function.\n Note Remember that if you already have the new-function branch existing locally you can leave off the remote name origin and run the command git merge new-function!\n  Now would be a great time for you to run a git status command to see what is going on:\nWhat Changes to Keep? Paul and John both made changes to the main.py file. We need to decide which ones to keep and which to throw away.\nThe changes that we want to keep in this walkthrough include the following:\n function created from John’s solution name of file used in Paul’s solution (web.log)  Resolve conflicts in main.py Open up the main.py file with vim (or nano or the file editor of your choice) so that you can make the necessary changes and fix the conflicts inside of the file:\nMake the below changes:\nAfter making the required changes to the file it should look similar to the above image. Write the changes and exit vim.\n Warning Make sure to write the changes to the file before exiting vim!\n  Now that the conflicts have been resolved inside of the main.py file you need to resolve the conflicts inside of the .gitignore file.\nResolve Conflicts in .gitignore Open the .gitignore file with vim.\nKnowing that web.log is the name of the file preferred you can remove everything else from the .gitignore file so that there are no conflicts.\nWrite the file and exit vim so that you are back inside of the py-web-logs-continued directory.\nStaging, Committing and Pushing Conflict Resolution Now that all conflicts have been resolved you will need to add the changes to staging so that you can continue the merge.\nAdd the files to staging and commit changes:\nRun the following commands:\n git add .: Add changes to staging git status: Check status git commit -m \"your commit message: Commit changes to complete merge git push origin master: Push changes to remote repo   Bonus Both the new-feature branch and the new-function branch can now be deleted safely!\n  Recap:  Traditional git merge command: Merge development branches into master branch using the git merge command  Merged the new-feature branch into master without conflict Merged new-function branch into master while resolving conflicts Staging: Pushed updated files into remote master branch    ","description":"","tags":null,"title":"Git Merge","uri":"/git/walkthrough/merging/git-merge/"},{"content":"We will be using Ubuntu as our Linux distribution in this class.\nThe linked articles will take you through:\n Downloading Ubuntu Setting up a virtual machine (using VirtualBox) Configuring the virtual machine to use the downloaded Ubuntu image Starting the virtual machine \u0026 completing Ubuntu setup First time user login  Articles Download Ubuntu Image VirtualBox Image Creation Ubuntu ISO Image Setup Start the Virtual Machine \u0026 Complete Ubuntu Setup First Time User Login  ","description":"","tags":null,"title":"Ubuntu","uri":"/configurations/ubuntu/"},{"content":"Before you can create the Virtual Machine that utilizes the Ubuntu Image you need to open VirtualBox.\nOpen VirtualBox Open VirtualBox the same way you would open any software. Once it is open you should be greeted by the VirtualBox Manager Window:\nCreate a New Virtual Machine In the VirtualBox Manager Window click the New button. Its icon is the blue spiky icon.\nAfter clicking the New button a Create Virtual Machine wizard will open and will guide you through creating a new Virtual Machine. The wizard window looks like the following picture.\n Note If you have never used VirtualBox before, which is likely, you will be prompted by your host OS to give VirtualBox access to your files including your Downloads, and Documents directories. Make sure to grant VirtualBox permission to these locations!\n  Using this wizard you will configure all of the components of the Virtual Machine:\n Virtual Machine Name Virtual Machine Type Virtual Machine OS version Virtual Machine Memory Size Virtual Machine Hard Disk  Virtual Machine Name In the Name textbox enter student-VirtualBox:\nVirtual Machine Type In the Type dropdown select Linux from the dropdown box:\nVirtual Machine OS Version In the Version dropdown select Ubuntu (64 bit):\nAfter entering all three of the preceding components click the Next button.\n Note You will not be changing the default value on the Machine Folder component. Your default location is dependent on your host opearating system. For a MacOS it will be similar to /Users/user-name. For a Windows OS it will be similar to C:\\Users\\user-name.\n  Virtual Machine Memory Size You need to configure the amount of RAM this Virtual Machine has access to. Your host computer has a certain amount of RAM, you cannot provide all of the RAM to the Virtual Machine because your host computer still needs access to some of the memory.\nFor this step you will be entering 2048 (2 GB) into the only textbox on this window:\n Note You could also use the slider bar to configure the amount of RAM to provide to the Virtual Machine. We don’t recommend this, because it’s difficult to be precise. Make sure to provide at least 2048 MB of RAM.\n  After entering 2048 into the textbox click the Next button.\nVirtual Machine Hard Disk Similar to the RAM of your Virtual Machine you need to provide a certain amount of hard disk space from the Host operating system. However, this hard disk space needs to be formatting in a way that allows for an operating system to function.\nLuckily, VirtualBox will perform this formatting for us after completing the wizard.\nCreate a Virtual Hard Disk You will be creating a new VirtualBox managed virtual hard disk.\nLeave the first setting on the default value Create a virtual hard disk now.\nClick the Create button.\nSelect Hard Disk Type You will be using the VirtualBox preferred VDI (VirtualBox Disk Image) which should be the default value.\nAfter confirming the VDI option click Next.\nFixed or Dynamic Hard Disk VirtualBox allows you to dynamically add more space to your Hard Disk. However, this slows down the entire Virtual Machine because of the flexible nature of the hard disk size.\nFor this reason you will be using the Fixed size for your virtual hard disk.\nAfter selecting the Fixed size option click Next.\n Note If you are creating your own personal Virtual Machine after this class, you may want to use a dynamically sized hard disk. This will offer you more flexibility with regards to the virtual machine hard disk usage.\n  File Location and Size The file location for the VirtualBox you will leave as the default value. You will want to adjust the size of the virtual hard disk. The default value is 10.00 GB. You should change this to 12.00 GB as shown in the image below.\nAfter entering 12.00 GB click the Create button.\nVirtualBox Manager Homepage After completing all of the steps above your virtual machine will be created. When you view the VirtualBox homepage you should see a window similar to the following image:\nReview As a final step let’s review all of the settings we configured into this virtual machine. You can see these in the window displaying the student-VirtualBox virtual machine.\nGeneral  Name: student-VirtualBox Operatating System: Ubuntu (64 bit)  System  Base Memory: 2048 MB  Storage  Controller :IDE:  IDE Secondary Device 0: [Optical Drive] Empty   Controller :Sata:  SATA Port 0: student-VirtualBox.vdi (Normal 12.00 GB)    Take note of the IDE Secondary Device 0, this is referencing the CD drive of this specific image. It is currently empty, which makes sense, as we don’t have a CD in our computer! In order to load Ubuntu we are going take the Ubuntu.iso image we downloaded earlier and virtually insert it into this optical drive. This will allow us to boot into Ubuntu and load it into this virtual image.\n Note In this course will not be discussing the audio, network, usb, shared folders, or description. The VirtualBox software does allow you to configure these settings if your virtual machine needs customized access to these host operating system tools.\n  Next Steps After completing the above instructions please move on to the next portion of the installation process located in the article below:\nUbuntu ISO Image Setup\n","description":"","tags":null,"title":"VirtualBox Image Creation","uri":"/configurations/ubuntu/virtualbox-image-instructions/"},{"content":"Get Organized What needs to happen for the Spring project to be deployed?\nVirtualBox  VirtualBox Image created VirtualBox First time setup completed  Machine State  git must be installed web server must be installed  Project Artifacts The artifacts are already built, they just need to be installed onto the machine with git.\n use git to clone build artifacts  Web Server Configuration caddy or nginx must be configured to catch HTTP requests and respond as a file_server, and then must be reloaded.\nAt this point the Spring project should be accessible in your browser.\n Note This Spring project has a couple of different requirements than the React project. You will need to install the required version of java in order to run this project to set up a reverse proxy. The version you will need is 11. In order to start the project you need to run the command java -jar path/to/jar-file\n  Full Script Solution   Click Here for Solution  # Install Dependencies  ## Update Package Repositories sudo apt update -y  ## Install Git sudo apt install git  ## Install openjdk-11-jre  sudo apt install -y openjdk-11-jre  ## Install Caddy  sudo apt install -y curl  curl -1sLf \\  'https://dl.cloudsmith.io/public/caddy/stable/cfg/setup/bash.deb.sh' \\  | sudo bash  sudo apt update -y sudo apt install caddy  ## Clone Build Artifacts  git clone https://github.com/LaunchCodeTechnicalTraining/spring-todo-mvc-artifact  ## Run the project jar file with jre in detached mode  java -jar /home/student/spring-todo-mvc-artifact/todo-api.jar \u0026  ## Configure Web Server  ( cat \u003c\u003c'EOF' http://localhost { reverse_proxy http://localhost:8080 } EOF ) \u003e Caddyfile  sudo mv Caddyfile /etc/caddy/Caddyfile  sudo systemctl stop caddy  sudo caddy start  sudo caddy reload --config /etc/caddy/Caddyfile    Check Browser ","description":"","tags":null,"title":"Spring Initialization Script","uri":"/final-project/spring-initialization-script/"},{"content":"This article has you adding the official NGINX package repository and adding the nginx package.\nInstallation To read the installation instructions provided by NGINX look over the NGINX Ubuntu Installation Article.\nInstall Tools Used in Installation sudo apt install curl gnupg2 ca-certificates lsb-release ubuntu-keyring Download and Add the nginx_signing.key: curl https://nginx.org/keys/nginx_signing.key | gpg --dearmor | sudo tee /usr/share/keyrings/nginx-archive-keyring.gpg \u003e /dev/null Check the Contents of the nginx_signing.key: gpg --dry-run --quiet --import --import-options import-show /usr/share/keyrings/nginx-archive-keyring.gpg Desired Output of the nginx_signing.key:\npub rsa2048 2011-08-19 [SC] [expires: 2024-06-14]  573BFD6B3D8FBC641079A6ABABF5BD827BD9BF62 uid nginx signing key \u003csigning-key@nginx.com\u003e Add NGINX Package Repository: echo \"deb [signed-by=/usr/share/keyrings/nginx-archive-keyring.gpg] http://nginx.org/packages/ubuntu `lsb_release -cs` nginx\" | sudo tee /etc/apt/sources.list.d/nginx.list Configure Package Repository Set up repository pinning to prefer our packages over distribution-provided ones:\necho -e \"Package: *\\nPin: origin nginx.org\\nPin: release o=nginx\\nPin-Priority: 900\\n\" | sudo tee /etc/apt/preferences.d/99nginx Update Package Repository List and Install nginx Package: sudo apt update sudo apt install nginx Validation which nginx nginx -version Output:\nUpon a successful installation you should see the location of the nginx binary and the version of the installed nginx package with the preceding commands.\nManaging the nginx.service NGINX automatically creates a service upon installation. The nginx.service can be controlled with the systemctl package.\nFor now we will be turning off and disabling the nginx.service. We will learn more about this in a later lesson.\nStop Service sudo systemctl stop nginx Disable Service sudo systemctl disable nginx ","description":"","tags":null,"title":"NGINX Installation","uri":"/package-manager/exercises/nginx/"},{"content":"Name  chown - change file owner and group\n Usage The chown command allows you to change the ownership on any given file which will directly affect what users are able to read, write, and execute the target file.\nchown [OPTION] [OWNER][:[GROUP]] [file-name] Examples Create a new file called chown-example.\ntouch chown-example Check the current owner of the newly created file:\nls -l Output:\nThe current user student in the student group is the owner of the file chown-example.\nChange File Owner Change the ownership of the file chown-example to the root user.\nsudo chown root chown-example Output:\nThe new owner of the file chown-example has been changed to the root user. However the chown-example file still falls within the student group.\nChange File Group To change the group of a file chown requires an additional argument:\nsudo chown :root chown-example Output:\nYou are able to add a : to the chown argument to change the group of a file.\n Bonus The chown command also allows you to change the user and group ownership with one command. sudo chown student:student chown-example The first argument of the chown command (prior to the :) designates the file owner. The second argument designates the desired group.\n  Recap:  chown command  allows you to change user and group ownership of a file chown [OPTIONS] file-name chown new-user file-name: changes user ownership chown :new-group file-name: changes group ownership chown new-user:new-group file-name: changes both user and group ownership with one command    ","description":"","tags":null,"title":"Changing File Ownership","uri":"/file-permissions/walkthrough/chown/"},{"content":"Conditional Statements in Bash Similar to many programming languages bash allows you to write conditional statements to control the flow of a script:\nBash Python JavaScript Java  if [[ condition ]] then  clause statement fi   if condition:  clause statement   if (condition) {  clause statement }   if (condition) {  clause statement }     Bash requires a closing “fi” for if statements.\n Note Bash is an old and mature tool. To wit, there are many ways to write an if statement in bash. The preceding example is the example that most closely aligns to many of the popular programming languages.\nThe double square brackets ([[]]) are the way of defining a boolean expression in bash. The if statement will first evaluate the boolean expression inside of the square brackets to true (1) or false (0) and then the clause statement will be executed based on the results of the boolean expression.\n  Operators Bash has built in binary operators for the following:\n equal to: -eq not equal to: -ne less than: -lt less than or equal to: le greater than: -gt greater than or equal to: -ge  Some of the above operators will be used in the following walkthroughs for the Bash: Scripting chapter.\n Note Again, due to the age and maturity of Bash some of the preceding binary operators can be replaced with more modern programming language equivalents like equal to (==) and not equal to (!=). However, even the oldest version of bash will accept the binary operators as defined above.\n  Examples if Statement Create a new file called if-condition.sh.\n#!/bin/bash  number1=10  if [[ $number1 -eq 10 ]] then  echo \"$number1is equal to 10!\" fi Save the above code to the if-condition.sh file and exit the editor.\nRun the command bash if-condition.sh.\nif else statement Create a new file called if-else-condition.sh.\n#!/bin/bash  number1=1 number2=2  if [[ $number1 -gt $number2 ]] then  echo \"The first number is higher\" else  echo \"The second number is higher\" fi Save the above code to the if-else-condition.sh file and exit the editor.\nRun the command bash if-else-condition.sh.\n Bonus Try changing the values of the variables to test different outcomes!\n  if elif else statement Create a new file called if-elif-else.sh.\n#!/bin/bash  new_number=50  if [[ $new_number -lt 50 ]] then  echo \"The number is less than 50\" elif [[ $new_number -eq 50 ]] then  echo \"The number is equal to 50\" else  echo \"The number is greater than 50\" fi Save the above code to the if-elif-else.sh file and exit the editor.\nRun the command bash if-elif-else.sh.\nTry changing the value of new_number!\n Bonus You can also read from stdin and assign a variable with bash to make a script more interactive. Create a new file called read-stdin-example.sh.\nAdd the code below:\n#!/bin/bash  echo \"Please enter a number: \" read number_value  if [[ $number_value -lt 50 ]] then  echo \"The number $number_valueis less than 50\" elif [[ $number_value -eq 50 ]] then  echo \"The number $number_valueis equal to 50\" else  echo \"The number $number_valueis greater than 50\" fi Run the command bash read-stdin-example.sh\n  Recap  if statement syntax  if statement example if else example if elif else example   fi: closing if statement  ","description":"","tags":null,"title":"Conditionals","uri":"/bash-scripting/walkthrough/conditionals/"},{"content":"Script Requirements  Write a script that does the following:  Loops through an ArrayList Prints out the highest number within the list Prints out the index of the highest number      Click Here for Solution  #!/bin/bash  ## Enter any numbers inside of index_list index_list=(15 10 -3 5 23 -5)  for number in ${!index_list[@]} do \tif [[ ${index_list[$number]} -gt $high_value ]] \tthen \thigh_value=${index_list[$number]} \thigh_index=$number \tfi done  echo \"The highest value within the array is: \"$high_value echo \"The index location of the highest value is: \"$high_index    ","description":"","tags":null,"title":"Index of Highest Value Script","uri":"/bash-scripting/exercises/highest-index/"},{"content":"Bonus: Selecting commands containing redirection write operators from history and saving. Pipe the STDOUT from the history command to grep and search all lines for a redirection write operator \u003e and write the output to myhistory-write-commands.txt.\nSolution   CLICK FOR ANSWER  history | grep '\u003e' \u003e myhistory-write-commands.txt    Verification   CLICK FOR ANSWER  cat myhistory-write-commands.txt Example output:\n 910 echo \"Paul\" \u003e myname.txt  913 echo \"firstName=Paul\" \u003e myname.txt  915 echo \"lastName=Matthews\" \u003e\u003e myname.txt  917 history \u003e myhistory.txt  919 history | grep '\u003e' \u003e myhistory-write-commands.txt In the command above grep is searching each line of output from the history command for a specific character (the redirect write operator \u003e) and only putting matched lines into STDOUT which is then written to myhistory-write-commands.txt!\nTake note that the redirect append operator was matched as a part of the grep search because it is made up of two characters that matched the grep search!\n  ","description":"","tags":null,"title":"Bonus: Pipe Operator","uri":"/bash-streams-redirection-pipe/exercises/pipe/"},{"content":"Convert STDOUT into STDIN of Following Command The Bash pipe operator | provides the abililty to take the STDOUT from the first command and use it as the STDIN for the next command.\nThe pipe operator is a powerful tool in Bash that allows us to create specific and sometimes complex commands.\nThe pipe operator syntax will look similar to: [bash-command-one] | [bash-command-two].\nWhatever contents added to STDOUT from [bash-command-one] will be used as the STDIN for [bash-command-two].\nPipe STDOUT from ls -a to less ls -a | less Upon executing the preceding command the STDOUT from ls -a will be used as the STDIN for the less command. This will open up the less view window in the terminal.\nOutput:\nThe picture displays a less window. The contents can be navigated using the less tools, and can be ultimately exited with a press of the q key.\n Note The output you see may be slightly different than the output from the picture. Many of the hidden files and directories in the picture will eventually find their way onto your machine as your continue through this course.\n  Pipe history to less Viewing the history of your bash terminal is useful, but can be overwhelming:\nhistory Output:\nThe STDOUT of the history command defaulted to the terminal window. It would be much easier to view the contents in a less window. This can be achieved by piping STDOUT of history to the STDIN of less:\nhistory | less Output:\n Note Your history will be different than the above picture. You can exit the less window by pressing the q key.\n  Pipe history to grep grep is a searching tool that we will learn about in a future article, but is a great example of how the bash pipe operator can be used.\nIn this case the STDOUT of history needs to be filtered to only include ls commands. This can be achieved by executing history and piping the STDOUT to the grep command with an argument searching for only ls commands:\nhistory | grep 'ls' Output:\nPipelines In bash you can chain together multiple commands with the pipe operator to create specific and sometimes complex commands.\nSuppose you wanted to open the STDOUT from history | grep 'ls' in less you can add another pipe:\nhistory | grep 'ls' | less Output:\nThe STDOUT contents of history | grep 'ls' have now been passed as the STDIN to the less command.\nYou can chain as many pipes together as you need creating complex, but simple to understand, pipelines.\n","description":"","tags":null,"title":"Pipe Operator","uri":"/bash-streams-redirection-pipe/walkthrough/pipe-stdout-to-stdin/"},{"content":"Opening an Existing File With vim an existing file can be opened by entering vim [file-name] in the bash shell.\nOpen the file created in the last article by entering: vim temp-file.txt\n Note Opening a file looks very similar to creating a new file. The only difference in this image from the image in the original creation article is the text at the bottom of the file:\n\"temp-file.txt\" 0L, 0C After creating the file initially it was:\n\"temp-file.txt\" [New File] A subtle, but informative difference.\n  ","description":"","tags":null,"title":"Open File","uri":"/userspace-applications/walkthrough/vim/open-file/"},{"content":"Dependencies Install .NET SDK 3.1 and the dotnet CLI Add Package Repository wget https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb  sudo dpkg -i packages-microsoft-prod.deb Update Package Repository List sudo apt update Install .NET SDK 3.1 and dotnet CLI sudo apt install dotnet-sdk-3.1 Clone React Build Artifacts: Clone the following repository to the home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/dotnet-techjobs-mvc-artifacts How do you deploy the dotnet-techjobs-mvc project using Caddy?\n  Click Here for Answer  Ensure the caddy service is running:\nsystemctl status caddy Start the caddy service if it is inactive:\nsudo systemctl start caddy Start the .NET application:\ndotnet TechJobsMVC.dll Create a Caddyfile\n You can create the Caddyfile anywhere you would like. For this exercise it was created inside of the home directory.  Add the following code to the Caddyfile\n## Default localhost port https://localhost {  reverse_proxy http://localhost:5000 } Reload the Caddy Service:\ncaddy reload Open Localhost in the browser:\n  ","description":"","tags":null,"title":".NET Exercise","uri":"/web-server/exercises/caddy-exercises/dotnet/"},{"content":"Dependencies Install .NET SDK 3.1 and the dotnet CLI Add Package Repository wget https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb  sudo dpkg -i packages-microsoft-prod.deb Update Package Repository List sudo apt update Install .NET SDK 3.1 and dotnet CLI sudo apt install dotnet-sdk-3.1 Deploy Artifacts (GitHub) You can find the artifacts for this project at the .NET Techjobs MVC artifacts GitHub repo.\nInstructions Using the project dependencies and the deploy artifacts:\n start the application server configure NGINX to serve as a reverse proxy to the running application server  Hints Starting the Application Server  Figure out how to start a .NET application with the dotnet CLI. Figure out how to start a .NET application with the executable script in the Project artifact directory.  NGINX Troubleshooting  NGINX and Caddy can’t both be running as they conflict over the ports 80 and 443. Use the systemctl stop and start commands to ensure only NGINX is active.  Questions \u0026 Answers How can the application server be started with the dotnet CLI?   CLICK FOR ANSWER  cd dotnet-techjobs-mvc-artifacts dotnet TechJobsMVC.dll Optionally you can invoke the script found in the artifact directory ./TechJobsMVC after changing into the project directory.\n  What port was the application server running on?   CLICK FOR ANSWER  The Kestrel server was running on: http://localhost:5000. Port 5000.\nTake note of the output in the picture where it mentions listening on http://localhost:5000.\n  What did the NGINX configuration need to contain to serve as a reverse proxy?   CLICK FOR ANSWER  server {  listen 80;  server_name localhost;   location / {  proxy_pass http://localhost:5000;  } }    What command was used to reload NGINX after a change was made to the configuration file?   CLICK FOR ANSWER  sudo nginx -s reload    ","description":"","tags":null,"title":".NET Exercise","uri":"/web-server/exercises/nginx-exercises/dotnet/"},{"content":"Articles Setup Caddyfile Commands Static Website Reverse Proxy  ","description":"","tags":null,"title":"Caddy","uri":"/web-server/caddy/"},{"content":"Caddy CLI Commands: The Caddy service is controlled using the Caddy CLI.\nThe Caddy CLI provides a command to start, stop, and reload the process. The primary reason to use the caddy reload command would be to recognize changes made to the Caddyfile configuration.\n Bonus The caddy CLI offers many commands for managing and even configuring the Caddy web server. Almost all of these commands fall outside the scope of this class. We predominately interested in reloading the Caddy webserver when changes have been made to a Caddyfile.\nTo learn more about the caddy CLI checkout it’s help page:\ncaddy help     Warning Anytime a change is made to a Caddyfile the process must be reloaded with caddy reload.\n  ","description":"","tags":null,"title":"Commands","uri":"/web-server/caddy/commands/"},{"content":"nginx CLI Command: reload The nginx.service is controlled with the systemctl tool, which is the preferred way of working with the running service. However, when an NGINX configuration file is altered systemctl has no way of instructing the service to reload the configuration.\nThe nginx CLI provides a command that allows you to reload the process, including any changed configuration files, this command is sudo nginx -s reload.\n Bonus In total there are four signals you can send using the nginx CLI:\n nginx -s stop nginx -s quit nginx -s reopen nginx -s reload  This course only requires you to understand reload.\n  Anytime a change is made to an NGINX configuration file the process must be reloaded with sudo nginx -s reload\n","description":"","tags":null,"title":"nginx -s reload","uri":"/web-server/nginx/nginx-reload/"},{"content":"Walkthrough systemctl Webserver: Nginx Unit File Webserver: Caddy Unit File Bash Unit File Spring Unit File  ","description":"","tags":null,"title":"Walkthrough","uri":"/systemd/walkthrough/"},{"content":"pwd command Let’s try out our first command: pwd. pwd is one of the Bash commands that takes no arguments.\nSimply type pwd into your terminal and hit enter.\n Note Make sure you only type pwd into your terminal before hitting enter. Since the Bash shell is expecting text it requires the text you enter to exactly match it’s expectations.\n  pwd stands for print working directory. You will notice the output of the command is simply the text /home/student. Which is the current working directory of our Bash shell session.\nWhile in a Bash shell session you will be regularly changing directories. Being able to quickly determine your current working directory is highly beneficial.\n","description":"","tags":null,"title":"Bash Command: pwd","uri":"/bash-introduction/walkthrough/pwd/"},{"content":"Major Concepts \u0026 Key Terminology  shell terminal emulator Bash shell Bash command structure  bash arguments bash options   Basic Bash commands:  pwd clear ls echo which   Bash Shell Variables  $BASH $HOME $PATH   Bash Help  man --help option    Content Links Walkthrough Demo Exercises  ","description":"","tags":null,"title":"Bash: Introduction","uri":"/bash-introduction/"},{"content":"Walkthrough Bash is the GNU Project’s shell. A shell is an interface between a user and the kernel. Bash is a text-based shell. By learning aspects of the Bash shell you are learning a powerful mechanism for interfacing with a computer.\nTerminal Emulator Bash Command Basics Bash Command: pwd Bash Command: clear Bash Command: ls Bash Command: echo Bash Shell Variables Bash command: kill Bash command: which Getting Help Review  ","description":"","tags":null,"title":"Walkthrough","uri":"/bash-introduction/walkthrough/"},{"content":"Example cronjob within crontab: Open up your crontab config file and add the following cronjob command:\n* * * * * echo \"$(date)\" \u003e\u003e ~/Desktop/time.log Run the command: crontab -e and add the cronjob to the config file:\nWrite the file and navigate to your desktop. You should see the created time-log file created from the cronjob.\nValidation cat out the time-log file.\nRecap:  Add a cronjob to crontab file check file created from cronjob for validation  ","description":"","tags":null,"title":"Create a Cronjob","uri":"/cron/walkthrough/cronjob/"},{"content":"Exercises Create a cronjob that removes all .txt files from your Desktop directory every 3 minutes.\n Add a file to your Desktop directory for testing purposes:  touch /home/student/Desktop/example-file.txt    Click Here for Answer  */3 * * * * rm /home/student/Desktop/*.txt    Create a cronjob that would append the current date the first minute of every month to a file called new-month on your Desktop.\n  Click Here for Answer  1 0 1 * * echo \"$(date)\" \u003e\u003e /home/student/Desktop/new-month    Questions and Answers What is a Crontab?   Click Here for Answer  File that holds instructions for the cron daemon.\n  How do you list the current user’s Crontab?   Click Here for Answer  crontab -l    How do you edit the current user’s Crontab?   Click Here for Answer  crontab -e    How many time parameters are required for a Cronjob?   Click Here for Answer  Five\n  What would the syntax be to run a cronjob at 5:30 PM every Monday, Wednesday, and Friday?   Click Here for Answer  30 17 * * 1,3,5\n  What is the syntax to run a cronjob at 5:00 AM the first day of every quarter of the year?   Click Here for Answer  0 5 1 3,6,9,12 *\n  ","description":"","tags":null,"title":"Exercises","uri":"/cron/exercises/"},{"content":"Content Links Review: Basic Git Workflow Forking a Repository Cloning a Repository Git Branches Creating Branches Changing Branches Staging Changes Merging Review Existing Code Git Merge Git Rebase  ","description":"","tags":null,"title":"Walkthrough","uri":"/git/walkthrough/"},{"content":"When dealing with any Package Manager a common task is to refresh your list of package repositories and download the metadata of all packages. This is a common task to complete before installing a new package or upgrading any existing packages because it ensures our Package Manager has the most up to date information on all packages.\n Note Being able to update the metadata about the packages is a very important task. There are tons of packages and all of them are actively maintained which takes the form of: bug squashing, vulnerability patching, feature adding, optimization, etc. Each of these changes usually results in a new version (or build) of the package which adds to the metadata of the package. Being able to update our package manager allows us to learn of any of these changes without upgrading any of our packages.\n  sudo apt update Updating from the CLI is quite easy. We simply enter sudo apt update:\nYou can see from the display that it is reading all package lists from our configured Ubuntu package repositories.\nThe command also detected that 99 packages can be upgraded as there are newer versions as dictated by the package lists.\nman apt It’s always a good idea to read the documentation of the tools you are working with. You can manually search the Manual Reference Page for apt to find the update section, or take a look at the section we copied for you:\nFrom Man page:\nupdate is used to download package information from all configured  sources. Other commands operate on this data to e.g. perform  package upgrades or search in and display details about all  packages available for installation. ","description":"","tags":null,"title":"Updating Package Repositories","uri":"/package-manager/walkthrough/updating-package-repositories/"},{"content":"Walkthrough We will be using the apt command line interface to work with our packages and package repositories.\napt CLI Reading Package Repositories Updating Package Repositories Reading Packages Searching for Packages Installing Packages Removing Packages Upgrading Packages Adding Package \u0026 Repository  ","description":"","tags":null,"title":"Walkthrough","uri":"/package-manager/walkthrough/"},{"content":" Wget Exercises Curl Exercises Grep Exercises Sed Exercises Vim Exercises  ","description":"","tags":null,"title":"Exercises","uri":"/userspace-applications/exercises/"},{"content":"Questions and Answers What is the purpose of Grep?   Click Here for Answer   Parse text and return lines that match specific patterns.\n   What are some common uses of Grep?   Click Here for Answer   Search for file names matching a specific pattern in a directory Search contents of a file for specific patterns Search web request data for lines matching specific patterns    What character represents the Line Begin Anchor?   Click Here for Answer  ^\n  What character represents the Line End Anchor??   Click Here for Answer  $\n  What is the Any Character Symbol??   Click Here for Answer  .\n  How would you search a file for lines beginning with the phrase John?   Click Here for Answer  cat file-name | grep \"^John\"    How would you search a directory for only files ending in .csv?   Click Here for Answer  ls /path/to/directory | grep \".csv$\"    Working with the user.csv Dataset Using the user.csv Dataset complete the following requirements:\n Note If you need to get the user.csv Dataset again you can do so with the following command:\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e user.csv    Filter the results of the user.csv so that you only match users by the name of James with an email ending in .org that work for Boeing.\n  Click Here for Solution  grep '^James' user.csv | grep '.org' | grep 'Boeing$'    Filter the results of the user.csv so that you only match users with the last name Campbell that work for the organization Freedom pay.\n  Click Here for Solution  grep \"Campbell,\" user.csv | grep \"Freedom pay\"     Bonus How would you filter the results of the user.csv so that you only match users with the first name John or Paul and have a last name beginning with the letter J or S that work for the organization Express Scripts?\n    Click Here for Answer  grep -E '^John,[J,S]|^Paul,[J,S]' user.csv | grep \"Express Scripts\"    ","description":"","tags":null,"title":"Grep Exercises","uri":"/userspace-applications/exercises/grep/"},{"content":"Find the hosts files  find all files containing the word hosts in the /etc directory  hint: you may need to elevate permissions hint: you may need to use wildcards (*) bonus: only return files: checkout the man pages and look for the -type option   printout the terminal the contents of the /etc/hosts, which should be one of the files/directories you found in the last step  what do you think this file means? hint: what is the relationship between 127.0.0.1 and the domain name localhost?    Find the passwd file  find the passwd file in the /etc/ directory  find your username in this file  what does it say the home directory for that user is?      Questions \u0026 Answers What command, arguments, and options did you use to find all files containing the word hosts in the /etc directory?   CLICK FOR ANSWER  sudo find /etc --name *hosts*\n  Why are the wildcards (*) necessary in the previous answer?   CLICK FOR ANSWER  Without the wildcards the find command searches for file names matching exactly hosts of which it finds a couple, but it doesn’t find all files that contain the word hosts.\n  ","description":"","tags":null,"title":"Finding Files","uri":"/file-system/exercises/find-hosts/"},{"content":"Reading Contents Let’s learn how to Read files and directories.\nYou already know how to list the contents of a directory with the ls command.\nYou can list the contents of a file in a few different ways:\nConcatenate and Display The cat command will concatenate all of the contents of a file into an ASCII string and display in the terminal window.\nLet’s take a look at the contents at some of the files on our machine.\ncat /etc/hostname This is the hostname on record for this machine. This lines up with whatever you named your machine back when we first setup this VirtualBox image. If you followed our guide to the letter it should be student-Virtualbox.\nThe hostname is the name of the computer. Any given computer may have multiple users (in this case: student).\ncat /etc/timezone After installing the Ubuntu distribution onto our Virtualbox we configured our operating system including selecting our timezone. This is the file that keeps the record of our timezone!\ncat /etc/environment This is the file that coincides with the $PATH shell variable. This is known as the system wide $PATH all users (including the student and root users) use this base system wide path. If you added a directory to this file it would be shared across all users of the machine.\n Warning A user wouldn’t add something to the system wide path, they would make their changes in the ~/.bashrc file which would only make changes to their specific path. We will learn about later in this lesson.\n  cat ~/.bash_history  Note Your history will be different from the picture!\n  This is the text file tracking all of the commands of all of the most recent bash shell’s initialized by the user. There is so much information you would have to scroll in the terminal window to see the start of the command.\nhistory The preferred way of viewing the history of any given Bash shell is by using the history builtin command.\nEnter history\nDisplay and Parse Interactively When files have a lot of content it’s not always ideal to cat the file and scroll using the terminal window. This is a manual and tedious process, not to mention the terminal window only has access to a certain amount of memory and very large files will have their content truncated after the memory has been exceeded.\nLuckily, there are multiple programs that chunk the contents of the file into memory and display them in an interactive fashion. One of these programs is called less.\nThere are some tips and tricks you need to know about using less to read files. After opening a file with less your terminal will change to display the file and you will lose access to your bash shell until you exit the less program.\nYou can scroll up and down in less with the directional (arrow) keys. You can also scroll up by pressing the j key and you can scroll down with the k key.\nTo exit less you simply need to press the q key.\nLet’s give it a try.\nless ~/.bash_history Before executing the command you will see:\nAfter executing the command you will see something similar to the following picture.\nFrom here you have the full power of less at your fingertips, you can move to any line on the file by navigating with the tips listed above.\nWhen you are ready to exit the file you simply need to press the q key. This will return you back to your Bash shell.\nBonus   Click here for a list of interesting files to display!   /etc/hostname /etc/timezone /etc/nanorc /etc/group /etc/gshadow –\u003e need elevated permissions (more of a demo) /etc/environment –\u003e system wide environment variables /etc/profile –\u003e login shell environment variables ~/.bashrc –\u003e individual user bash shell initialization execution script (individual shell environment variables) /etc/apt/sources.list /var/log/syslog /var/log/message /var/log/boot.log /var/log/kern /var/log/cron ~/.bash_history    Display contents in Text Editor Another common way to display (and edit if necessary) is by using a terminal text editor.\nAn example of this would be running the nano filename command. This would open the file contents with the GNU text editor nano.\n Warning If you open a file with a terminal text editor you will need to figure out how to exit the file to get back to your bash shell. In nano you can exit a file by pressing the control and x keys (ctrl + x).\n  We will see examples of this when we learn about editing the contents of files with nano in a later section.\n Bonus Many IDEs and graphical text editors also provide a shell command for opening a file with the chosen IDE/text editor! If you install Visual Studio Code onto your distribution you can open a file directly into VSC with the code filename command. We will see an example of this when we learn about installing additional software in the Package Manager section.\n  ","description":"","tags":null,"title":"Reading Contents","uri":"/file-system/walkthrough/reading-contents/"},{"content":"File System Commands Review \u0026 Changing Directories Creation Commands Reading Contents Deleting Files \u0026 Directories Updating Files \u0026 Directories Finding Files Bash Aliases Bashrc Sudo  ","description":"","tags":null,"title":"Walkthrough","uri":"/file-system/walkthrough/"},{"content":"sed substitute ‘,’ with ‘\\t’ Convert the user-data.corrected.csv to a tsv file:\nRun:\nsed 's/,/\\t/g' user-data.corrected.csv \u003e user-data.corrected.tsv Validation ls Output:\nA new file exists: user-data.corrected.tsv.\nInspect it:\ncat user-data.corrected.tsv Output:\n","description":"","tags":null,"title":"Substitute: Convert CSV to TSV","uri":"/userspace-applications/walkthrough/sed/substitute-convert-csv-tsv/"},{"content":"Regular Expression Any Character: . You can use the any character reserved symbol (.) to instruct the Regular Expression pattern to match any single character.\nMatch '^.a' Let’s match all lines that start with any character, but the second character must be the lowercase letter a:\ngrep '^.a' user.csv Output:\n Note This RegEx pattern '^.a' is combining the Line Begin Anchor and the match any character symbol .. RegEx allows you to mix and match the special syntax to create highly specific patterns.\n  Match '.7@example.com grep '.7@example.com' user.csv Output:\n Note The match any character symbol provides great flexibility for all patterns.\n  ","description":"","tags":null,"title":"Regex: Any Character Symbol","uri":"/userspace-applications/walkthrough/grep/regex-any-character/"},{"content":"Name  grep, egrep, fgrep, rgrep - print lines that match patterns\n Purpose Parse text and return lines that match specific patterns.\nUsage  Search for file names matching a specific pattern in a directory Search contents of a file for specific patterns Search web request data for lines matching specific patterns  What is a Pattern? A pattern is written as a regular expression.\nRegular expressions can be:\n a single character a word a phrase all of the above using the additional tools defined by regular expressions  Setup: Download Walkthrough Dataset Before we can start searching text we need to first download the text we will be searching. From your home directory:\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e user.csv This command makes a curl request to the provided endpoint and whatever data is returned will be written to a file called user.csv.\nValidation You can cat out the file, but it has 25000 records in it.\n Bonus You can use the wc package to count the lines in the file:\nwc -l user.csv Output:\n25001 total lines.\n  Word \u0026 Phrase Matching Any string is a valid regular expression.\nWhen using a string as the regular expression in the pattern all lines containing the string will be matched.\nMatch 'Paul' grep 'Paul' user.csv Trimmed Output:\ngrep is searching each line of our file for pattern matches.\nThis command has matched:\n Paul as the first name Paula as the first name Paul as the last name  It would also match Paul in any remaining sections like the company, or email address.\nAs long as Paul is found at any point in the line, the line will be returned.\nMatch 'Paul,Ro' grep 'Paul,Ro' user.csv Output:\nThis is a more specific string than the previous example.\nSix records matched each last name started with Ro as dictated by the regular expression, but the rest of the name didn’t matter which is why Rogers, Robinson, \u0026 Rodriquez all matched.\nMatch 'Paul,Rogers' grep 'Paul,Rogers' user.csv This is an even more specific string resulting in even less results.\nTwo records matched:\n Paul,Rogers,richardmedina@exaxmple.org,Edward Jones Paul,Rogers,richard72@example.org,mastercard  grep will parse the entire text and only return lines that contain the exact pattern provided.\nMore Specific Matching with Regex Concepts \u0026 Symbols Regular Expressions are a very powerful tool.\nBy learning the Regular Expression concepts and syntax you can create very specific patterns. Typically the more specific your pattern is, the better your result set will be.\nThis class doesn’t really cover Regular Expressions, however we included some of the basics to show how to create better patterns by incorporating some RegEx basics.\nContent Regex: Line Begin Anchor Regex: Line End Anchor Regex: Any Character Symbol Regex: Matching Set grep From STDIN grep Chaining  ","description":"","tags":null,"title":"grep","uri":"/userspace-applications/walkthrough/grep/"},{"content":"Checking Status systemctl status caddy Loaded: loaded(/lib/systemd/system/caddy.service; enabled; vendor preset:\u003e Viewing Unit File cat /lib/systemd/system/caddy.service # caddy.service # For using Caddy with a config file. # # Make sure the ExecStart and ExecReload commands are correct # for your installation. # # See https://caddyserver.com/docs/install for instructions. #  # WARNING: This service does not user the --resume flag, so if you # use the API to make changes, they will be overwritten by the # Caddyfile next time the service is restarted. If you intend to # use Caddy's API to configure it, add the --resume flag to the  # `caddy run` command or use the caddy-api.service file instead.  [Unit] Description=Caddy Documentation=https://caddyserver.com/docs After=network.target network-online.target Requires=network-online.target  [Service] Type=notify User=caddy Group=caddy ExecStart=/usr/bin/caddy run --environ --config /etc/caddy/Caddyfile ExecReload=/usr/bin/caddy reload --config /etc/caddy/Caddyfile TimeoutStopSec=5s LimitNOFILE=1048576 LimitNPROC=512 PrivateTmp=true ProtectSystem=full AmbientCapabilities=CAP_NET_BIND_SERVICE  [Install] WantedBy=multi-user.target This unit file is very similar to the NGINX unit file.\nIn the [Unit] section it defines a description, a link to the documentation and defines some relationships.\nIn the [Service] section it sets the ExecStart= directive among other configurations.\nIn the [Install] section it defines that this service should be created before the multi-user.target run level is complete.\n Bonus Take note of how this unit file also defines the user and group this service should run under.\n  ","description":"","tags":null,"title":"Webserver: Caddy Unit File","uri":"/systemd/walkthrough/webserver-caddy-unit-file/"},{"content":"  Note In this article we will be using the Repository we forked in the previous walkthrough article.\n  Git Clone Cloning a repo will work for any repository on GitHub you are authenticated to view. An original project, a forked project, or a project you have created previously that you would like to access on a new machine.\nThe command used to accomplish this task is git clone.\nThe main purpose of cloning a repository is to setup a local repository that is an exact copy of a remote repository. This allows you to make changes and commits locally. You can always sync your local and remote repositories (git push \u0026 git pull).\nThere are a few ways to clone a repository. The simplest way is to grab the github project url and run the git clone command inside of your terminal.\nCopy Github Project URL Locate GitHub URL from your repository by hitting the green Code button and copying the link to your clipboard.\nNow open up a new terminal and navigate to the directory where you want the project to live. In the below example you will see that we are cloning the project into the Desktop directory.\n Warning make sure to replace /[your-github-user]/ with your own personal github username while also inside the directory where you want the project to live.\n  Run the command git clone https://github.com/[your-github-user]/py-demo-web-logs.git in the terminal.\nThis will create a new directory (inside of your current working directory) named py-demo-web-logs, initialize a local git repository (located in the .git directory) and copy all of the tracked files.\nIf you run the ls command you can see that the folder has been cloned:\n Bonus You can also clone a repository and provide it a new name should you ever wish to do so. You can accomplish this by adding the name you want the directory to be called at the end of the command: git clone https://github.com/[your-github-user]/py-demo-web-logs.git \u003cnewdirectoryname\u003e   Explore Cloned Local Files Now that you have cloned a repository onto your machine you can access the files locally. Take a look at what the py-demo-web-logs contains.\nNavigate into the newly cloned directory and run the ls command.\nYou will see that there is a main.py file located within.\nRecap: This walkthrough was a refresher on the following:\n Cloning a Repository  git clone https://github.com/git-repo-url     Note In the upcoming branching walkthrough we will be creating a new branch inside of this project directory and fixing a bug located within the main.py file of our py-demo-web-logs.\n  ","description":"","tags":null,"title":"Cloning a Repository","uri":"/git/walkthrough/cloning/"},{"content":"  Note You will be using py-demo-web-logs-rebase as the github repository for this walkthrough.\n  Merging with Git Rebase Rebase is another way to merge branches. The git rebase command will reapply commits from the current branch on top of the target branch.\nTo perform a git rebase the command is as follows:\ngit rebase [target-branch]\n Note You are rebasing the current branch on top of the [target-branch].\n  Repository Staged for Rebase  Fork this repository: https://github.com/LaunchCodeTechnicalTraining/py-demo-web-logs-rebase to your personal github account Clone the forked repo to your own machine: git clone https://github.com/[your-github-username]/py-demo-web-logs-rebase cd into the root folder of the project inside of your terminal  Perform the Rebase This project is currently staged for a git rebase. There has been a feature branch merged into the master branch already. In order to merge the remaining branch new-function into master we will need to resolve the merge conflicts within the main.py and .gitignore files.\nCheckout to the new-function branch and perform the git rebase:\nRun the following commands:\n git checkout new-function git rebase master  Rebase works by taking the original full history of the [target-branch] (in this case master) and builds each of the commits from the current working branch (in this case new-function) one at a time, adding to the history of the [target-branch].\n Bonus During rebase conflicts can come up at any point in time between the first commit and the last commit of the current working branch as the commits are being built in order.\n  Merge Conflicts You will receive a notification that there are merge conflicts in main.py and .gitignore and that the conflicts need to be resolved manually before continuing the rebase onto the master branch.\nThe output looked similar to:\nAuto-merging main.py CONFLICT (content): Merge conflict in main.py CONFLICT (add/add): Merge conflict in .gitingore Auto-merging .gitignore error: Failed to merge in the changes. Resolve all conflictrs manually, mark them as resolved with \"git add/rm \u003cconflicted_files\u003e\", then run \"git rebase --continue\" The output is telling us:\n Two Conflicts were detected in this commit: in main.py and in .gitignore It asks you to resolve the conflicts manually and mark them as resolved with the git add or git rm command After the conflicts have been resolved you can then run git rebase --continue.  Let’s resolve the conflicts so you can continue the rebase.\nResolve Conflicts  Open up the main.py file with vim:  Run the command vim main.py.\nGit Conflict Syntax Git is simply a tool. It cannot make decisions. When a conflict emerges git will inform you about the conflict, but leaves it up to you to resolve the conflict.\nLet’s take a look at the syntax git uses to inform us of conflicts:\n\u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD  with open(\"web.log\", \"w\") as tf:  tf.write(\"{}: {}@{}ip: {}home-dir: {}\".format(ts, user, hostname, local_ip, home_dir)) =======  with open(new_file_name, \"w\") as the_file:  the_file.write(\"{}: {}@{}ip: {}home-dir: {}\\n\".format(ts, user, hostname, local_ip, home_dir))  if __name__ == \"__main__\":  new_function(\"web-log.txt\") \u003e\u003e\u003e\u003e\u003e\u003e\u003e new feature Git needs to tell us where the conflict happens, and the two possible options:\n Option one is marked as \u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD indicating the conflicting section of the target branch (in this case master) Option two is marked as \u003e\u003e\u003e\u003e\u003e\u003e\u003e new feature indicating the conflicting section of the current working branch (in this case new feature which we are currently rebasing onto the target branch) They are delineated by seven equal signs (=======)  This conflict syntax is always used to show merge conflicts.\n Bonus Since git uses a consistent syntax to highlight merge conflicts many IDEs have built in functionality to find the unique syntax to further highlight the conflicts and provide you with options for choosing one or the other, or both. Following is the default behavior of Visual Studio Code when a git conflict has been detected:\nNotice VSC is adding in some colors, clarifying information about current change and incoming change, and provides buttons to assist with handling the conflict in the form of:\n Accept Current Change Accept Incoming Change Accept Both Changes Compare Changes  Options that will help the user decide which block of code they want to keep.\n  In the case of this example we will be aspects from both changes and will need to manually enter in our code and clear out any git conflict syntax (the \u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD, \u003e\u003e\u003e\u003e\u003e\u003e\u003e new feature, and =======).\nManually Resolving Conflict in main.py Paul and John both made changes to the main.py file. We need to decide which ones we want to keep and which to throw away.\nThe changes that we want to keep in this walkthrough include the following:\n function created in John’s solution name of file used in Paul’s solution (web.log)  After making the required changes to the file it should look similar to the above image.\n Write the changes and exit vim.   Warning Make sure to write the changes to the file before exiting vim!\n  Now that the conflicts have been resolved inside of the main.py file you need to resolve the conflicts inside of the .gitignore file.\nManually Resolving the Conflict in .gitignore Open the .gitignore file with vim.\nKnowing that web.log is the name of the file preferred you can remove everything else from the .gitignore file so that there are no conflicts.\nWrite the file and exit vim so that you are back inside of the py-web-logs-continued directory.\nStaging All conflicts have been resolved you will need to add the changes to staging so that you can continue the rebase onto master.\nRun the following commands:\n git status: check changes made git add .: add changes to staging   Bonus If you run the command git status after adding the changes to staging you will notice that it says “all conflicts fixed: run “git rebase --continue”.   Git Rebase --Continue Since you have added the changes to staging you can now continue the git rebase.\nRun the command git rebase --continue.\nThis tells git to continue the rebase by building additional commits from the current branch on top of the target branch. It will build any remaining commits and inform you of any detected git conflicts. After all of the commits have been successfully built and any conflicts have been resolved the rebase will complete.\n Note In this example there will be no additional conflicts so rebase should complete after running git rebase --continue.\n  Pushing Local Changes to Remote Branch You have completed a git rebase. If you run the command git status you will receive a notice that your branch and origin/new-function have diverged. This is because you rebased your local new-function branch onto the local master branch. Git is smart enough to detect that your local repository’s current working branches history has diverged from the remote repository’s branch of the same name. This is a good thing, this is what we were attending to accomplish with the rebase!\nIf you attempt to run the command git push origin new-function without force the push will be denied because the divergence in histories between your local and remote branches. Again git is detecting an issue and needs us to tell it which history we want it to keep. We can tell git to keep the history of the remote branch (pull), or the history of our local branch (push). In either case we will need to use the --force option to overwrite our local or the remote branch’s history.\nRun the command git push -f origin new-function.\nNow that the local changes have been pushed to the remote repository you should be able to merge the branch without conflict.\nOpen up the pull request from the new-function branch on your personal github account and merge the pull request!\n Warning You may need to change the base repository and base branch reference!\n   Click the Create pull request button. Click the Merge pull request button. Click the Confirm merge button. Click the Delete branch button.  You have successfully completed a git rebase!\nRecap:  Checkout to branch needing to be merged  Rebase the branch onto master with git rebase master Resolve merge conflicts Add changes to staging Continue rebase with git rebase --continue    ","description":"","tags":null,"title":"Git Rebase","uri":"/git/walkthrough/merging/git-rebase/"},{"content":"In this article we will configure our new virtual machine to use the Ubuntu .iso image we downloaded earlier. We will be configuring our virtual machine to use the .iso file as a CD simulating entering a CD with the file into the optical drive of this virtual machine.\nSetting up the Virtual Machine to use our ISO Image Click the settings wheel icon for the virtual machine we just created.\nThe settings wheel is a yellowish cog/gear icon. Upon clicking this icon you will see the student-VirtualBox - Settings window.\nStorage Click on the Storage Option located on the left side of the menu\nStorage View After clicking the storage option it will bring up the following view:\nEmpty Attributes Section Under Controller:IDE it says Empty. This is because we haven’t told the machine which ISO to use for this Virtual Machine. Click on the Empty section below the Controller: IDE.\n Note The icon is an image of a CD, indicating we are configuring this virtual machine to boot off of the files stored on the virtual optical drive.\n  Optical Drive On the right side under attributes you should now see an Optical Drive drop down, to the right of that is a disk icon button. Click the blue disc icon button and it will bring up a couple of options:\n Choose/Create a Virtual Optical Disk... Choose a disk file...  Click on the Choose a disk file... option.\nSelecting the Ubuntu ISO Upon clicking Choose a disk file your host OS will open the default file manager. Using that file manager you need to select the ubuntu-22.04-desktop-amd64.iso file you downloaded earlier.\n Note The location of the ubuntu-22.04-desktop-amd64.iso will likely be in a different location than the example image posted below. The file is likely located in your downloads folder. This image is an example of the default file manager on a Pop!_OS which is an Ubuntu derived distribution.\n  ISO added to Optical Drive You will now see that the Ubuntu ISO has been populated under the Controller:IDE section:\nYou have configured the virtual machine to use the virtual CD in the virtual optical drive. This way the new virtual machine (that doesn’t currently have an operating system) will boot from the Ubuntu .iso file which will allow you to configure Ubuntu on the virtual machine.\nNext Steps After completing the above instructions please move on to the next portion of the installation process located in the article below:\nStart the Virtual Machine\n","description":"","tags":null,"title":"Ubuntu ISO Image Setup","uri":"/configurations/ubuntu/ubuntu-iso-instructions/"},{"content":"React Initialization Script that Builds Artifacts Below you will find a working solution to a script that builds the required artifacts for the react-tic-tac-toe project.\nIn the previous sections we provided the build artifacts required to run the project. In the section below we build them within the script.\n  Click Here for Script  # Install Dependencies for React project  ## Update Package Repositories  sudo apt update -y  wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash  ## Install Git  sudo apt install git  ## Install Caddy  sudo apt install -y curl  sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo tee /etc/apt/trusted.gpg.d/caddy-stable.asc curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update -y sudo apt install caddy  ## Install nvm  export NVM_DIR=\"$([ -z \"${XDG_CONFIG_HOME-}\" ] \u0026\u0026 printf %s \"${HOME}/.nvm\" || printf %s \"${XDG_CONFIG_HOME}/nvm\")\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\"  ## install node and npm version 16.3.0 (version the project uses)  nvm install 16.3.0 nvm use 16.3.0  ## Cloning Repository to Local Machine  git clone https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-tutorial.git /home/student/Desktop/react-tic-tac-toe-tutorial  ### Load project dependencies inside of directory  cd /home/student/Desktop/react-tic-tac-toe-tutorial  npm i  ## Build dependences / Artifcats  npm run build  ## Move artifacts: Create a /website at root of server  sudo mkdir /website  mv /home/student/Desktop/react-tic-tac-toe-tutorial/build /website  ## Create a Caddyfile inside of /website and caddy reload  ( cat \u003c\u003c'EOF' https://localhost { root * /website/build file_server } EOF ) \u003e /website/Caddyfile  caddy reload --config /website/Caddyfile    ","description":"","tags":null,"title":"Bonus: Build Artifacts","uri":"/final-project/bonus-build-artifacts/"},{"content":"Visual Studio Code is a very popular text and code editor. It is graphical in nature, and does not offer a terminal version. However, due to it’s popularity let’s install it on our machines.\nThere isn’t an official Ubuntu repository for Visual Studio Code, however the Microsoft documentation provides an excellent article for installing VSC on Linux systems:\nThe picture above shows the exact steps for adding the repository, with gpg key, and then installing the code package.\n Bonus If you visit the actual article you will find there is another way to complete the steps in a more streamlined process.\n  ","description":"","tags":null,"title":"Bonus: VSC Installation","uri":"/package-manager/exercises/bonus-vsc/"},{"content":"Looping with Bash Similar to other programming languages like Java, JavaScript, and Python you are also able to write for loops in bash:\nBash Python JavaScript Java  for item in [LIST] do  [COMMANDS] done   for element in collection:  loop body   for (Virable Initialization; Loop Exit Condition; Variable Modification) {  loop body }   for (Variable Initialization; Loop Exit Condition; Variable Modification) {  loop body }     You can also write while loops:\nBash Python JavaScript Java  while [CONDITION] do  [COMMANDS] done   while condtion:  loop body   while (condition) {  loop body }   while (condition) {  loop body }      Note Notice that bash requires a closing done statement to end the loop.\n  Examples For Loop Create a new file called for-loop.sh\n#!/bin/bash  for string in \"Linux\" \"Microsoft\" \"Apple\" do  echo $string done Save the above code to the for-loop.sh file and exit the editor.\nRun the command bash for-loop.sh:\n Bonus You can also loop through an array of items:\n#!/bin/bash  OperatingSystem=(\"Linux\" \"Microsoft\" \"Apple\")  for string in ${OperatingSystem[@]} do  echo $string done    For Loop with Condition Create a new file called for-loop-if-else.sh\n#!/bin/bash  OperatingSystem=(\"Linux\" \"Microsoft\" \"Apple\")  for string in ${OperatingSystem[@]} do  if [[ $string == \"Linux\" ]]  then  echo $string: \"Open Source!\"  else  echo $string: \"Not Open Source : (\"  fi done Save the above code to the for-loop-if-else.sh file and exit the editor.\nRun the command bash for-loop-if-else.sh:\nWhile Loop Create a new file called while-loop.sh\n#!/bin/bash  number=0  while [ $number -lt 10 ] do  echo $number  ((number++)) done Save the above code to the while-loop.sh file and exit the editor.\nRun the command bash while-loop.sh:\nWhile Loop with Condition Create a new file called while-loop-if.sh\n#!/bin/bash  number=0  while [ $number -lt 10 ] do  echo $number  ((number++))  if [[ $number -eq 5 ]]  then  echo \"halfway done!\"  fi done Save the above code to the while-loop-if.sh file and exit the editor.\nRun the command bash while-loop-if.sh:\nRecap:  For loop  For loop with conditional statement   While loop  While loop with conditional statement    ","description":"","tags":null,"title":"Loops","uri":"/bash-scripting/walkthrough/loops/"},{"content":"Major Concepts \u0026 Key Terminology  STDIN: standard input STDOUT: standard output STDERR: standard error redirect STDOUT write \u003e redirect STDOUT append \u003e\u003e pipe operator |  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Bash: Streams, Redirection \u0026 Pipes","uri":"/bash-streams-redirection-pipe/"},{"content":"Redirect STDIN So far you have given bash commands input in two ways:\n as command arguments via converting STDOUT from a preceding command into STDIN using the pipe operator  These are the two ways you should expect to work with STDIN in this course.\nHowever, there are additional ways you can provide input to bash commands.\nSTDIN Redirection from Here String cat \u003c\u003c\u003c \"hello\" cat is concatenating the contents of the here string “hello”.\n Note This is identical to echo \"hello\". This example shows how a here string can be passed to a command as STDIN.\n  STDIN Redirection from File cat \u003c hello-from-bash.txt   Note The hello-from-bash.txt file was created in the Redirect STDOUT Append File article.\n  cat is concatenating the contents of the file hello-from-bash.txt\n Note This is identical to cat hello-from-bash.txt. This is example shows how a file can be passed to a command as STDIN.\n  You will not be expected to know here strings, or STDIN redirection from files in this course.\n","description":"","tags":null,"title":"Bonus: Redirect STDIN","uri":"/bash-streams-redirection-pipe/walkthrough/redirect-stdin/"},{"content":"Normal Mode to Insert Mode Open temp-file.txt:\nWhen opening a file, vim defaults to Normal mode.\nIn Normal mode commands can be given to vim. When content needs to be added the easiest option is to change from Normal mode to Insert mode.\nInsert mode will allow us to type directly into the file.\nYou can enter Insert mode from Normal mode by typing the i key:\nNote the text at the bottom of the terminal window changed to:\n-- INSERT -- When – INSERT – is seen at the bottom of the terminal window vim is in Insert mode.\n Note While vim is in Insert mode text can be typed directly into the file. This will be demonstrated in the next article.\n  Insert Mode to Normal Mode While in Insert mode (and most other modes) you can return back to Normal mode by hitting the escape (esc) key on your keyboard.\nTry it out and notice the change to the vim terminal window:\nTake note of the bottom of the vim terminal window, it does display – INSERT – any more indicating vim is back in Normal mode.\n Warning There are many modes in vim and it’s easy to wander into a mode you don’t understand when you are learning vim. The escape key is the best way to return back to Normal mode while in another mode. The escape key will cancel any in progress commands.\nYou may find yourself in an unfamiliar mode in the middle of a command, hitting escape will cancel the command, but you will need to hit escape again to return back to Normal mode. For this reason if you need to return back to Normal mode and are unsure of what’s currently happening you can simply hit the escape key two or three times.\n  ","description":"","tags":null,"title":"Changing Between Normal \u0026 Insert Modes","uri":"/userspace-applications/walkthrough/vim/changing-between-command-insert/"},{"content":"Articles Setup nginx.conf nginx -s reload Static Website Reverse Proxy  ","description":"","tags":null,"title":"NGINX","uri":"/web-server/nginx/"},{"content":"Configuring Caddy to Serve a Static Website A common task performed by a web server is to serve static websites.\nA static website only requires that the HTML, CSS, JS, and media files (like .jpgs) need to be served as a part of the HTTP Response.\nThe syntax for a Caddyfile meant to serve a static website will look similar to the following:\nlocalhost {  root * /absolute/path/to/build/artifact/directory  file_server } New Configuration File A Caddyfile can technically live anywhere on the machine. Some people opt to store all of their Caddyfiles in /etc/caddy. This is similar to the best practice used by the NGINX web server.\nAnother practice is to store a Caddyfile with the source code of a project. For this example we will be deploying the Orbit Report angular project built in LC101 unit 1. We will be creating a Caddyfile near the source code of this project.\n Warning The Caddyfile can be stored in any location as long as your path is pointing to the correct build artifacts for the application you would like to deploy. When running the command caddy reload you must be in the directory containing the Caddyfile you want to load.\n  Create New Caddyfile touch /home/student/Desktop/Caddyfile Validation:\nAdd Configuration to Caddyfile Using your preferred editor add the following configuration to the newly created Caddyfile:\nhttp://localhost {  root * /home/student/Desktop/orbit-report  file_server } Configuration breakdown:\n http://localhost: designated hostname and port to listen on  root * /home/student/Desktop/orbit-report: the root location for all requests coming to this server file_server: static file_server directive instructing Caddy to serve the files found in the root location as files for any incoming requests    Clone Build Artifacts The Caddyfile is expecting /home/student/Desktop/orbit-report to contain the artifacts (HTML, CSS, JS, media files) of this project.\nAs of now the directory doesn’t exist and the build artifacts are missing.\nLuckily the build artifacts are stored on GitHub.\nFrom your home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts From here you will want to move the contents of orbit-report-artifacts into /home/student/Desktop/orbit-report/.\nMove Build Artifacts to /home/student/Desktop/orbit-report Create /home/student/Desktop/orbit-report\nmkdir /home/student/Desktop/orbit-report Move all files in /home/student/orbit-report-artifacts/ into /home/student/Desktop/orbit-report:\nmv /home/student/orbit-report-artifacts/* /home/student/Desktop/orbit-report/ Check the contents of /home/student/Desktop/orbit-report:\nls /home/student/Desktop/orbit-report/ Validation:\nReload Configuration cd ~/Desktop caddy reload   Warning If Caddy is not currently running you will need to start the caddy service with systemctl like:\nsudo systemctl start caddy    Access Site Make a web request to localhost.\n","description":"","tags":null,"title":"Static Website","uri":"/web-server/caddy/static/"},{"content":"Configuring NGINX to Serve a Static Website A common task performed by a web server is to serve websites.\nSometimes the website to be served is a static website. A static website only requires that the HTML, CSS, JS, and media files (like .jpgs) need to be served as an HTTP Response.\nThe default configuration of NGINX includes an example of a static website configuration.\nThe NGINX configuration file can be found at /etc/nginx/conf.d/default.conf:\nserver {  listen 80;  server_name localhost;   location / {  root /usr/share/nginx/html;  index index.html index.htm;  }   error_page 500 502 503 504 /50x.html  location = /50x.html {  root /usr/share/nginx/html;  } Upon making an HTTP request to localhost the following HTML is returned:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e  body {  width: 35em;  margin: 0 auto;  font-family: Tahoma, Verdana, Arial, sans-serif;  } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration required.\u003c/p\u003e  \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr /\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e  \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Rendered in browser it looks like a normal webpage:\nEditing the Existing Static Website We can tap into the index.html file stored at the root of the default configuration file found at: /usr/share/nginx/html to change the file NGINX is serving.\nOpen /usr/share/nginx/html/index.html with your editor of choice.\nChange the contents of index.html to:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eMy Site!\u003c/title\u003e \u003cstyle\u003e  body {  width: 35em;  margin: 0 auto;  font-family: Tahoma, Verdana, Arial, sans-serif;  } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to my site!\u003c/h1\u003e \u003cp\u003eI am exploring how the HTML file can be changed, and NGINX will serve the changed file without skipping a beat.\u003c/p\u003e  \u003cp\u003eNGINX doesn't care about the contents inside of the file's it is serving, it is simply serving the files in the manner it is instructed.\u003c/p\u003e  \u003cp\u003e\u003cem\u003eBrought to you by [YOUR NAME HERE]!\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e   Note Make sure to substitute [YOUR NAME HERE] with your actual name!\n  After making the changes make sure to save the file!\nAfter make a new request to localhost.\n Warning It is likely that the web browser has cached the response from NGINX. You will need to force the browser to make a new web request and not simply load from the browser’s local cache. You can force the web browser to make a new web request with the hard refresh keyboard shortcut ctrl + shift + r.\n  Web browser output:\nCongratulations. You changed the HTML that NGINX is configured to serve.\n Note This is not the preferred way of working with NGINX. More realistically you will have already generated HTML/CSS/JS/media files that may have a complex file structure. In which case you will want to configure your own NGINX conf file.\n  New Configuration File A better practice than using the default.conf file is to create a new .conf file for the server that is being configured.\nIn this case let’s create a new .conf file for the Angular Orbit Report.\nDelete Original default.conf File First up, delete the original default.conf file. It has served its purpose.\nsudo rm /etc/nginx/conf.d/default.conf Validation:\nCreate New orbit-report.conf File sudo touch /etc/nginx/conf.d/orbit-report.conf Validation:\nAdd Configuration to orbit-report.conf Add the following configuration to orbit-report.conf:\nserver {  listen 80;  server_name localhost;   location / {  root /home/student/website/orbit-report;  index index.html;  } } Configuration breakdown:\n server: defining a new server in NGINX listen: the port the server is listening on (standard HTTP 80) server_name: the domain name, or IP address of the server (localhost) location /: URL path location directive, dictates how HTTP requests to the / (root) are handled  root: the location of the files to be served at the configured path index: the filename for any non-provided file paths (attached automatically by NGINX, never seen by the web user)     Note If you reload the nginx configuration file and make a request to localhost you would see a 404 Not Found error, because currently the directory /home/student/website/orbit-report/ does not have an index.html file.\n  Clone Build Artifacts NGINX is expecting /home/student/website/orbit-report/ to contain the artifacts (HTML, CSS, JS, media files), as of now the directory doesn’t exist and the build artifacts are missing.\nLuckily the build artifacts are stored on GitHub.\nFrom your home directory:\ngit clone https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts From here we will want to move the contents of orbit-report-artifacts into /home/student/website/orbit-report/.\nMove Build Artifacts to /home/student/website/orbit-report Create /home/student/website/orbit-report\nmkdir -p /home/student/website/orbit-report   Bonus The -p flag instructs the mkdir command to make any necessary parent directories in the path provided. In this case it’s likely that both website/ and /website/orbit-report are being created!\n  Move all files in /home/student/orbit-report-artifacts/ into /home/student/website/orbit-report:\nmv /home/student/orbit-report-artifacts/* /home/student/website/orbit-report/ Validation:\nReload Configuration sudo nginx -s reload Access Site Make a web request to localhost.\n","description":"","tags":null,"title":"Static Website","uri":"/web-server/nginx/static/"},{"content":"Exercises Service: Spring Todo MVC  Questions \u0026 Answers What is the purpose of systemd?   CLICK FOR ANSWER  Create and manage services.\n  What is systemctl?   CLICK FOR ANSWER  The CLI package that allows for managing services.\n  What is a unit file?   CLICK FOR ANSWER  A service definition file. It configures the service and dictates how the service behaves and how it is managed by systemd.\n  What are the five primary commands of systemctl introduced in this class?   CLICK FOR ANSWER   status start stop disable enable    Which of the five commands is necessary to view information about a given unit?   CLICK FOR ANSWER  status\n  Which of the five commands are necessary for managing a units state?   CLICK FOR ANSWER   start stop    Which of the five commands are necessary for controlling when a unit starts at a specific computer target?   CLICK FOR ANSWER   enable disable    What must be included in a unit file to start a service?   CLICK FOR ANSWER  [Service] ExecStart=valid command to start the service    What must be included in a unit file to configure a unit to restart on failure?   CLICK FOR ANSWER  [Service] Restart=on-failure    What must be included in a unit file to configure a unit to start at a specific computer target (like on boot)?   CLICK FOR ANSWER  [Install] WantedBy=some-defined.target    ","description":"","tags":null,"title":"Exercises","uri":"/systemd/exercises/"},{"content":"clear command Our next command also takes no arguments. clear will clear the terminal emulator of all text.\nEnter clear into your terminal.\nThen submit the command with enter.\nAll that text is gone! We now have a clean slate to continue working.\n Note Most future images in this course will clear the screen before running new commands.\n  ","description":"","tags":null,"title":"Bash Command: clear","uri":"/bash-introduction/walkthrough/clear/"},{"content":"Demo: Creating \u0026 Executing a Bash Script  Warning This file is written as instructions for an instructor-led demo. As a student you probably can work through this file on your own, but it does a few things that we haven’t learned or practiced yet. You very possibly could get stuck and will not receive guidance on moving through any issues you encounter. That being said, you can attempt this demo and work through the issues you encounter as practice for attempting to learn on your own and troubleshooting issues as they arise.\n  In this Demo your instructor will show you how to create and execute a bash script, how to add to the $PATH Shell Variable, and how to create a SymLink. This demo will also give a sneak peek into creating directories and files from the Bash shell.\nCreate Directory \u0026 File  mkdir /home/student/bin touch /home/student/bin/whattimeisit  Add the following text into the file. You may find nano to be useful, but feel free to edit the file however you want.\n#!/bin/bash  echo \"Hello Paul...\" echo \"It is currently $(date)\" echo \"Have a nice day!\" Execute the file using the Bash command  run the file: bash /home/student/bin/whattimeisit  Make the file executable \u0026 execute in new ways  make the file executable: chmod +x /home/student/bin/whattimeisit run the file: /home/student/bin/whattimeisit  or: ./bin/whattimeisit or: bash /home/student/bin/whattimeisit    Adding /home/student/bin to $PATH  what is the shells $PATH: echo $PATH update the PATH variable with our personal bin: PATH=$PATH:/home/student/bin check $PATH for the new information: echo $PATH  Execute the program directly from $PATH  whattimeisit  Rename file  what if I want to change the name of my program?  mv /home/student/bin/whattimeisit /home/student/bin/when    Run same program with new name  when can you run the old name? whattimeisit can you run it directly with bash? bash /home/student/bin/when  can you run it the other ways we tried above?    How can we view the absolute path of the when program?  what happens if we: which when  Does the when program have a man page?  what happens if we: man when  Symlink Where is python?  python comes standard as a part of most Linux distros which python –\u003e so where is it? which python3 –\u003e here it is (python 2 is dead and has been fully replaced by python3) –\u003e older versions of Ubuntu did have python which defaulted to Python2 \u0026 also had a version of Python3 installed.  Manually search for python3 in /usr/bin  ls /usr/bin  python should be here, manually search for it  why is python3 blue? why is there a python3.8 that is green?  when we made our Bash script executable it turned green are all executables green?        Take a deeper look at the file metadata   could do it manually with ls -l /usr/bin, but that would take a while\n  let’s use grep to search for the output we want instead: ls -l /usr/bin | grep python3\n  What is python3 -\u003e python3.8 representing? It looks like python3 is a shortcut to python3.8!\n what is a Symlink?  it really is just a shortcut soft link both python3 and python3.8 should execute the same program  Enter python3 --version \u0026 python3.8 --version  same program!        Edit our Bash script to be executable with a SymLink Change name back to whattimeisit  mv /home/student/bin/when /home/student/bin/whattimeisit  Create a SymLink pointing to whattimeisit named when  ln -s /home/student/bin/whattimeisit /home/student/bin/when look at the contents of the /home/student/bin directory: ls -l /home/student/bin  How can we run the program?  whattimeisit when  This explains what Python3 is in /usr/bin – just a symlink pointing at the actual python3.8 interpreter!\n Note In Ubuntu the color scheme of STDOUT is helpful. Green files are executable, light blue files are SymLinks, dark blue files are directories, white files are standard files. Not all terminal emulators support color, but it is quite useful when it is around.\n  ","description":"","tags":null,"title":"Demo","uri":"/bash-introduction/demo/"},{"content":"Additional Resources If you would like to dig deeper into Cron you may find the following resources beneficial:\n Cron Manual Page Crontab Manual Page “Crontab” in Linux - GeeksforGeeks Cron Wikipedia Page  ","description":"","tags":null,"title":"Next Steps","uri":"/cron/next-steps/"},{"content":"Exercises New Project Bonus: Git Revert  Questions \u0026 Answers What is git?   CLICK FOR ANSWER  Distributed version control software.\n  What is a local git repository?   CLICK FOR ANSWER  A git repository that lives on your local computer.\nDevelopment happens in local git repositories.\n  What is a remote git repository?   CLICK FOR ANSWER  A git repository that lives on a team accessible remote server.\nCode sharing and collaboration happens in remote git repositories.\nMany remote git repos are hosted by Git hosting organizations like GitHub, Gitlab, or Bitbucket.\n  When changes (commits) are made to a local repo how can the remote repo be updated?   CLICK FOR ANSWER  git push    When changes (commits) are made to a remote repo how can the local repo be updated?   CLICK FOR ANSWER  git pull    What is the command to create a new local git repository from an existing directory?   CLICK FOR ANSWER  git init This command will create a local git repository in the directory where it is invoked, resulting in a new hidden folder called .git.\n  How can a new remote repository be created?   CLICK FOR ANSWER  It varies by Git Remote repo manager (GitHub, Gitlab, BitBucket), but usually consists of working through a Web based GUI to name and create a new remote repo.\n  What is the command to add a remote repo to a local repo?   CLICK FOR ANSWER  git remote add [remote-name] [remote-URI]    What are the steps of the basic git workflow?   CLICK FOR ANSWER   stage commit push  git add files-to-be-committed git commit -m \"commit message title\" -m \"commit message body\" git push    What is forking a remote repository?   CLICK FOR ANSWER  Creating a copy of a remote repository you don’t control to a remote repository you do control. The forked relationship allows you make changes to your remote repo and suggest them as changes to the remote repo you don’t control.\n  How do you fork a remote repository?   CLICK FOR ANSWER  It varies by Git remote repo manager, but usually there is a fork button and web GUI to guide the process.\n  What is cloning a remote repository?   CLICK FOR ANSWER  Cloning a remote repo creates a brand new directory and local git repo onto your local computer from the existing remote repo.\nIn addition to copying all repo files (including the .git folder) it automatically adds a new remote to the local repo using the URI of the cloned location.\n  How do you clone a remote repository?   CLICK FOR ANSWER  git clone [remote-repo-URI] A web address (URL) like https://github.com/LaunchCodeTechnicalTraining/linux is a valid remote repo URI that can be used with git clone.\n  What is a branch?   CLICK FOR ANSWER  A branch is an independent line of development.\nA new branch is a copy of an existing branch with the full set of files, and history. Changes can be made to files and new commits can be added without altering the files or history of the original branch.\nThis gives you the ability to add new work in a safe environment.\n  What is the command to create a new branch?   CLICK FOR ANSWER  git branch [new-branch-name]    What is the command to change into an existing branch?   CLICK FOR ANSWER  git checkout [existing-branch-name]    What is the command to both create and change into a new branch?   CLICK FOR ANSWER  git checkout -b [new-branch-name]    What is a merge?   CLICK FOR ANSWER  A merge is a combination of two branches.\nThe files and histories need to be merged together so file changes and histories can be combined as the new history of the project.\n  What is a merge conflict?   CLICK FOR ANSWER  A merge conflict is when two merging branches have conflicting information between the contents of a file.\nBoth branches would have to change the same line of the same file in different ways to create a conflict.\nConflicts must be manually resolved before the merge can be considered complete.\n  What are the two merge strategies introduced in this course?   CLICK FOR ANSWER  Traditional merge and rebase.\n  ","description":"","tags":null,"title":"Exercises","uri":"/git/exercises/"},{"content":"Exercises Install the packages in the following articles:\nExisting Package Repositories Caddy Installation NGINX Installation Bonus: VSC Installation   Note The Visual Studio Code (VSC) installation is optional.\n  Questions \u0026 Answers What is a package?   CLICK FOR ANSWER  A package is software and related metadata.\n  What is a package repository?   CLICK FOR ANSWER  A package repository is the web address where the package files can be downloaded.\n  What is a package manager?   CLICK FOR ANSWER  A package manager is a tool that is used to manage packages. There are commonly CLI and GUI programs for interfacing with a Linux distributions underlying package management system.\n  What is the package manager for Ubuntu that we learned in this course?   CLICK FOR ANSWER  We learned about the Advanced Packaging Tool known as apt.\n  How can you learn more about the apt CLI?   CLICK FOR ANSWER  Three ways:\n man apt apt --help Searching the internet for assistance (reading the apt online documentation)    How can you list all package repositories?   CLICK FOR ANSWER  apt list\n  What is the source of the package repositories?   CLICK FOR ANSWER  /etc/apt\n  How do you update the package repositories?   CLICK FOR ANSWER  sudo apt update\n  How can you view all installed packages?   CLICK FOR ANSWER  apt list --installed\n  How can you view the metadata for any specific package?   CLICK FOR ANSWER  apt show [package-name]\n  Using apt how do you find packages?   CLICK FOR ANSWER  apt search [package-name]\n  Using the internet how do you find packages?   CLICK FOR ANSWER  Use a search engine! A common phrase for finding valid articles: [package-name] Ubuntu Installation.\n  How do you install packages with apt?   CLICK FOR ANSWER  sudo apt install [package-name]\n  How do you remove packages with apt?   CLICK FOR ANSWER  sudo apt remove [package-name]\n  How do you upgrade all installed packages?   CLICK FOR ANSWER  sudo apt upgrade -y\n  What would including the -y option when using apt accomplish?   CLICK FOR ANSWER  It would auto confirm the apt action being performed including: updating, installing, removing, upgrading.\n  ","description":"","tags":null,"title":"Exercises","uri":"/package-manager/exercises/"},{"content":"Being able to access the metadata of package can be useful. This article shows how to view all currently installed packages, and how to look at some of the metadata associated with any specific installed package.\nViewing All Installed Packages Enter: apt list --installed\nThere are so many installed packages that they cannot be displayed within one Bash shell session.\n Note It’s pretty rare you would need to see all of the installed packages on a machine. It is much more informative to look at the metadata for a specific package.\n  Viewing a Specific Package You can use the apt show command to view some of the metadata, and OS level configuration information about any specific package. The structure for this command is: apt show [package]. Go ahead and try it out on a couple of different packages\nEnter apt show apt Enter apt show bash Enter apt show python3 Package Metadata Breakdown Each of the examples listed above show a ton of different metadata including:\n Package: The name of the package Version: The version of the currently installed package OS Priority: If this package is required for the current distribution to operate normally Origin: The party that controls the package Maintainer: The party that maintains the package Depends: All the packages this specific package needs to function properly Suggests: Additional related packages you may want to use in addition to this package Description: What the package is used for   Note All of this metadata simply describes the package. However to learn how to use the package you should look at the package homepage, the man reference page, or the --help option.\n  ","description":"","tags":null,"title":"Reading Packages","uri":"/package-manager/walkthrough/read-packages/"},{"content":"There are tons of userspace applications. It would be impossible to know of all of them.\nMany userspace applications were presented in this class really everything introduced, with the exception of the filesystem are technically userspace applications.\nResearching and practicing are the ways you can learn and become comfortable with userspace applications.\nGNU offers many free, open source packages most of which are userspace applications.\nGNU resource links  GNU Software Homepage GNU Package Blurbs GNU Package Documentation Links  Not everything in this class was a GNU package. We also used other software from different organizations. Many of the chapters of this book contain a Next Steps article pointing you towards official documentation.\nvimtutor The vim package comes with a package called vimtutor which is an interactive tool for advancing your vim skills.\nFinding Additional Userspace Applications There is no manifest of all possible userspace applications. So you have to discover them on your own.\nStrategies for discovering additional software:\n Talk to other technologists  what tools do they use on the job? what tools have they heard of that they want to learn? what tools are they actively learning? what are the purposes of those tools? what are unique problems they had to solve using various tools?   Join technologist communities  local meetups online meetups social media tech groups   Subscribe to mailing lists or RSS feeds Attend Tech conferences Research alternatives to tools you already know  Web Servers: this class introduced NGINX and Caddy, research alternatives Task scheduling: this class introduced cron, research alternatives Service creation and management: this class introduced systemd, research alternatives Package Manager: this class introduced apt, research alternatives    ","description":"","tags":null,"title":"Next Steps","uri":"/userspace-applications/next-steps/"},{"content":"Questions and Answers How do you run a substitute command with sed?   Click Here for Answer  sed 's/word-or-phrase-to-replace/replacement-word-or-phrase/' file-name    How do you use the substitute command to add additional text?   Click Here for Answer  sed 's/word-or-phrase/\u0026 additional-text-to-add/' file-name    Working with the user.csv Dataset Using the user.csv Dataset complete the following requirements:\n Note If you need to get the user.csv Dataset again you can do so with the following command:\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e user.csv    Substitute all employers by the name of Hunter Engineering for LaunchCode\n  Click Here for Solution  sed 's/Hunter Engineering/LaunchCode/' user.csv    Add the additional text “: Kansas City” to all users employed at VMLY\u0026R\n  Click Here for Solution  sed 's/VMLY\u0026R/\u0026: Kansas City/' user.csv    Substitute all email signatures (@example.org, @example.net, @example.com) for @launchcode.org\n  Click Here for Solution  sed 's/\\(@example.org\\|@example.net\\|@example.com\\)/@launchcode.org/' user.csv \u003e launchcode-emails.csv or\nsed 's/@example.org/@launchcode.org/' user.csv | sed 's/@example.net/@launchcode.org/' | sed 's/@example.com/@launchcode.org/' \u003e all-launchcode-emails.csv    ","description":"","tags":null,"title":"Sed Exercises","uri":"/userspace-applications/exercises/sed/"},{"content":"Bonus Exercise In the previous Bash: Introduction - Demo article the instructor presented a demo consisting of:\n Creating a new bin directory in the current user’s home directory Creating a new bash file called whattimeisit Adding the shebang (#!/bin/bash) instructing the OS to run the file using the bash interpreter on the first line Adding three separate echo commands to the bash file Saving and exiting the file executing the bash file using the bash command adding executable permissions to the file executing the bash file by invoking the name both using a relative path and an absolute path  These are all steps you can now perform with your new found Bash: File System Navigation and File/Directory CRUD skills!\nAdditional Bonus You can also complete the rest of the steps from the Bash: Introduction - Demo.\n Note You are not expected to know about manually changing the $PATH shell variable, Symlinks, or how to use the ln command, but you can do your own research to learn about these concepts and commands. Being able to look up and use various commands is a very important skill to develop within the tech industry!\n  General Steps  add the /home/student/bin directory to the $PATH variable create a symlink named when that points at the whattimeisit bash script invoke both when and whattimeisit to show how they work  Additional Bonus: Question \u0026 Answer What happens if you close your terminal and try to run when and whattimeisit?   CLICK FOR ANSWER  The when and whattimeisit commands no longer work! Check the path of this new Bash session with echo $PATH. You will notice the /home/student/bin is no longer on the Path variable.\nWhen we manually added the /home/student/bin directory to our Path variable, we were only adding it for the current Bash session. There are many ways you can add this directory to the $PATH permanently. However, the best solution would be to add the line specifically to your ~/.bashrc user profile. That way this specific directory of programs is only added for the student user.\nYou could simply add export PATH=\"$PATH\":/home/student/bin to the bottom of your ~/.bashrc file. Now every time a new Bash shell is opened by the student user the /home/student/bin is added to the global path that is initially set for all users.\nTry it out by closing and opening a new terminal and then echo $PATH.\n  ","description":"","tags":null,"title":"Bonus","uri":"/file-system/exercises/bonus/"},{"content":"Deleting Files and Directories Let’s learn how to Delete files and directories.\nThe rm command You can remove files and directories with the remove (rm) command.\nYou simply provide the remove target as the argument for the rm command.\nLet’s create a new temporary file and then delete it with rm.\ntouch temporary.file After executing the ls command you can see that a new file named temporary.file was created from the touch command.\nrm temporary.file Let’s get rid of that file with the rm command.\nAnd the file is gone!\n Bonus In an earlier walkthrough we created a file named temp.file. Feel free to remove that file as we won’t be using it again!   Delete Recursively The rm command works on both files and directories. However the rm command can only delete an empty directory. Usually when we choose to delete a directory we want to delete all of the contents in the directory as well.\nLuckily, there is a recursive option that will remove all of the items inside of directory before deleting the directory itself, it’s the -r option. Let’s try it out.\nCreate a directory: mkdir temp-dir Add file to new directory: touch temp-dir/temp.file Delete directory without recursive option: rm temp-dir Delete directory recursively: rm -r temp-dir/ Since our user student has full permissions of the temp-dir/temp.file our Bash shell deleted the file without asking. In instances where the file is write-protected the Bash shell will ask for confirmation before deleting any files while using the -r option.\n Bonus The following image shows a read-only file. Notice the beginning of the second line: -r--r--r-- indicating the file owner, group, and everyone else only has read access to the file. Write access and Execute access would be represented by the letter w and x respectively. When we go to delete the directory recursively, the Bash shell will ask for permission before deleting this write protected file. We will not cover modifying file permissions in this lesson. But you can read about the chmod command to get a sense of how the temp.file came to have only read access for all users.\n   Bonus In an early section of this course we created a temp directory in our home directory. Feel free to delete it using your newfound rm -r skills!\n  Delete Recursively with Force! In some instances there may be many write-protected files in a directory. It would be tedious to manually hit enter for each write protected file that needs to be deleted. There is another option called force -f that will delete the file(s) without checking the write protected status of the individual pieces.\nWe recommend throughout this course that you manually go through the process of approving the deletion of write protected files, except when instructed not to.\n Warning Linux will do what you tell it. If you tell it to delete a directory recursively with force it will not ask again. Many horror stories exist around people accidentally running rm -rf against their entire home directory and losing all of their files. Even worse targeting the root directory which would effectively delete the entire OS…\n  ","description":"","tags":null,"title":"Deleting Files \u0026 Directories","uri":"/file-system/walkthrough/deleting/"},{"content":"Exercises Create Hidden Notes Bash Alias Finding Files Bonus  ","description":"","tags":null,"title":"Exercises","uri":"/file-system/exercises/"},{"content":"Regular Expression Sets: [] You may not want to match every character, but a large number of specific characters. RegEx gives you the ability to match any character in a given set by using the special bracket characters [].\nFor example:\n match any lowercase letter [a-z] match any uppercase letter [A-Z] match any single digit [0-9] match a comma, period, or semicolon [,.;] match any case letter and the numbers 1-5 [a-zA-Z1-5]  You can build whatever set fits your specific needs.\nMatch '3[0-9] Match any two digit number starting with 3.\ngrep '3[0-9]' user.csv Output:\nMatch '3[5-9]' Match the numbers 35, 36, 37, 38 and 39.\ngrep '3[5-9]' user.csv Match '^Paul,[A-F]' Match the beginning of the line, then exactly Paul, and then any uppercase letter between A and F.\ngrep '^Paul,[A-F]' user.csv  Note RegEx sets give you fine tuned control over what can and cannot be matched.\n   Bonus You can also define an exclusion set in RegEx.\nMatch the beginning of the line, then any character not in A, E, I, O, U.\ngrep '^[^AEIOU]' user.csv The exclusion group symbol is a set with the ^ character. Making it very similar to the begin line anchor ^.\n  ","description":"","tags":null,"title":"Regex: Matching Set","uri":"/userspace-applications/walkthrough/grep/regex-set/"},{"content":"Name  sed - stream editor for filtering and transforming text\n Purpose Edit streams of text allowing entire text files to be filtered, or transformed in any number of ways.\nUsage  search and replace add content before or after specific patterns delete lines add lines  Like many of the Userspace Applications introduced in this course we will only be covering a small portion of what you can do with the tool.\nIn the case of sed we will simply be showing you how to use the substitute feature. You have likely used a similar feature in other software called Find \u0026 Replace.\nsed Command Pattern sed '[script]' 'input-file' sed Substitute Syntax sed 's/regex-pattern/replacement-text/flags' 'input-file'  s: the action sed will be performing, this case a substitute action regex-pattern: a regular expression sed should search each line for replacement-text: the text to replace the regular expression with flags: which matching section(s) should be replaced  Substitute Flags  N: Only the Nth matched pattern of the line should be replaced g: All matched patterns of the line should be replaced   Note If you do not include a substitute flag it will default to 1, so only the first matched pattern on the line will be replaced.\n  Setup This and the following articles use the user-data.csv file.\nIf you don’t already have the user-data.csv file in your home directory run the following command:\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e ~/user-data.csv   Bonus You can validate the user-data.csv file with the following command:\nwc -l ~/user-data.csv The output you see should confirm there are 25001 lines in the file.\n  sed substitute First Occurrence of 'a' with 'q'  Warning All commands in this and following articles assume your current working directory is the directory where the user-data.csv file resides, most likely your home directory.\nYou can change into your home directory from anywhere with the command:\ncd    Replace the first a in each line with q:\nsed 's/a/q/1' user-data.csv Output:\nLooking at the last record displayed in STDOUT:\nKristy,Strong,nwilliqms@example.com,Hunter Engineering\nIt looks like nwilliams was changed to nwilliqms. Take a look at the other lines to notice that the first instance of each a character was replaced with a q character.\n Note STDOUT shows the substitution that was made, however sed does not edit the original file by default. You would need to instruct sed to save the changes by writing STDOUT to a file with the redirection operator (\u003e) or use the -i option. Both of these options for saving changes will be covered in future sections.\n  sed substitute All Occurrences of 'a' with 'q' Replace all occurrences of a with q:\nsed 's/a/q/g' user-data.csv Output:\nThe last record: Kristy,Strong,nwilliams@example.org,Hunter Engineering was changed to: Kristy,Strong,nwilliqms@exqmple.org,Hunter Engineering\n","description":"","tags":null,"title":"sed","uri":"/userspace-applications/walkthrough/sed/"},{"content":"Setup Clone git clone https://github.com/LaunchCodeTechnicalTraining/bash-garbage-collector Review Source Code ls bash-garbage-collector cat bash-garbage-collector/empty.sh #!/bin/bash  dir=/home/student/bash-garbage-collector/trash log=/home/student/bash-garbage-collector/garbage.log  while true do  if [[ $(ls $dir) == \"\" ]]  then  echo \"$(date): no contents detected in $dir\" \u003e\u003e $log  else  echo \"$(date): contents detected in $dir...emptying\" \u003e\u003e $log  rm $dir/*  fi  sleep 30 done A simple script that checks the contents of /home/student/bash-garbage-collector/trash every 30 seconds. If contents exist at the location it logs that contents were detected and deletes the contents. If contents were not detected it simply logs that no contents were found.\nRun Script From the project directory run:\nbash empty.sh Feel free to add files to /home/student/bash-garbage-collector/trash after 30 seconds check the contents of /home/student/bash-garbage-collector/garbage.log and the trash/ directory to see the effects of the script.\nStop Script The script can be stopped by entering ctrl + c to send the interrupt signal to the running process.\nCreate Unit File This bash script can be converted into a systemd service by creating a valid unit file. After creating the unit file the service will be controllable with the systemctl tool.\nCreate a file in /etc/systemd/system/ called bash-garbage-collector.service as the root user:\nsudo touch /etc/systemd/system/bash-garbage-collector.service Add the following contents to the file using your editor of choice (make sure you are still acting as the root user):\n[Unit] Description=An awesome bash garbage collector (files in a certain directory)  [Service] ExecStart=/usr/bin/bash /home/student/bash-garbage-collector/empty.sh Restart=never  [Install] WantedBy=multi-user.target Breakdown:\n Description: the human readable description of the service ExecStart: The command invoked when the service is started (in this case /usr/bin/bash is being used to execute /home/student/bash-garbage-collector/empty.sh) Restart: Instructions on how and when the service should restart (in this case never). WantedBy: The system level in which the service should be initialized if enabled (in this case just before the user login screen appears (a multi-user environment has been reached))  Service Control via systemctl Start sudo systemctl start bash-garbage-collector After starting the service add contents to /home/student/bash-garbage-collector/trash wait 30 seconds and see how the directory and the garbage.log are affected.\nStop sudo systemctl stop bash-garbage-collector After stopping the service the garbage collector is no longer running.\nEnable sudo systemctl enable bash-garbage-collector After enabling the service the garbage collector should start when the machine reboots.\n Note You can reboot your virtual machine in many ways. The easiest is with the reboot command. After rebooting check the status of the service, and look over the contents of the bash-garbage-collector/ directory.\n  Disable sudo systemctl disable bash-garbage-collector After disabling the service it will no longer start when the computer starts.\nService Failure Right now the service file instructs systemd to never restart the running service. Even if the service fails and stops running systemd will leave it in a stopped state.\nThis can be tested by starting, and finding the PID of the service:\nsystemctl status bash-garbage-collector Output:\nMain PID: 556 (bash) Simulate Failure with kill  Warning The PID (process id) will be a different number on your virtual machine. When entering the next command make sure to use the PID of your specific service file!\n  We can simulate a failure by sending a SIGKILL signal with the kill command:\nsudo kill -9 [YOUR-SERVICE-PID] Check Status After simulating a catrastophic failure check the status of the service:\nsystemctl status bash-garbage-collector Configure Service to Restart on Failure systemd can be told to restart a service when it fails. Change the Restart section of the /etc/systemd/system/bash-garbage-collector.service file to:\nRestart=on-failure Now systemd knows to restart the service when it has experienced a failure.\nStop and Start Service After making a change to a unit file you will need to stop and start the service again.\n Note In some instances, depending on the state of the service when a change was made to the service’s underlying unit file, the systemd tool may need to be restarted. If this is required your terminal will let you know, and will ask you to execute a command similar to:\nsudo systemctl daemon-reload If you see this, make sure to do it so that the change to the underlying unit file is loaded into systemd properly.\n  Kill again Find the PID of the service again and kill it with a SIGKILL signal (-9).\nCheck the status of the service. Take note of the new PID the service was assigned when it was restarted.\n","description":"","tags":null,"title":"Bash Unit File","uri":"/systemd/walkthrough/bash-unit-file/"},{"content":"Branching Working with branches allows you to diverge from the master branch of development.\nWorking on a branch separate from the master branch provides many benefits. One of which is to create, read, update, and delete content without breaking anything on the master branch.\nIn the Git Branches walkthrough you will be doing the following:\n Creating new branches with git branch Changing branches with git checkout Fixing existing bugs  staging changes with git add and git commit   Pushing changes to remote repositories with git push  Content Links Creating Branches Changing Branches Staging Changes   Note The walkthrough articles in this section will be using the py-demo-web-logs repository you cloned in the Review: Basic Git Workflow.\n  ","description":"","tags":null,"title":"Git Branches","uri":"/git/walkthrough/git-branching/"},{"content":"Staging, Committing \u0026 Pushing Now that you have made changes on a new branch this would be a great place to stage, commit and push the changes. You can then open a new pull request so the changes introduced in the bug-fix branch can be incorporated into the master branch.\n git status: Check that there have been changes made git add . or git add [file-name]: Add the changes to staging git commit -m \"commit message\": Commit the changes git push origin bug-fix: Push updated local branch to remote repo Submit a pull request and merge the bug-fix branch into the master branch.  ","description":"","tags":null,"title":"Staging Changes","uri":"/git/walkthrough/git-branching/staging/"},{"content":"Starting the Virtual Machine Within the VirtualBox Manager window click on the virtual machine so that it is highlighted and then click the green Start button.\n Bonus You may notice the options within the dropdown next to the start arrow, the options are normal start, headless, and detachable start. During this course we will always be using the normal start. Without doing so you will not have access to the GUI. To learn more about headless starts which are common, refer to the Headless Software Wikipedia Article.\n  First Time Start The first time you start your machine it will load the .iso file in the virtual optical drive, which will trigger a new installation of Ubuntu. As it is setting up this installation you will see quite a few different screens, one of which will look similar to the following image:\nPossible Install Error  Warning If the image is not set properly you will see the following error when you try to start the Virtual Machine: If you see this error you misconfigured your ISO image. Please repeat the steps from the above section.   Installing Ubuntu (First Time Setup) Once the installation wizard has finished setting up, you will see a a screen with the option to select your language. It will more than likely default to the language associated with your host operating system (English US).\nAfter confirming, or selecting, your language of choice click the Install Ubuntu button underneath the laptop icon\n Warning Do not click “Try Ubuntu”. This would get you into the machine quickly, however none of your work would be saved and would all be deleted after you shut down the virtual machine the first time.\n  Keyboard Layout Select your Keyboard layout (keep default, unless you use a non english keyboard).\nAfter selecting your keyboard layout click continue.\nUpdates and other Software Select the Minimal installation. This will lower the amount of space taken up by software on the Virtual Machine.\nSelect Download updates while installing Ubuntu. As it mentions this will save time after installation.\nClick Continue.\nInstallation Type For the Installation type you should select: Erase disk and install Ubuntu.\n Note If you can see that an Operating System has been detected that means you did not select VDI (Virtual Disk Image) in the Virtaul Machine Hard Disk portion of this setup. If this is the case you will need to recreate your Virtual Machine.\n  Click the Install Now button.\nWrite Changes to Disks This popup is notifying us of the changes we are making to the Virtual Disk Image.\nClick the Continue button.\nSelecting your Timezone Select your Timezone (this option should default automatically).\nClick the Continue button.\nWho are you? This is the section where you will provide the user settings to the new operating system.\nUse the following:\n Your name: student Your computer’s name: student-VirtualBox Pick a username: student Choose a password: admin Confirm your password: admin select: require my password to log in (default)  User Settings Review Double check your input before continuing.\nAfter you review your settings and all form fields are filled out click the Continue button.\nWelcome to Ubuntu The setup for your Virtual Machine with a Ubuntu operating system is now complete. All that is left is to do is let the operating system finish its own configuration and then to log in!\nInstallation Complete Once you receive a notification that the installation is complete you can click the Restart Now button.\nClicking Restart Now will not restart your host operating system, it will only restart the virtual machine that we just configured.\nSystem Restart After clicking the restart now button the virtual machine operating system will restart and you should see something similar to the image below:\nInstallation Medium You will notice that it is asking you to remove the installation medium and then press enter. The virtual machine thinks we used an optical CD drive to install Ubuntu. We did use a virtual optical drive, but don’t need to actually remove anything. You could go through the steps of removing the virtual CD from the virtual optical drive, but it is not necessary and we will not provide the steps for completing this.\nYou can press the enter key when you reach this page.\n Note Often times when someone is installing Ubuntu or any other Linux distribution on a new machine they will use a USB drive or CD. Once the operating system has been installed it asks that you remove the installation medium (the USB drive) so that it wont ever reboot or start up and go into installation mode again.\n  Review You successfully started your virtual machine and completed the installation of Ubuntu operating system on this machine. The next article will take you through logging in for the first time, and completing any remaining first time login steps.\n","description":"","tags":null,"title":"Start the Virtual Machine \u0026 Complete Ubuntu Setup","uri":"/configurations/ubuntu/first-time-start/"},{"content":"Redeployment Script Below you will find a script that can be run inside of the react-tic-tac-toe project.\nThe script accomplishes a few things:\n Compares the local and remote branch to one another Appends a message to a deploy Rebuilds the project if there are changes that were merged   Note This is not a common way to redeploy projects nor rebuild them. This is meant to serve as a fun way to manipulate the .git directory within any given project.\n    Click Here for Script  ## Change into react-tic-tac-toe project directory (your directory location may vary) cd ~/Desktop/react-tic-tac-toe-tutorial  git fetch  remote_head=$(sed 's/\\t.*$//' .git/FETCH_HEAD) local_head=$(cat .git/refs/heads/master)  ## Compare remote and local branch if [[ $remote_head == $local_head ]] then \techo \"$(date):Commit histories are the same, no changes detected\" \u003e\u003e ~/Desktop/react-deploy.log  else \tgit merge \t## build project \texport NVM_DIR=\"$([ -z \"${XDG_CONFIG_HOME-}\" ] \u0026\u0026 printf %s \"${HOME}/.nvm\" || printf %s \"${XDG_CONFIG_HOME}/nvm\")\" \t[ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" \tnvm install 16.3.0 \tnvm use 16.3.0 \tnpm i \tnpm run build \trm -rf ~/Desktop/build \tmv build/ ~/Desktop \techo \"$(date):Changes have been detected, project rebuilt and redeployed\" \u003e\u003e ~/Desktop/react-deploy.log fi    ","description":"","tags":null,"title":"Bonus: Redeployment Script","uri":"/final-project/bonus-redeployment-script/"},{"content":"Combinig Concepts Now that you have learned how to create write a basic bash script, assign values to variables, write conditional and loop statements lets combine them all into one script!\nCreate a new file called high-low.sh\n#!/bin/bash  ## Create new ArrayList high_low=(15 10 -3 5 23 -5)  ## Loop through ArrayList for item in ${high_low[@]} do ## Compare item in list to current high_value \tif [[ $item -gt $high_value ]] \tthen \thigh_value=$item \tfi ## Compare item in list to current low_value \tif [[ $item -lt $low_value ]] \tthen \tlow_value=$item \tfi done  ## echo items to stdout and redirect: append the results into a new file echo \"The highest value is: \"$high_value \u003e\u003e high-values.txt echo \"The lowest value is: \"$low_value \u003e\u003e low-values.txt Add the above code to the file:\nRun the command bash high-low.sh\n","description":"","tags":null,"title":"Bring it All Together","uri":"/bash-scripting/walkthrough/bring-it-together/"},{"content":"Standard Error Output stream used to display error messages.\nExample  broken bash command with a redirect into error.log file  Redirect STDERR By default any error messages in STDERR are sent to the terminal window of the CLI shell.\ncat non-existent-file.txt Output:\ncat: non-existent-file.txt: No such file or directory Redirect STDERR Write STDERR can be redirected and written, or appended to a file similar to STDOUT, by using the write file 2\u003e and append file 2\u003e\u003e redirection operators.\ncat non-existent-file.txt 2\u003e cat-error.log Output:\ncat-error.log \u0026\u0026 ls \u0026\u0026 cat cat-error.log output\"\nRedirect STDERR Append cat different-file.txt 2\u003e\u003e cat-error.log Output:\n Note You are not expected to know how to redirect STDERR in this course.\n  ","description":"","tags":null,"title":"Bonus: Redirect STDERR","uri":"/bash-streams-redirection-pipe/walkthrough/redirect-stderr/"},{"content":"Edit File The most common way to edit the contents of a file is in Insert mode.\nOpen temp-file.txt\nEnter Insert mode by typing i in Normal mode:\nIn Insert mode type your content:\nWhile in Insert mode your keyboard presses are redirected to the contents of the file.\nFile Navigation in Insert Mode While in Insert mode the cursor can be controlled with the directional arrow keys on your keyboard.\nTry using the directional arrow keys to move your cursor over text. I will move the cursor after the period of the third paragraph:\nAfter navigating to the new position you enter more text at the location of the cursor:\n Note Navigation is possible in Insert mode, but is cumbersome. Luckily there are more effective ways to navigate the file while in Normal mode. This will be covered in a future article.\n  Deleting Content in Insert Mode While in vim Insert mode text can be deleted by using the backspace or delete keys. These keys behave the same way as they do in other text editors:\n","description":"","tags":null,"title":"Insert Mode: Edit File","uri":"/userspace-applications/walkthrough/vim/insert-edit-file/"},{"content":"Caddy Practice:  React java/Spring Boot C#/.NET  NGINX Practice:  React java/Spring Boot C#/.NET  ","description":"","tags":null,"title":"Exercises","uri":"/web-server/exercises/"},{"content":"Configuring Caddy as a Reverse Proxy A common task performed by a web server is to proxy HTTP requests to a running application server.\nIf you have completed an LC101 style course you predominately wrote code running in an application server.\nExamples of application server frameworks:\n Springboot (Java) Entity (C#) Express.js (Node) Flask (Python) Django (Python) Rails (Ruby) Cake (PHP) 1 million additional options for every single programming language under the sun  The application server frameworks contain code that handle raw HTTP requests, perform certain actions, and serve an HTTP response.\nA production grade web server must proxy HTTP requests to the application server framework.\nIn this case a web user makes an HTTP request to a server. Caddy catches the initial HTTP request and passes it to a running application server. The application server processes the HTTP request and builds an appropriate HTTP response. The application server then passes the HTTP response back to Caddy who sends it back to the web user.\nThis may seem like a complicated process. However, application servers are not built as production grade web servers and lack many of the features that web servers like Caddy provide. Caddy and other production grade web servers allow for multiple workers to handle requests, can distribute high web load to many different locations, can provide TLS via SSL termination, are optimized to handle a high volume of HTTP requests, and more.\nIn this article you will be running a Springboot application framework, and configuring Caddy to serve as a reverse proxy to the application framework.\nRemove Previously Created Caddyfile rm /home/student/Caddyfile Create New Caddyfile touch /home/student/Caddyfile Add Configuration to New Caddyfile http://localhost {  reverse_proxy localhost:8080 } Clone Build Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact Install Runtime Dependency  Note You may already have the necessary Java Runtime Environment to run this project openjdk-11-jre.\n  If you do not have this installed on your system you can install it with:\nsudo apt update -y sudo apt install openjdk-11-jre Run Application Server In a new terminal run:\njava -jar /home/student/spring-techjobs-mvc-artifact/spring-mvc.jar Reload Caddy caddy reload Access via Web Browser Curl Localhost curl localhost ","description":"","tags":null,"title":"Reverse Proxy","uri":"/web-server/caddy/reverse-proxy/"},{"content":"Configuring NGINX as a Reverse Proxy A common task performed by a web server is to proxy HTTP requests to a running application server.\nIf you have completed an LC101 style course you predominately wrote code running in an application server.\nExamples of application server frameworks:\n Springboot (Java) Entity (C#) Express.js (Node) Flask (Python) Django (Python) Rails (Ruby) Cake (PHP) 1 million additional options for every single programming language under the sun  The application server frameworks contain code that handle raw HTTP requests, perform certain actions, and serve an HTTP response.\nA production grade web server must proxy HTTP requests to the application server framework.\nIn this case a web user makes an HTTP request to a server. NGINX catches the initial HTTP request and passes it to a running application server. The application server processes the HTTP request and builds an appropriate HTTP response. The application server then passes the HTTP response back to NGINX who sends it back to the web user.\nThis may seem like a complicated process. However, application servers are not built as production grade web servers and lack many of the features that web servers like NGINX provide. NGINX and other production grade web servers allow for multiple workers to handle requests, can distribute high web load to many different locations, can provide TLS via SSL termination, are optimized to handle a high volume of HTTP requests, and more.\nIn this article we will be running a Springboot application framework, and configuring NGINX to serve as a reverse proxy to the application framework.\nRemove Old Configuration Files Delete any existing nginx.conf files inside of /etc/nginx/conf.d/.\nCreate New Configuration File sudo touch /etc/nginx/conf.d/spring-mvc.conf Add Configuration to New Configuration File server {  listen 80;  server_name localhost;   location / {  proxy_pass http://localhost:8080;  } } Clone Build Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact Install Runtime Dependency  Note You may already have the necessary Java Runtime Environment to run this project openjdk-11-jre.\n  If you do not have this installed on your system you can install it with:\nsudo apt update -y sudo apt install openjdk-11-jre Run Application Server In a new terminal run:\njava -jar /home/student/spring-techjobs-mvc-artifact/spring-mvc.jar Reload NGINX sudo nginx -s reload Access via Web Browser ","description":"","tags":null,"title":"Reverse Proxy","uri":"/web-server/nginx/reverse_proxy/"},{"content":"Official Homepage Reviewing the official homepage is always a great place to start:\n systemd Homepage  GitHub Repo Checking out the source code on GitHub can be benefical:\n systemd GitHub repo  Debian hosted systemd Wiki Debian (the base distribution of Ubuntu) offers a great wiki on learning and using systemd:\n Debian: systemd Documentation  ","description":"","tags":null,"title":"Next Steps","uri":"/systemd/next-steps/"},{"content":"ls command Our next command will list out the contents of either our current working directory or a specific directory: ls.\nls will use your current working directory as a default argument if you do not provide an argument. So to list out the contents of your current working directory you simply need to enter ls and nothing else before submitting the command. Give it a try!\nOur home directory /home/student has quite a few things in it. All of the entries just happen to be directories:\n Desktop Documents Downloads Music Pictures Public snap Templates Videos  That’s a pretty standard collection of user folders. These happen to be the default folders created when a new user is created in Ubuntu.\nls with argument We can provide an argument to the ls command, which must be a valid directory, and our Bash shell will list all the contents in that argument!\nLet’s try looking at all the contents inside of the root directory /.\nEnter ls /.\nThe root directory is the container for all files/directories on this computer! It is the root of our Ubuntu distribution. The root directory contains the /home directories of all users, all the tools shared across the machine, and all of the files/directories necessary for the operating system to function.\nLet’s take a look in the bin directory inside of the root directory.\nEnter ls /bin.\nWoah. That’s a lot of files! The /bin directory is a location of many of the binaries used on this operating system. If you scroll through the list you may see some familiar names like zip or python3. zip is used to create and open zipped folders. python3 is the Python3 interpreter that can run python files.\nIf you continued to search through this list you will also find the three commands we have already learned (pwd, clear, ls). All three of these programs are simply binaries that the Bash shell is executing for us. Many of the programs we will use in this class are located in this directory!\n Warning Do not create, change or delete any files above your home directory /home/student/, unless this book instructs you to. The files found directly above the user home directories are necessary for the operating system to work properly. Most Linux distributions will allow you direct access to these files.\n  ls Empty Directory Let’s take a look at the contents inside our current user’s Documents directory.\nEnter ls Documents.\nNothing came up. This isn’t a bug, this is the output we would expect if there are no contents to be listed.\n Bonus Try listing the contents of the remaining directories inside of /home/student/. Do any of them have contents?\n  ls Options ls has many options for you to choose from, however the two most common options are:\n -l: show the permissions, size, and date last modified among other meta-data (this is often referred to as long listing format) --all: show all files and directories including hidden  -l Enter ls -l to see the long form output for the current directory.\nMost of the information isn’t relevant to us yet, but it’s still important to know how to access it.\n-a Enter ls -a to see all the files and folders including any that may be hidden for the current directory.\nHere we can see a few hidden files, and directories. All of the hidden files and folders start with a period ..\n Note Your ls -a output may look slightly different from the provided image. Many hidden files and folders are created in the home directory to keep track of shell histories, shell profiles, and various configurations. As you continue to use this operating system your home directory will fill up with some of these files and directories.\n  ","description":"","tags":null,"title":"Bash Command: ls","uri":"/bash-introduction/walkthrough/ls/"},{"content":"Exercises The more practice you get with the tools in this class, the more comfortable, and faster with them you will become.\nWe haven’t learned how to use many tools yet, but we can still practice what we have learned. We want you to walk away from this chapter with a basic understanding of the terms presented and to be comfortable with Bash command structure, and the commands presented in the Walkthrough.\nPractice  write down the absolute path for each of the following commands:  bash which echo ls users cat less man kill   use the man pages to read the DESCRIPTION of each of the previous commands  Questions \u0026 Answers How many directories does your $PATH variable currently contain?   CLICK FOR ANSWER  9\n /usr/local/sbin /usr/local/bin /usr/sbin /usr/bin /sbin /bin /usr/games /usr/local/games /snap/bin    What command was less based on? Check out the less man page for the answer!   CLICK FOR ANSWER  more   Is the answer from the previous question a command you can use?   CLICK FOR ANSWER  Yes try less /etc/passwd and more /etc/passwd   Does the command from the previous answer have a man page?   CLICK FOR ANSWER  YES try man more   How can you exit or terminate your currently running emulator?   CLICK FOR ANSWER  kill -9 $BASHPID   Is there any way you can terminate the terminal emulator using the terminal emulator window?   CLICK FOR ANSWER  YES click the red x button in the terminal emulator window.   There is a command built directly into Bash for exiting a Bash Shell. Can you guess it?   CLICK FOR ANSWER  exit. Using the built-in exit command is the preferred way to terminate a Bash Shell!\n  ","description":"","tags":null,"title":"Exercises","uri":"/bash-introduction/exercises/"},{"content":"Going to the source is the best way to learn a tool. The git official website and GitHub repositories:\n Git Homepage Git Documentation Git GitHub Repos  In addition the Atlassian resources for learning git are fantastic:\n Atlassian: Learn Git Atlassian: Beginner Atlassian: Getting Started Atlassian: Collaborating Atlassian: Advanced Tips  ","description":"","tags":null,"title":"Next Steps","uri":"/git/next-steps/"},{"content":"Next Steps Ubuntu / Debian We have barely scratched the surface on package managers. We focused on using apt which is a relatively recent wrapper over the older apt-get package manager.\nLinks about the Ubuntu/Debian ecosystem of package managers:\n Ubuntu Package Search The underlying apt-get Package Manager Man Page The even further underlying Debian dpgk Package Manager Man Page  RedHat In addition to Debian based distros RedHat based distros are also very popular.\nA great place to start with learning about RedHat package managers would be to start learning about the dnf Package Manager.\n","description":"","tags":null,"title":"Next Steps","uri":"/package-manager/next-steps/"},{"content":"Not all packages come installed on your operating system. However, through using your operating system you may need to find and properly install new packages.\nBefore you can install a package you must figure out how to find a package.\n Note Before searching for packages you should Update Package Repositories with: sudo apt update\n  apt search [package-name] If you already know the name of the package you are interested in you can just search for it by name using apt search. Let’s search for the popular terminal text editor called vim.\nEnter apt search vim Lots of entries mention vim in their description, or name. Scroll through the list and you should find:\nThat’s exactly what I’m looking for the Vi IMproved - enhanced vi editor.\n Note The vim text editor is popular and highly customizable. You may have noticed the large number of packages that plug in to vim to provide features for specific programming languages or technologies.\n  Using the Internet In order to use apt search you have to already know the package name, or luck into guessing some part of the description of a package. This is not always possible. Regularly you will find new packages when researching how to accomplish any given task in Linux.\nSearching for Terminal Text Editors You know the task you want to accomplish, so you can leverage the internet to discover packages/tools that can assist you in your task.\nYou know you want to edit files from the terminal in Ubuntu. So pull up a search engine and search for it:\nubuntu terminal text editors\nYou may want to check out a couple of different results, but you are mainly on a discovery mission, so just focus on the first article for now: Exploring Text Editors in Ubuntu 20.04 - ByteXD.\nIt’s an article with the date of Oct 23, 2021. Pretty quick read, just mentioning some terminal text editors this specific author has heard of including both terminal (CLI) and graphical (GUI).\nThe CLI options the article lists:\n vi/vim nano kakoune emacs ne  You don’t want to learn 5 different packages that allow you to accomplish the same task. You simply need to use one. You will need to conduct further research to choose the tool that is right for your problem, and for you personally.\n Bonus Go ahead and try out apt search [package-name] on all of the listed items to see if there is a package associated with each of the 5 tools listed above. You may find using some Regex anchors beneficial while searching. Try apt search vim \u0026 apt search ^vim$. How are the results different? What are the keywords you’ve learned from this hint you can use to learn more? (Regex \u0026 Regex anchors)\n  Searching for Image Editors Search for: ubuntu image editor.\nThe top result was: linuxhint: Best Image Editor for Ubuntu.\nIt is an article from 2 years ago talking about the popular GNU Image Manipulation Program (GIMP). It’s a GNU package so you can probably assume you can access it with your package manager, but you can always search to make sure with apt search gimp.\nAgain, you just discovered the package using the internet. You will need to do more research into if the tool is a good choice for your specific task, and you may need to learn how to use the tool.\n","description":"","tags":null,"title":"Searching for Packages","uri":"/package-manager/walkthrough/package-searching/"},{"content":"Questions \u0026 Answers What is the purpose of vim?   CLICK FOR ANSWER  To create, view, and edit files from the terminal.\n  How do you open an existing file with vim?   CLICK FOR ANSWER  vim path/to/file-name    What are the three vim modes we learned in this course?   CLICK FOR ANSWER   Normal Insert Command Line (subset of Normal)    What is the purpose of Normal mode?   CLICK FOR ANSWER  To navigate a file, perform commands on the file, search a file.\n  What is the purpose of Insert mode?   CLICK FOR ANSWER  To modify the contents of a file directly with the keyboard.\n  In Normal mode how do you execute a write command?   CLICK FOR ANSWER  :w    In Normal mode how do you execute a quit command?   CLICK FOR ANSWER  :q    In Normal mode how do you navigate through a file?   CLICK FOR ANSWER  Many ways:\n directional pad arrow keys for moving left, down, up and right hjkl keys for moving left, down, up, and right $ to move to the end of a line 0 to move to the beginning of a line gg to move to the top of a file G to move to the end of a file :[line-number] to move to an exact line number w to navigate to the next word b to navigate to the previous word    In Insert mode how do you navigate through a file?   CLICK FOR ANSWER  Limited navigation. You must use the directional pad arrow keys for moving left, down, up and right.\n  How do you change from Normal mode into Insert mode?   CLICK FOR ANSWER  Many ways. This course showed the i key which switches to Insert mode at the current cursor location.\nThe a key switches to Insert mode right after the current cursor location.\n  How do you change from Insert mode to Normal mode?   CLICK FOR ANSWER  By pressing the escape esc key.\n  ","description":"","tags":null,"title":"Vim Exercises","uri":"/userspace-applications/exercises/vim/"},{"content":"Major Concepts \u0026 Key Terminology  Navigating the file system CRUD directories and files Finding files Bash Aliases Bash shell initialization script Substitute user  Commands  cd mkdir touch cat less rm  -r   mv nano find alias ~/.bashrc sudo  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"File System","uri":"/file-system/"},{"content":"Next Steps We mainly explored navigating the file-system from a Bash shell. You can continue building Bash shell skills by referencing the official GNU Bash Reference Manual\nThe entire manual will take you through the entire Bash shell and how it can be used. That may be overwhelming. We recommend checking out some specific sections as a great place to continue your Bash shell learning journey:\n Bash Shell Pipelines: to learn how to pass the output (STDOUT) of one command to another command.  example: cat /etc/passwd | grep student how has the output been modified from running cat /etc/passwd alone?   Redirecting Output: to learn how to redirect the various input/output streams in Linux.  example: echo \"My name is Paul!\" \u003e name.file look for a new file called name.file example: cat /etc/passwd \u003e users.file look for a new file called users.file    It is also a good idea to start learning about the importance of files in Linux. You can begin this journey with the Ubuntu: FilePermissions article.\n","description":"","tags":null,"title":"Next Steps","uri":"/file-system/next-steps/"},{"content":"Update Files and Directories You can update the contents of a file/directory or the metadata (name, last modified, permissions) of a file/directory.\nUpdating Metadata Moving Files and Directories The filename and path of a file/directory is a key piece of metadata. In many instances it makes sense to move a file, or directory to a new location within the file-system. You can move a file/directory with the mv command.\nLet’s create a new directory temp-dir and a new file temp.file both in our home directory.\nNow we have /home/student/temp-dir/ and /home/student/temp.file. Let’s move temp.file into our new directory temp-dir/.\nmv requires two arguments. The first argument is the file/directory we want to move. The second argument is the directory that will hold the file/directory we want to move.\nSo to move the temp.file into the temp-dir we would need a command like: mv ~/temp.file ~/temp-dir/\n Note You can use absolute or relative paths with the mv command. So you could have accomplished the same task with absolute paths: Or you could have accomplished the same task with relative paths:   Moving Directories The mv command works with directories as well. Let’s move the ~/temp-dir directory into the ~/Documents directory. Our first argument will be temp.dir as it represents the file/directory we want to move. The second argument will be Documents as it represents the directory we want to move our contents into.\nmv ~/temp-dir/ ~/Documents\nMoving to Rename Files and Directories When you use the mv command you are affecting metadata by updating the absolute path of the file/directory. The previous section focused on changing the directories that hold a file/directory. However, with the mv command you can also change the name of a file/directory.\nLet’s change the name, but not location, of a file. Currently we have a file: /home/student/Documents/temp-dir/temp.file what if we wanted to change the name of that file to roster.txt?\nWe can use the mv command to update the absolute path. The parent directories will stay the same, but we will simply provide it a new filename.\nmv ~/Documents/temp-dir/temp.file ~/Documents/temp-dir/roster.txt\nThis command updated the name of the file without changing it’s location. Under the hood, the absolute path of the file was updated and that’s the purpose of the mv command. The absolute path started as /home/student/Document/temp-dir/temp.file and we updated it to /home/student/Document/temp-dir/roster.txt!\n Bonus You can both update the location and the name of a file in one mv command. This command moved the roster.txt file from the temp-dir/ directory into the current working directory (as represented by ./) and renamed it to hello.txt. That’s a lot of work packed into one command!\n  Updating File Contents While changing the metadata attached to a file is important, it’s not as common as updating the contents of a file. This section will focus on updating the internal contents of a file with the GNU bash shell terminal editor called nano.\nOpening a file using a terminal text editor:\n nano filename  vim filename emacs filename     Bonus echo \"newline\" \u003e\u003e filename\n  Open the file in your favorite text editor or IDE. Visual Studio Code, IntelliJ, Pycharm, Atom, etc.\nUsing nano GNU’s nano stands for Nano’s ANOther editor. There is a very long history of terminal based text editors, they far outdate the graphical text editors you are familiar with.\n Note If you find any pair of computer enthusiasts that worked on computers between 1960-1990 they will likely have strong, but different, opinions on their favorite terminal text editor! These strong opinions still exist in many internet communities. You may have heard of the zealous arguments between vim and emacs users. nano, vim, and emacs are just three of the many dozens of terminal text editors that exist.\n  nano is a great choice as it is the most straightforward to use and it comes as a part of the standard package of most Linux/GNU distributions. We will predominately use nano to edit files in this course. We will also explore some of the basics of vim.\nOpening a File Opening a file with nano is very straightforward. We simply execute the nano command with one argument, the file we wish to open. If the file exists, its contents will be populated into nano. If the file does not exist, it will be created as an empty file and opened within nano.\nWhen you open the file you will leave the Bash shell behind and the nano text editor will take up the entirety of your terminal window.\nLet’s create and open a new file in our home directory called myname.txt.\nnano ~/myname.txt\nAfter executing the command you will see the ~/myname.txt file opened in the nano text editor:\nThere are three sections of the nano text editor:\n The top of the screen shows the version (GNU nano 4.8) and the currently opened file (/home/student/myname.txt) A large block of space, with a cursor. This is the area where we can create, read, update, and delete any of the contents of the file. The bottom of the screen contains a useful collection of control keys allowing us to save, exit, or assist us in editing the file.  Add Contents to the File Go ahead and type your name into the file:\nI simply typed directly on my keyboard and nano added the contents to the file! You can also use the arrow keys on your keyboard to navigate the file.\nWrite File Once you are happy with the changes you have made to the file, we need to write the changes to the hard disk.\nnano provides a control key combo for writing files. By simply holding the control (ctrl) and then pressing the o key nano will Write Out the file.\nGive it a shot.\nNotice the change to the nano window. A new message towards the bottom of the screen (above the control key combos) is confirming the name and location of the file to be written.\nThe /home/student/myname.txt file didn’t exist before we opened the file. It is standard behavior for nano to ask us to confirm before creating and writing the contents of the file.\nYou can simply hit enter on your keyboard to write the /home/student/myname.txt file with the contents you provided in the window. Try it out.\nnano was kind enough to confirm that one line was written, as indicated by the message above the control key combos.\nExit File To exit a file you simply need to invoke the control combo key for the Exit option. You should be able to see from the avaible options that it is ctrl + x.\nTry it out.\nSince the file had been written in the previous step, and had no changes nano immediately exited the file and returned us to our Bash shell.\n Note If you invoke the exit condition of nano while having unsaved changes, it will prompt to write, or discard the changes before exiting to the Bash shell.\n  Looking at the New File Let’s see the new file. Enter ls ~ to see the new myname.txt.\nAnd let’s cat out the contents of our file:\nWe have successfully opened a file, edited the contents of a file, wrote a file, and displayed the contents of a file all from our terminal!\n Bonus Like everything in this class, you will become more comfortable the more you practice. If you truly want to become comfortable and productive with a terminal text editor you need to use one often. nano is straightforward to use, but lacks the many features you will find in vim or emacs. For now practice creating and editing some files with nano. Soon we will learn about installing new software and you can take it upon yourself to learn how to use either vim or emacs. Conquering the basics and being comfortable with some of their more advanced uses will benefit you greatly if you work with Linux systems in your career.\n  ","description":"","tags":null,"title":"Updating Files \u0026 Directories","uri":"/file-system/walkthrough/updating-files/"},{"content":"sed from STDIN So far you have only performed sed substitute commands using a file as input, however you can re-route STDOUT from another command to use as the STDIN for sed.\nThis allows you to combine sed with other tools like grep.\nIn this example you will be using grep to match users with a specific last name. However, you don’t want the Company the person works for, just their first and last names, and their email address. So you will use sed to trim out the company of our filtered dataset.\ngrep Last Name: Johnson grep '^[^,]\\+,Johnson' user-data.csv Output:\nThis grep and regular expression combo matched all individuals with a first name, and the last name of Johnson.\n Note This grep command is using two regular expression symbols you have not seen before:\n [^,]: exclusion group, match any character other than the characters found inside of the match group [^] in this case a comma , +: match at least one, but as many additional characters that fit the pattern  Altogether: '^[^,]\\+,Johnson' is a regular expression for:\n match the beginning of the line (^) match any character except for characters found in the exclusion group, in this case just a comma (,) match at least one of the preceding pattern (anything but comma), but as many characters as you can: \\+ match exactly one comma (,) match exactly Johnson   Sally,Johnson: match Fred,Johnson: match Sally,Kemper: no match ,Johnson: no match Fred,,Johnson: no match    sed Substitute Company with Nothing As of now the output contains all the people you want to email, but you currently have each person’s employer, which you don’t care about. Let’s substitute and replace the company with no characters, effectively deleting the section.\ngrep '^[^,]\\+,Johnson' user-data.corrected.csv | sed 's/[^,]\\+//4' Output:\nThat was pretty slick. Let’s break down the sed substitution: s/[^,]\\+//4.\n s/regex/replacement-text/flag s: substitute /[^,]\\+/: regex saying match at least one charcter not in the exclusion group (comma), but match as many as possible //: empty replacement-text, after matching the pattern it should substituted with nothing /4: make the substitution on the 4th match in the line   Note You can visualize the four sections with grep and it will give you a better understanding of exactly what was replaced with nothing on each line:\ngrep '^[^,]\\+,Johnson' user-data.corrected.csv | grep '[^,]\\+' Output:\nTake note that each line has matched exactly four segments, but no actual commas.\n the first name would be removed by providing a 1 flag the last name would be removed by providing a 2 flag the email would be removed by providing a 3 flag the company would be removed by providing the 4 flag all matches would be removed by providing the g flag (which would only leave the three commas).    sed Substitute Hanging Command with Nothing At this point in time we have our email list: all the Johnsons, their emails, but not their employer.\nEach line has a hanging comma. The hanging comma can be matched and substituted with sed:\ngrep '^[^,]\\+,Johnson' user-data.corrected.csv | sed 's/[^,]\\+//4' | sed 's/,//3' Output:\nGoodbye trailing comma!\nWriting the Stream The matched lines (grep) and substitutions (sed) have transformed our user-data.corrected.csv in to a family email list for the Johnsons, but the end result has been displayed to STDOUT.\nSTDOUT can be redirected to a file by using the bash redirection operator (\u003e) that results in a file with the matching, and substitutions:\ngrep '^[^,]\\+,Johnson' user-data.corrected.csv | sed 's/[^,]\\+//4' | sed 's/,//3' \u003e johnson-email-list.csv Validation Check the contents of the working directory:\nls Output:\nCheck the contents of the file:\ncat johnson-email-list.csv ","description":"","tags":null,"title":"Sed From STDIN","uri":"/userspace-applications/walkthrough/sed/sed-from-stdin/"},{"content":"grep from STDIN So far you have only used grep to search a specific file. However, you can pass input directly to grep and match STDIN results against a Regular Expression pattern.\nls | grep Example Match patterns for all contents of the home directory:\nMatch all files with a . in our home directory.\nls ~ | grep '\\.' Output:\n Note The . is a Regular Expression special symbol meaning to match any character. In order to search for an actual . you need to escape the . so that RegEx knows that you are searching for an actual period and not referencing special symbol. The escape special symbol in RegEx is the backslash \\ symbol.\nWhen you provide the regular expression: '\\.' you are telling grep to match any lines that have a . in them.\n  history | grep Example Match all grep commands in our bash history\nhistory | grep 'grep' Output:\nfind | grep Example Match all /bin/ for files containing the word bash in the root directory.\nsudo find / -name 'bash' | grep '/bin/' Output:\ncurl | grep Example Send a curl request directly to the API and match the results (csv in STDIN) to a specific pattern.\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep 'Microsoft$' Output:\n","description":"","tags":null,"title":"grep From STDIN","uri":"/userspace-applications/walkthrough/grep/grep-stdin/"},{"content":"Name  vim - Vi IMproved, a programmer’s text editor\n Purpose CLI for editing text files. Provides various modes and actions that allow the user to navigate, search and transform text files manually, or automatically.\nUsage  create new files in terminal edit files in terminal read files in terminal  Setup You have likely installed vim already, if you have not you can with apt:\nsudo apt install vim vim Modes vim has a few different modes:\nBasic Modes:\n Normal Visual Select Insert Command-line Ex  Additional Modes:\n Operator-pending Replace Virtual Replace Insert Normal Insert Visual Insert Select   Bonus The listed modes can be found in the Vim Docs / vim-modes.\n  This curriculum will only utilize the following modes:\n Normal Insert Command Line Mode via Normal Mode  Our goal is to learn how to create, edit, and read files from the terminal using vim.\n","description":"","tags":null,"title":"vim","uri":"/userspace-applications/walkthrough/vim/"},{"content":"real handy command: systemctl list-units --type target\n[Unit] Description=Keystroke logger  [Service] ExecStart=/usr/local/pylogger/env_pylogger/bin/python3 /usr/local/pylogger/main.py Restart=on-failure  [Install] WantedBy=multi-user.target # WantedBy=graphical.target  have students clone lc-pylogger have students create a virtualenv for project have students run program with virtualenv walk students through creating the very simple unit file using virtualenv and executing lc-pylogger systemctl start [unit-name.service] systemctl stop [unit-name.service]  Now the key-logger can be started or stopped with the systemctl tool.\n","description":"","tags":null,"title":"Python3 Unit File","uri":"/systemd/walkthrough/python3-unit-file/"},{"content":"Branching Practices When creating a new branch you always want to make sure your master branch is updated to the most recent version. One reason for this is to avoid any unecessary merge conflicts when you begin to merge any working branches into the master branch. That process will look something like the following:\n git checkout master (if not already on the master branch) git pull: Update master branch to most recent working version git branch [new-branch-name]: Create a new branch git checkout [new-branch-name]: Checkout or switch to newly created branch   Note When you “checkout” from master you are effectively creating a new branch with identical files and directories to the master branch. If you were to checkout from a different branch you would be working with code from that specific branch (which most likely wont have been merged with master yet). The command git checkout -b new-branch-name is also a shortened way of running the following commands: git branch [new-branch] » git checkout [new-branch]\n  ","description":"","tags":null,"title":"Best Practices","uri":"/git/walkthrough/git-branching/branching-practices/"},{"content":"After your machine boots up for the first time, or after you have completed the Ubuntu installation you will be greeted with the typical Ubuntu user login screen:\nYou can login by hitting the enter key or click student to login.\nUser Password Enter your password. If you followed the steps above during the user account creation the password is admin.\nHit the enter key to continue after inputting your password.\nOptional Settings You will now be prompted with some first time start up optional settings. You will have to click past these options since it is the first time you have logged in.\nClick the Skip button.\nLivepatch Click Next\nHelp improve Ubuntu Click Next\nPrivacy Click Next\nYou’re ready to go! And lastly click Done\nSoftware Update You will most likely receive a notification at this point that there is updated software available. This is the package manager informing you that there are newer versions of the packages available that you currently have installed.\n Note It is normally a best practice to update your operating system whenever new package versions are available. However one of the early sections of this book is learning about and using the package manager. We will complete the step of updating our software at that point in time. Please select Remind Me Later to skip this step for now. No problem if you accidentally select Install Now, it will simply change some of the output you see during the Package Manger lessons, but will not impact your ability to work through this course.\n  Select Reminder Me Later as we will complete updates in a later lesson.\nUbuntu Desktop You have reached the Ubuntu Desktop!\n","description":"","tags":null,"title":"First Time User Login","uri":"/configurations/ubuntu/user-login/"},{"content":"Merge Strategies In this walkthrough you will find two different merge strategies: git merge and git rebase.\nBoth strategies have their own pros and cons.\nThe main benefit of git merge is that you keep the original history of the master branch in tact. However, conflicts are handled during the merge into the master branch.\nThe main benefit of the git rebase is that conflicts are handled in the feature branch and conflicts will not need to be managed when merging with the master branch. However, performing a rebase alters the history of the feature branch.\n get merge requires you to merge a branch directly into master. git rebase allows you to rebase your development branch on top of master.  Content Links Review Existing Code Git Merge Git Rebase   Note The walkthrough articles in this section will be using the py-demo-web-logs-continued GitHub repository.\n  ","description":"","tags":null,"title":"Merging","uri":"/git/walkthrough/merging/"},{"content":"Major Concepts \u0026 Key Terminology  permission classifications  owner group other users   read permission write permission execute permission chmod chown  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"File Permissions","uri":"/file-permissions/"},{"content":"Normal Mode: File Navigation One of vim’s major ideals is that the user’s hands never need to leave the keyboard. Meaning various keys and keystrokes have been programmed to give the user navigation controls.\nMost navigation occurs in Normal mode.\n Warning This article will use the user-data.csv used in the previous grep and sed sections. If you do not already have the file, you can re-download it with:\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv \u003e user-data.csv After running the command you should have a new copy of the user-data.csv file:\nThe file should have 25001 lines in it (run wc -l user-data.csv):\n  Open user-data.csv with vim First open the file:\nvim user-data.csv Output:\nBy default, vim opens the file in Normal mode.\nBasic Navigation Navigate Down j In Normal Mode the j key will move the cursor down one line.\nUpon pressing the j key exactly one time it will move the cursor from over the f in first_name to the A in Amy immediately below it.\nTry it out:\nNotice the cursor moved over the A in Amy.\nWhat happens if the j key is pressed five more times? It should be over the W in Wesley:\nNavigate Up k In Normal mode the k key will move the cursor up one line.\nAs the cursor is currently over the W in Wesley pressing k one time should place the cursor over the B in Brian:\nNavigate Right l In Normal mode the l key will move the cursor right one character.\nThe cursor is currently over the B in Brian pressing l one time should place the cursor over the r in Brian:\nNavigate Left h In Normal mode the h key will move the cursor left one character.\nThe cursor is currently over the r in Brian pressing the h key one time should place the cursor over the B in Brian:\nAdvanced Navigation The Normal mode basic navigation keys (h, j, k, l) are analogous to the direction keys in Insert mode. Both suffer from the same drawback: tedious and slow navigation. Using the mouse would be a better experience than trying to navigate through a 25001 line file with the basic navigation commands.\nLuckily, vim has a ton of advanced Navigation commands in Normal mode we will explore:\n go to specific line go to next word go to previous word go to beginning of line go to end of line go to top of file go to bottom of file  Go to specific line :[line-number] + \u003center\u003e The cursor is currently on B in Brian typing:66 and hitting enter will navigate to the 66th line of the file:\nThis command took us to the first character of the 66th line E in Ernest.\nLet’s navigate back to line 6 typing :6 and hitting enter:\n Note Two things to take notice of:\n giving a goto line is a Normal mode command requiring an enter key press the bottom right corner of the vim terminal window displays two numbers (like 6,1) representing the cursor location  The following picture will highlight the cursor location:\n  Navigate Next Word w In Normal mode the w key will move the cursor forward one word.\nThe cursor is currently on B in Brian (line 6) pressing w one time will place the character on the next word (in this case the comma):\nPressing w three more times should move the cursor to the i in iperez@example.net:\nNavigate Previous Word b In Normal mode the b key will move the cursor back one word.\nThe cursor is currently on the i in iperez@example.net pressing the b should move the cursor back to the , preceding the word:\nNavigate to Beginning of Current Line 0 In Normal mode the 0 (zero) key will move the cursor to the beginning of the current line.\nThe cursor is currently located at 6,14 pressing the 0 key will move the cursor to 6,1:\nNavigate to End of Current Line $ In Normal mode the $ (shift + 4) key combo will move the cursor to the end of the current line.\nThe cursor is currently located at 6,1 pressing the $ key combination will move the cursor to 6,45:\nNavigate to Top of File gg In Normal mode the gg key combo will move the cursor to the top of the file.\nThe cursor is currently located at 6,45 pressing the gg key combo will move the cursor to 1,1:\nNavigate to Bottom of File G In Normal mode the G (shift + g) key combo will move the cursor to the bottom of the file.\nThe cursor is currently located at 1,1 pressing the G key combo will move the cursor to 25001,1:\nRecap Navigating in vim can be accomplished in either Normal or Insert modes with basic navigation commands.\nHowever, vim Normal mode provides many additional commands for navigating the file in an efficient manner.\n Note There are additional navigation commands in vim, but you will have to research those on your own!\n   Bonus You can provide a numeric prefix to the majority of the navigation commands like 5 and it will perform the provided navigation action the provided number of times.\nFor example:\n Navigate down five lines with 5j Navigate up 15 lines with 15k Navigate 32 characters to the right with 32l Navigate 6 characters to the left with 6h Navigate forward 3 words with 3w    ","description":"","tags":null,"title":"Normal Mode: File Navigation","uri":"/userspace-applications/walkthrough/vim/normal-navigation/"},{"content":"We learned a lot about web servers:\n Installing Controlling with systemctl Configuring as a static web server Configuring as a reverse proxy to an application server  We did all of this for two different web servers: NGINX and Caddy.\nThere are many more web servers, and there are additional things you can do with web servers.\nResources A great place to learn more would be to read through the documentation for both of the web servers introduced in this class.\n General Documentation  Caddy Documentation Homepage NGINX Documentation Homepage    Additionally the next three concepts related to web servers we recommend you to start researching are:\n Load Balancing  Caddy Documentation: Load Balancing NGINX Documentation: Load Balancing   Enabling HTTPS  Caddy Documentation: HTTPS NGINX Documentation: HTTPS   Web Server Logging  Caddy Documentation: Logging NGINX Documentation: Logging    ","description":"","tags":null,"title":"Next Steps","uri":"/web-server/next-steps/"},{"content":"echo The next command echo simply prints out a message to the Bash shell’s Standard Output (STDOUT). An echo statement is very similar to the print() method in Python3, or the console.log() method in JavaScript, or the System.out.println() method in Java. View the following code snippets to see how you can display “hello” using Python, JavaScript, Java, and the Bash echo command.\npython JavaScript Java Bash  print(\"Hello\")   \u003e console.log(\"Hello\")   System.out.println(\"Hello\")   echo \"Hello\"     To use the echo command we simply need to invoke the command with one argument that results in a string.\nEnter echo \"Hello world\".\n Note echo commands are especially useful inside of Bash scripts. In any given Bash script many things may be happening and outputting some message to the individual that invokes the script is a very useful feature.\n  The echo command can be used to easily view the contents of a Shell Variable. Your home directory, path, and many other variables are attached directly to your Bash Shell in the form of variables. You can use echo $VARIABLE to easily view the contents of the variable.\n","description":"","tags":null,"title":"Bash Command: echo","uri":"/bash-introduction/walkthrough/echo/"},{"content":"apt install vim Before installing any new packages it is a good idea to update your package repositories, this way you can guarantee you have the most updated package for your specific version of Ubuntu!\nNow you can install the Vim package: sudo apt install vim:\nAs a standard feature of the apt CLI it will ask for confirmation before installing any packages. We need to enter Y, or simply hit enter on our keyboard to confirm the package installation. Once we do the apt CLI will install and configure the new package for our use!\nLots of text was output to the bash shell’s display (STDOUT). If you scroll through the text take note of some of the statements including where the package files were installed, packages that were unpacked (so they could be installed), triggers that were processed or created, and more.\nYou don’t really need to worry about those statements for now. You should mainly be concerned with ensuring this tool was installed and you can use it.\nHow can you determine that this tool was installed and configured to use from your Bash shell?\nwhich vim Our old friend the which command:\nvim --version Another common way to check for program installation and usage from the CLI shell is by using the --version option:\n Note Not all packages have created a --version flag, however it is a very regular part of packages and if you are installing packages in the future, is a handy way for determining if you can use the package from your CLI shell.\n  Opening vim Finally you can open vim in the manner you would use it.\nvim is similar to nano in that it is a CLI shell text file editor.\nSo you can create and open a new file for edits by executing: vim [filename]. If the file doesn’t exist it will create the file and open it for editing. If the file already exists its contents will be loaded into the file as it is being opened for editing.\nTo try it out execute: vim temp.temp, which will create and open a new temp.temp file in your working directory:\nOnce the file has opened you will see that it doesn’t have any contents:\nNothing exists in the file, and so therefore nothing is displayed. Your cursor is currently on the first line of the file, but if you type nothing happens!\n Bonus vim has various modes, you are in command mode, which allows the user to perform various commands and operations within, or on the entire file. Some of the features built into command mode are what make vim such a popular terminal text editor. You will learn about vim usage in a future lesson.\n  Closing vim There are many ways to exit vim, but none of them are readily apparent. The easiest way is to enter the command :q or :wq while in vim command mode. :q is the operation to quit a file, and :w is the operation to write (save) the file.\nIn order to type and execute one of these commands you must be in vim command mode. When you are in command mode when you type : with any additional characters it will be displayed at the bottom of the vim window:\nIn the picture above notice the line at the bottom that says: :e9faefafe0-[ay8fe. Being able to type after entering the colon (:) character at the bottom of the file is a way we know we are in command mode.\nInsert Mode You may find yourself in vim insert mode:\nTake note of the line at the bottom that says: -- INSERT -- indicating you are in insert mode.\nWhile in insert mode any key presses you make will show up in the file. This is the primary way for entering or editing text into a file while in vim.\nVisual Mode Or you may find yourself in vim visual mode:\nTake note of the line at the bottom that says: -- VISUAL -- indicating you are in visual mode.\nVisual mode allows you to visually select lines, or characters and then perform operations on those specific sections.\nReturning to Command Mode In either insert mode or visual mode you can return to command mode by hitting the escape (esc) key on your keyboard.\n Note You may need to hit the escape (esc) key twice as you may have a partial keyboard operation in process, and hitting escape first cancels the operation, and then hitting it again returns you to command mode if you aren’t already in it. Sometimes when I want to return to command mode and I don’t remember what operation or mode I’m in, I just spam the escape key like 15 times.\n  Writing and Exiting a File Once you are in command mode enter :wq:\nThen hit the enter key which will execute the vim command to write and quit the file returning to your bash shell:\nClosing Vim can feel like quite a process! Vim will likely feel like a hassle until you’ve learned some of its features. Those features make it a very powerful tool for editing and manipulating the contents of a file. You will continue to learn more about Vim in a later lesson.\napt install gimp Let’s practice installing a package that has a GUI component. The GIMP package stands for GNU Image Manipulation Program. This program is an open source, and free software for manipulating files.\n Note You won’t use, or learn GIMP in this program. This is just an example of a package that is predominately driven by a GUI.\n  Update Package Repositories Again, before installing a new package you should update our package repositories:\nInstall GIMP Now let’s install GIMP with: sudo apt install gimp:\nAgain confirm the install by hitting enter or entering in Y and hitting enter.\n Bonus The apt install CLI has a -y option that will automatically enter yes into any package installation confirmations. So you would find that sudo apt install gimp -y would install the gimp package without asking for confirmation. In this class we are going to recommend not using the -y flag as it’s great to reinforce the steps of the apt CLI.\n  Confirm Installation which gimp gimp --version Opening gimp You can simply enter gimp into our Bash shell:\n Note Alternatively you could search for gimp in the Activities pane:   And the GNU Image Manipulation Program GUI will open:\nClosing gimp Since this is a GUI you simply need to click the red X in the top right hand corner of the GIMP window, or you can select File-\u003eQuit (or use the shortcut ctrl + q).\nAfter closing GIMP, if you opened it from your bash shell you should see your terminal once again:\nGIMP is a popular tool in the GNU/Linux world, because it is an open source, free software maintained by GNU. We will not be using GIMP in this course.\n","description":"","tags":null,"title":"Installing Packages","uri":"/package-manager/walkthrough/package-installation/"},{"content":"Major Concepts \u0026 Key Terminology  apt - Advanced Package Tool Package Repositories Package Managers  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Package Manager","uri":"/package-manager/"},{"content":"Finding Files If you haven’t noticed by now, Linux/GNU is a file based operating system. You can actively look at (and in many cases modify or delete) almost any of the files that make Linux work. However having such a huge number of files can make finding the files you need a difficult task.\nLuckily there are many tools that help us find the files we are looking for. One of which is the find command.\nThe find command takes two arguments: a directory to search, and a search pattern (in this class the pattern will predominately be a filename).\nLet’s search our home directory for any files named myname.txt.\nfind ~/ -name \"myname.txt\"\nThe command found one matching file with the absolute path of /home/student/myname.txt.\n Note We did provide one option to the find command called -name. We were telling the find command that the provided pattern only needs to match the filename instead of all parts of the filepath. This is a nice option to include as it will not match if any directories matched our pattern.\n  Finding Files in Directories Above Home As you are continuing on your Linux/GNU learning journey you may learn about various tools found in the /bin, or interesting files in /etc or other locations outside of the /home directory. If you want to read these files, or learn about their locations you can use the find tool.\nLet’s use find to find the python3 binaries starting at the root (/) directory.\nfind / -name \"python3\"\nThat was overwhelming! There are dozens of files that match \"python3\" just for filenames in our entire computer. Many of the files we do not even have permission to read which is why we are getting Permission denied errors.\nLet’s run our find command again, but instead of starting at the root directory, let’s start at the /usr directory.\nfind /usr -name \"python3\"\nThis is definitely more manageable as we are only looking for files matching \"python3\" in the user directory.\nUsing Wildcards with find In an earlier lesson we looked at /usr/bin/python3. However, there was also a /usr/bin/python3.8 in the same location. This file did not match our explicit pattern of \"python3\". However, we can use a Bash shell wildcard (*) to increase the amount of potential matches.\nfind /usr -name *\"*python3*\"\nAnother long list, but we do have at least read access on all of the results. Note how the find command matched any file name starting with \"python3\", but matched any text after that match. That’s the power of the Bash shell wildcard *.\nIn this list you should see both /usr/bin/python3 and /usr/bin/python3.8 near the top of the list, you will probably need to scroll up to see.\n Bonus The /usr directory contains data, binaries, and documentation that are available to general users of the computer. It’s a great place to search for tools that are available across users, but aren’t used by the kernel to perform it’s many tasks. You can learn more about the /usr directory at the LDP Linux Filesystem Hierarchy Documentation.\n  ","description":"","tags":null,"title":"Finding Files","uri":"/file-system/walkthrough/finding-files/"},{"content":"Chaining Sed Another benefit of using STDIN when working with sed is the ability to chain multiple substitutions (or other sed scripts). The final example of the last article was an example of chaining sed, but you will get another example here.\nIn an earlier walkthrough you corrected the user-data.csv.\nIt took a total of three steps to complete the task. However, you could have chained all of the steps together using the pipe (|) operator.\nLet’s give it a try:\nsed 's/mastercard/Mastercard/' user-data.csv | sed 's/spectrum/Spectrum/' | sed 's/Stephens-Griffin/Stephens-Griffin-Ferguson/' \u003e user-data.corrected2.csv Validation cat user-data.corrected2.csv There shouldn’t be any spectrum matches:\ngrep 'spectrum' user-data.corrected2.csv There shouldn’t be any mastercard matches:\ngrep 'mastercard' user-data.corrected2.csv There should only be one Stephens-Griffin-Ferguson match:\ngrep 'Stephens-Griffin-Ferguson' user-data.corrected2.csv We did not provide the pictures as evidence, because you should have the skills now to validate these changes yourself.\n","description":"","tags":null,"title":"Chaining Sed","uri":"/userspace-applications/walkthrough/sed/sed-chaining/"},{"content":"Whole Match Reference \u0026 Using sed substitute you may want to keep the pattern you matched and simply add additional text to it. You can use the match reference symbol \u0026 to achieve this.\nAdd : PAID IN FULL to each line ending in Microsoft as they have settled their fictional debts with us:\nsed 's/Microsoft$/\u0026: PAID IN FULL/' user-data.corrected.csv Output (after scrolling up to find a line ending in Microsoft):\n Note This example could have been achieved with:\nsed 's/Microsoft$/Microsoft: PAID IN FULL/' user-data.corrected.csv However, there are some instances where you don’t know the exact string that was matched because you gave a regex pattern, not an exact string. The following example covers this and introduces a new Regex concept.\n  Match Microsoft or Mastercard and Reference sed 's/\\(Microsoft\\|Mastercard\\)$/\u0026: PAID IN FULL/' user-data.corrected.csv Output (after scrolling up to find both Microsoft and Mastercard records):\nIn this case a Regex pattern was provided: (Microsoft|Mastercard)$ instead of an exact string match Microsoft$. For the line where the match occurred when you used the match reference symbol: \u0026 it entered in the exact text that matched our pattern.\nThere would have been no way to know which company would have matched, and you couldn’t have hardcoded it like the example listed in the note above.\n Bonus This article introduced two new regex concepts:\n (): matching group |: logical or operator  Altogether: (Microsoft|Mastercard) creates a matching group where either Microsoft or Mastercard will match.\n  ","description":"","tags":null,"title":"Substitute: Reference Whole Match","uri":"/userspace-applications/walkthrough/sed/substitute-reference-whole-match/"},{"content":"Chaining grep We can even pass the output from a grep command to another grep command to build complex filter chains.\nStep One: Get our Dataset curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv Output:\n25000 records is too much.\nStep Two: Filter Matches '^John' Filter data to include only '^John':\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '^John,' Output:\nStep Three: Filter Matches 'Microsoft$' Using the output from the previous filter, filter further to include lines that match 'Microsoft$'.\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '^John,' | grep 'Microsoft$' Output:\nStep Four: Filter Matches @example\\.com Using the output from the previous filter, filter further to include lines that match '@example\\.com'.\ncurl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '^John,' | grep 'Microsoft$' | grep '@example\\.com' Output:\n","description":"","tags":null,"title":"grep Chaining","uri":"/userspace-applications/walkthrough/grep/grep-chaining/"},{"content":"Blocked Currently blocked by network issues. Port 25 will likely be blocked for learners. Opening up the port is not simple nor deterministic for every learner that goes through the class.\nName  Mailutils is a swiss army knife of electronic mail handling. It offers a rich set of utilities and daemons for processing e-mail.\n From Mailutils Homepage\nsudo apt install mailutils\nPurpose To create and configure email servers. Emails can be received and sent.\nUsage  Note We will only be using mailutils to send emails in this class.\n  Activity  setup mail utils to send emails send yourself an email  ","description":"","tags":null,"title":"mail-utils","uri":"/userspace-applications/walkthrough/mail-utils/"},{"content":"Normal Mode: Search File Navigating a file is a crucial skill. The Normal mode of vim provides a search function that allows you to search for specific characters, words, phrases, or additional Regular Expressions.\nTo perform a search in vim Normal mode you simply need to press the forward slash (/) character and type in your search term. While typing vim will automatically take you to the first encountered search term from the cursors current location.\nOnce you are happy with your search term you can hit enter and all of the words matching your pattern will be highlighted.\nSearch /Paul In Normal mode, from the cursor position 1,1 (get there by pressing gg) press / and then type Paul:\nBefore hitting enter vim automatically moved the cursor to the first matched instance. If more letters are typed they will be added to the search term. To signal the end of a vim Normal mode search the enter key must be pressed:\nAfter pressing enter the screen has changed in a subtle, but informative way:\n The cursor has been placed on the first match of the provided pattern The cursor location has been updated in the bottom right corner of the vim terminal window /Paul is still recorded as the in memory search pattern  Having the search term still recorded in vims memory is very handy as it allows us to provide additional key presses to advance to the next, or previous match in the file.\nNavigate to Next Match in File n After entering a search in Normal mode vim can be instructed to advance to the next matched result by pressing the n key:\nThe n key press placed the cursor on the next matched location 215,1.\nThe n key can be pressed any number of times after a search has been entered.\nNavigate to Previous Match in File N After entering a search in Normal mode vim can be instructed to backtrack to the previous matched result by pressing the N (shift + n) key combo:\nAfter pressing N our cursor changed from location 215,1 to 156,1.\nThe N key can be pressed any number of times after a search has been entered.\nSearch /^\\(John\\|Paul\\) Within vim Search mode enter the following regular expression:\n^\\(John\\|Paul\\) A match for our pattern was found at cursor start 19,1.\nHit n and N each a few times to see that both John and Paul at the beginning of the line are matching our regular expression.\nSome matches found at cursor locations:\n 19,1 24,1 59,1 156,1 192,1 209,1 24517,1 24832,1   Note The regular expression ^(John|Paul) needed to be escaped in a way that vim understands. The (, ) and | characters need to be escaped in vim so it doesn’t search for the string representation of those characters.\nThere is a general syntax for regular expressions, however the various tools and programming langauges that implement regular expressions may use the standard regular expression syntax in different ways. This requires escaping to work with regular expressions across tools.\n   Bonus After performing a search both advance to next match (n) and backtrack to previous match (N) can be provided with a numeric prefix (like 5) and the action will be performed the specific number of times.\n  ","description":"","tags":null,"title":"Normal Mode: Search File","uri":"/userspace-applications/walkthrough/vim/normal-search-file/"},{"content":"Bash Shell Variables The Bash shell has numerous variables that contain useful information. They are indicated by the following pattern: $VARIABLE_NAME.\nWe won’t look at all of the Bash Shell Variables, but we would like you to know about four of them:\n $BASH $HOME $PATH $BASHPID  To view the contents of any Bash Shell variable you can simply use the variable as the argument with the echo command.\necho $BASH The $BASH shell variable contains the absolute path to the shell this session is using.\necho $HOME The $HOME shell variable contains the absolute path to the home directory of the user that initiated the Bash shell.\necho $PATH The $PATH shell variable contains a collection of all of the tools currently accessible to this current Bash Shell session.\nAny files and subdirectories found within the listed directories are available to be invoked by name.\n Bonus If you have ever tried to run a program before and received a message about the command not being found in the path, this is what it was referring to. When installing new programming languages, build tools, or really any software that needs to be used from a shell the location of the tool must be added to the path variable. Lots of software installations take care of adding the tool to your path by either editing the PATH variable or by simply adding the binary of the software directly to one of the directories listed in your path.\n  echo $BASHPID The $BASHPID shell variable contains the process ID of the current Bash Shell. This number will likely be different for everyone. In fact if you open your current terminal and open a new one and then check the $BASHPID shell variable you should notice that it is different.\nEvery running program has at least one process running and therefore a process ID. Many programs will create multiple processes and each of their children processes will have unique IDs, however the program’s initial main process is the parent of all other associated process IDs.\n Note We will not be learning about processes in this class. Taking the time to learn about processes will make you a better Linux user, but goes deeper than we need to know in this class.\n  ","description":"","tags":null,"title":"Bash Shell Variables","uri":"/bash-introduction/walkthrough/bash-shell-variables/"},{"content":"Major Concepts \u0026 Key Terminology  Version Control Software  distributed   git repository  local remote   .git/ basic git workflow  add to staging commit to local repository push to remote repository   git status git log forking cloning local repository initialization adding remote repositories branches  master / main remote branch protection   pull requests / merge requests  code review   merging  git merge git rebase    Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Git","uri":"/git/"},{"content":"Removing Packages You can remove a currently installed package with the apt remove [package-name] command.\nLet’s remove the packages we installed in the installation article.\napt remove vim Check that Vim is installed by entering: which vim:\nNow remove the Vim package by entering: sudo apt remove vim:\nConfirm the Vim package removal by entering Y (or simply hitting enter):\nSince there wasn’t a display message about the package being removed enter: which vim:\nThe Vim package is gone!\napt remove gimp Now let’s remove the GIMP package following the same steps.\nConfirm it’s existence: which gimp\nRemove the GIMP package with the auto confirm flag: sudo apt remove gimp -y\nCheck for the package: which gimp\nAnd it’s gone!\napt autoremove The apt CLI also provides an autoremove command.\nLet’s take a look at what this command does by searching the apt Manual Reference for the autoremove command. It may take a second to manually find it, so we provided a picture of the information:\nPretty clearly this tool states that it will automatically remove packages that are no longer needed as dependencies to other packages.\nAs packages are maintained and features added they sometimes will change their package dependencies. The apt autoremove command will automatically find any packages that are currently installed as dependencies to other packages and remove them.\nIn fact if you take another look at the display message when you removed the GIMP package there was a message about running apt autoremove. Let’s look at the picture again:\nThe output is clipped, but it’s a large list of packages that are listed as dependencies for the GIMP package. At the very end of the list there is a statement Use 'sudo apt autoremove' to remove them.. This statement is telling us that when we removed the GIMP package there are still packages on this machine that were installed as dependencies for the GIMP package.\nHowever, you can remove them and free up space on this machine by simply running sudo apt autoremove.\nGive it a try: sudo apt autoremove\nClearly listed are all of the packages that will be removed since they are all flagged as dependencies and the packages that used them as dependencies have since been removed, or no longer require these dependencies.\nThese packages are doing nothing for you so enter y to have the apt CLI remove them:\nThat’s a lot of remove statements in the bash shell output (STDOUT).\n","description":"","tags":null,"title":"Removing Packages","uri":"/package-manager/walkthrough/package-removal/"},{"content":"Bash Aliases One of the hallmark features of Linux and GNU is how customizable and extendable they are.\nIn an earlier demo we saw the instructor create a new program, and add the directory containing the program to their $PATH variable, allowing them to use the program directly from their Bash shell!\nThis section explores creating bash aliases that act as shortcuts to other commands. This is a way you can add some quick functionality to increase your own workflow.\nThe alias command allows you to create a new shortcut keyword that when executed in a Bash shell will execute the command linked to the alias.\nNew displaycontents Bash alias The ls command displays the contents of the current working directory.\nLet’s create a new alias called displaycontents which will simply execute the ls command.\nalias displaycontents=ls\nUpon executing this command nothing was displayed to the terminal, however your current Bash shell session registered a new alias called displaycontents.\nSimply execute your new alias by entering displaycontents\nOur Bash shell has a displaycontents alias registered and it was configured to run the ls command when executed, which you can see happened in the above image.\n Note The displaycontents alias isn’t very useful, but serves as a demonstration for creating and using Bash aliases. Most people will create new aliases when they find themselves using the same complex commands over, and over again as a way of simplifying their work.\n  New greeting Bash alias Let’s create a new alias called greeting.\nalias greeting=\"echo Hello Paul, it is $(date)\"\nNow execute the greeting alias:\nThis is a more complex alias and is doing something we haven’t seen before. Inside of the echo command it is invoking another Bash shell command named date.\n Bonus The syntax $(command) is a Bash shell command substitution. It essentially means the date command is executed first and its output is used in place of the second command being executed which is echo. We will learn more about command substitution and some more advanced Bash features in a later chapter.\n  ","description":"","tags":null,"title":"Bash Aliases","uri":"/file-system/walkthrough/bash-alias/"},{"content":"BONUS This entire section is a bonus. It probably won’t be covered, but you can run the examples to see what is happening, and learn even more about RegEx and sed.\nBonus: Reference Groups Enter a Nickname sed -E 's/(Phillip),(Holmes),/\\1 \"Phil\",\\2,/' user-data.corrected.csv | grep 'Phillip \"Phil\"' The replacement text is:\n \\1: text from first match group  \"Phil\",: the exact string of one space, quotes around Phil and a comma \\2: text from second match group ,: an exact comma  Switch first_name \u0026 last_name columns sed -E 's/^([^,]+,)([^,]+,)/\\2\\1/' user-data.corrected.csv The first_name and last_name columns were switched!\nSwitch all the columns around sed -E 's/^([^,]+),([^,]+),([^,]+),(.*)/\\4,\\2,\\1,\\3/' user-data.corrected.csv Reorders all the records in the file to be:\n Company last_name first_name email   Note Outside of showing how matching groups can be referenced in sed the examples in this article use the -E option which informs sed to run as esed using the extended regular expression syntax. The extended regular expression syntax has different default behavior and changes what symbols need to be escaped. egrep is usually closer to actual RegEx defined syntax than regular grep is. However, they both work.\n  ","description":"","tags":null,"title":"Bonus: Substitute: Reference Match Groups","uri":"/userspace-applications/walkthrough/sed/bonus-substitutue-reference-groups/"},{"content":"kill command The kill command sends signals to a specific process. These signals give you a way to affect the process.\nOne of the most common signals we may want to send to a running process is to end the process. This would immediately stop the process and free up any CPU, RAM, or hard disk operations the process is currently utilizing.\nSending signals to a process is a powerful tool for using Linux. You will not be expected to know the kill command in this class.\nHowever, if you want to try the command out, you can send a signal to your $BASHPID to kill the process.\nTake note of your $BASHPID.\nThen enter kill -9 [your-bash-pid], but enter the number of your $BASHPID.\nUpon entering this command you should see your terminal close immediately!\nOnce you entered the command the Bash Shell sent a SIGKILL (-9) signal to the process associated with your $BASHPID. The SIGKILL signal notifies the operating system the process, and any child processes, needs to be terminated immediately and must be completed. Your operating system acts on the command and the Bash Shell associated with your $BASHPID is closed.\nThere are various other signals that can be sent to processes, but they go beyond the scope of this class.\n Warning Linux will perform whatever commands you instruct it to. You could conceivably start sending SIGKILL signals to random process IDs and Linux will terminate them. Everything running on your operating system has a process ID and you could terminate a process responsible for the Graphical User Interface of your operating system, or some software managing your hardware, which would require you to restart your machine to fix the issue.\n   Bonus If you want to send a SIGKILL signal to your $BASHPID without first looking up the value of the Shell Variable you can do that with a Bash Variable Substitution. You can simply reference the variable directly in a Bash Command!   ","description":"","tags":null,"title":"Bash command: kill","uri":"/bash-introduction/walkthrough/kill/"},{"content":"Upgrading Packages Overtime the packages on your system will need to be upgraded to new versions. All of the packages on your system are maintained by individuals and they may be:\n adding new features fixing bugs patching vulnerabilities optimizing runtime or spacetime complexities  You will most certainly want the security patches and bug fixes, and having the newest features and most optimized version of the package is always nice.\nHow do you upgrade packages?\nFrom the bash shell using the apt CLI upgrade command of course!\nsudo apt upgrade Let’s take a look at the upgrade command definition from the apt CLI Manual Reference page:\nupgrade (apt-get(8))  upgrade is used to install available upgrades of all packages  currently installed on the system from the sources configured via  sources.list(5). New packages will be installed if required to  satisfy dependencies, but existing packages will never be removed.  If an upgrade for a package requires the removal of an installed  package the upgrade for this package isn't performed. So the upgrade command will upgrade all currently installed packages in one fell swoop. It may take it some time to perform this action depending on how many packages needs to be upgraded.\n Note If you want to see all the currently installed packages that have available upgrades run: apt list --upgradeable: There are plenty to choose from.\n  Let’s try out the upgrade command.\nsudo apt upgrade Enter sudo apt upgrade:\nAnd then confirm that you do want to upgrade all packages by entering y or hitting enter.\nUnderstandably, it took some time to perform the apt upgrade command. If you scroll the Bash shell display (STDOUT) you will see many lines describing the actions that were performed as a part of this command.\nHowever, your distribution has been fully upgraded. Since all of our packages have been installed and managed through the apt CLI when you upgrade all installed packages you are performing a full upgrade of your Distribution!\n Bonus You could run sudo apt update -y and apt list --upgradeable again to see if there are any available new package upgrades since you just upgraded. In my case there were a couple of additional package upgrades: However, this is a much smaller list than the 100+ I had earlier. And there’s nothing stopping me from running sudo apt upgrade again!\n  ","description":"","tags":null,"title":"Upgrading Packages","uri":"/package-manager/walkthrough/upgrading-packages/"},{"content":"Major Concepts \u0026 Key Terminology  kernel root user end-user additional users?  service users daemon users   userspace  end-user tools (userspace applications) end-user files    Covered Userspace Applications  wget: download resources via web curl: craft HTTP(s) requests and display HTTP(s) responses grep: search content (using words or regular expressions) sed: edit streams of data (substitute) vim: edit files mail-utils: send emails  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Userspace Applications","uri":"/userspace-applications/"},{"content":"The ~/.bashrc File In your /home/student directory you should find a hidden file called .bashrc.\nThe contents of the ~/.bashrc file are executed as a new user invoked Bash shell is initialized.\nLet’s take a look at the contents of the existing .bashrc file with cat.\nThere is a lot going on in this file that we don’t need to worry about right now. However, if you scroll up you will find a section that looks like this:\n# some more ls aliases alias ll='ls -alF' alias la='ls -A' alias l='ls -CF' There are a few Bash aliases already programmed into our Bash shell. We should be able to execute them since the .bashrc file was run when our Bash shell session was being initialized.\nLet’s try them out.\nExecute ll Execute la Execute l Without defining any of the aliases they were still loaded into our Bash shell session because they exist in ~/.bashrc file which was run upon initializing our current Bash shell session!\nUses of ~/.bashrc Any personal changes you would want to make to your Bash shell sessions would go in this file. Those changes may include:\n Creating new Shell variables Editing any existing Shell variables (like adding your own personal /home/student/bin to only your $PATH variable) Adding any personal use Bash aliases Changing the color scheme of your terminal  Really anything you would want to happen as your Bash shell session initializes would go into your personal ~/.bashrc file.\n","description":"","tags":null,"title":"Bashrc","uri":"/file-system/walkthrough/bashrc/"},{"content":"Major Concepts \u0026 Key Terminology  Bash Scripting basics How to create and reference bash variables Bash Conditional Statements:  if statements if / else statements if / elif / else statements   Looping with Bash  for loops  for loops with conditional statements   while loops  while loops with conditional statements      Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Bash: Scripting","uri":"/bash-scripting/"},{"content":"which command Most of the commands we have learned about in this class come standard as a part of the Ubuntu distribution we have been using. We will eventually learn about adding new commands and tools to our existing distribution. It is important to know the specific location of a command on your computer, something we can locate easily by using the which command.\nThe which command will give you the absolute path of the file that is being used to execute the instructions.\nLet’s find out where the ls command’s binary lives.\nEnter which ls.\nAccording to the which command ls resides in /usr/bin/ls.\n Note In Linux when you see something named bin it is almost always short for the word binary. A binary file is a file that is not readable to humans. Many binary files are executable programs. In fact, looking into the /usr/bin and /bin directories you may see the names of many executable programs that we have already used in this class!\n  which which? What about the which command? It is also an executable command so it should also have a location on our machine. How can we figure out where the which command resides?\nIt looks like the which command is also an executable binary located in /usr/bin.\n","description":"","tags":null,"title":"Bash command: which","uri":"/bash-introduction/walkthrough/which/"},{"content":"Example: Adding New Package Repository \u0026 Package In some cases you may want to add a new third party Package. You could do so manually by downloading the package, manually building the tool and then adding the tool to your $PATH.\nHowever, when you need to update the new package you would have to replicate the steps after removing the old version.\nMany third party tools provide a Package Repository that you can simply add to your list of user-defined Package Repositories. Then you can manage its installation, upgrading, and removal all from the Package Manager CLI.\n Note This specific course will not touch Docker at all. Docker provides excellent documentation and their website provides exact instructions for adding their package repository and installing their package in Ubuntu (and other popular Linux distributions). When you have some free time you should glance over the original Install Docker Engine on Ubuntu documentation this article is based on.\n  This article will walk you through the steps and explain what is happening. The linked Docker Docs article provides the following steps:\nSet up the repository  Update the apt package index and install packages to allow apt to use a repository over HTTPS Add Docker’s official GPG key Set up the stable repository  Install Docker Engine  Update the apt package index, and install the latest version of Docker Engine and containerd Install the docker-ce docker-ce-cli and containerd.io packages  Setup the Docker Repository The Docker Docs article beings with instructions around setting up the package repository. We could just run the command, or we can use some of our new Linux skills to check to see if we already have the packages that are being installed.\nWe will:\n Update Package Repository List Check for Installed Packages Install any Required Packages Add Docker’s official GPG key Add the Docker stable repository  Update Package Repository List Before adding any additional packages, or adding a new package repository it’s a good idea to update existing package repositories.\nsudo apt update -y Check for Tools Necessary for Adding Repository Our first divergence from the Docker instructions.\nTo add the Docker Package Repository we will need a few command line tools. Most of the required packages come pre-installed as a part of Ubuntu 22.04\n Note The Docker Installation Guide makes no assumptions about your current distribution. So they include a snippet that installs all of the tools. When you use apt to install a tool that already exists, it doesn’t throw an error, and will not stop the remaining tools from installing.\n  As the user of our machine it is our responsibility, and a good chance to practice, to ensure all of the tools are properly installed.\nWe will need to figure out if the following packages are installed, and if not to install them:\n ca-certificates curl gnupg lsb-release  ca-certificates What command can we run to determine if the ca-certificates package is currently installed:\napt list ca-certificates After running this command we can see the output:\nIt looks like the ca-certificates package is automatically installed as a part of this distribution.\nWhat happens if we try to install it anyway?\nsudo apt install ca-certificates curl What command can we run to determine if the curl package is currently installed:\napt list curl After running this command we can see the output:\nIt looks like the curl package is not currently installed on this distribution.\nHow can it be installed with apt?\nsudo apt install curl  Note Don’t forget we will have to confirm the installation by entering y and hitting enter, or by simply hitting enter.\n  gnupg What command can we run to determine if the gnupg package is currently installed:\napt list gnupg After running this command we can see the output:\nIt looks like the gnupg package is automatically installed as a part of this distribution.\nWhat happens if we try to install it anyway?\nsudo apt install gnupg lsb-release What command can we run to determine if the lsb-release package is currently installed:\napt list lsb-release After running this command we can see the output:\nIt looks like the lsb-release package is automatically installed as a part of this distribution.\nWhat happens if we try to install it anyway?\nsudo apt install lsb-release Add Docker’s GPG Key After checking for and installing the prerequisite packages we need to add Docker’s GPG key.\nGPG stands for GNU Privacy Guard. It is an implementation of OpenPGP which allows you to asymmetrically encrypt data and create and authenticate digital signatures.\n Bonus GPG works by having two linked keys a public key, and a private key. A public key can be shared with anyone, the private key remains secret and in the control of an individual. Data can be encrypted by either the public or private key and key be decrypted by the alternate key. Because of this encryption a user can create a digital signature that the other party can decrypt and verify.\n  In this specific case (adding a package repository from Docker) we are adding the Docker public key to our gnupg keychain. This way docker can create a digital signature (using their private key) that we can verify (using our public key). Docker can also encrypt (using their private key) the payload of data and we can decrypt (using our public key) the data.\nThe command for requesting the Docker public gpg key and adding it to our personal pgp keyring is as follows:\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg That is a complex command that is using the pipe (|) operator. Which means the output from the first command is being passed as the input to the second command.\nLet’s break these commands down to get a better understanding of what’s happening.\nCommand Breakdown curl makes web requests from the terminal. The curl https://download.docker/com/linux/ubuntu/gpg command is requesting Docker’s public key to be printed out to the terminal (STDOUT).\n Bonus You can run curl https://download.docker.com/linux/ubuntu/gpg by itself to see the actual key. We don’t need to understand this key, we simply need it to verify Docker’s signature.\n  The output (the text of the key listed in the picture above) is being passed to the next command sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg.\nThis command is packing the key into the proper format (.gpg) and then writing the key to the file: /usr/share/keyrings/docker-archive-keyring.gpg.\nAfter running the full command, the Docker public key is now on our gpg keyring and will be used to verify any signatures from Docker!\nAdd the Docker stable Repository Now that we have the Docker public key on our keyring we can add the Docker repository to our computer. It’s another complex command we will break down:\necho \"deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null Wow, that’s a lot of stuff packed into one line. Let’s break it down.\nCommand Breakdown In the command there are two Bash operators (| and \u003e), meaning there are three separate bash commands. Let’s look at them one at a time:\nThe Pipe Operator (|) passes the output from the first command and uses it as the input for the next command.\nThe Output Redirection Operator (\u003e) passes the output from the first command to be written as a file in the second command.\nThe echo ... portion The echo command is just displaying something to the Bash shell’s display (STDOUT).\nYou can run this part of the command completely on your own to see the contents of this command:\necho \"deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\" Which results in the following output:\nThe output is difficult to see so we will share it here:\ndeb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu jammy stable Overall it’s a simple line. One line of output that contains:\n the architecture of our computer (amd64) the key to use when using this repo (docker-archive-keyring.gpg) the package repo URL (https://download.docker.com/linux/ubuntu) our distributions canonical name (jammy) the type of repository to add (stable)  This is the information necessary for a package repository to work.\n Bonus This information is eerily similar to the Ubuntu provided package repositories that come standard with your distribution. Print out the contents of the package repositories in /etc/apt/sources.list with cat /etc/apt/sources.list. There are multiple uncommented out lines that are similar to the line we just printed out.\n  The sudo tee ... portion The output from the previous echo command is passed to: sudo tee /etc/apt/sources.list.d/docker.list.\nBy simply taking a look at the tee package’s man page we will see it’s description:\nIt reads from standard input (the result of the echo command in the previous step) and writes it to a file in this case etc/apt/sources.list.d/docker. So the contents we printed to our display in the previous step will simply be written to this new file.\nThe /dev/null portion Finally a really weird section the output from the previous tee command is being directed to a file called /dev/null.\n/dev/null is a special file that when you write to it the contents are immediately deleted.\nThe tee command expects to write the result of creating the new file to a completely different file and will throw an error if the results aren’t written somewhere.\nSo we are using the /dev/null file as a location to write the expected output, where it is immediately discarded.\nInstall the Docker Tools Now that we have written the package repository to the appropriate location /etc/apt/sources.list.d/docker we can use the package repository to install and maintain the packages associated with that repo.\nUpdate the Package Repository List Not only is a good idea to update our package repository list, but we need to because we just added a brand new package repository, and we need to instruct the apt CLI to update itself.\nsudo apt update -y Install the Packages with apt Finally we can install the packages associated with docker using the apt CLI.\nsudo apt install docker-ce docker-ce-cli containerd.io Review We have successfully:\n web requested the Docker public key added the Docker public key to our gpg keyring added the Docker Package Repository installed Docker and associated packages using the apt CLI  ","description":"","tags":null,"title":"Adding Package \u0026 Repository","uri":"/package-manager/walkthrough/adding-repo-and-package/"},{"content":"A common way systemd is used with regards to web development is to strengthen the deployment of a web app.\nCaddy and NGINX come pre-configured as services that will restart when failed.\nHowever, if you are using one of these web servers to reverse proxy to your own application server you are also responsible for ensuring the application server will restart when failed. You are also responsible for ensuring the application server will start if the computer itself crashes and reboots.\nThis can be done easily using systemd. You can define a unit-file for your application, configure it to restart on failure, configure it to start on machine reboot. This will make the application available even if the application framework crashes (maybe because it ran out of RAM), or if the machine powers down and back up (maybe because a power outage happened).\nThis article will walk through creating a service out of a Spring application.\nSetup You will be running the spring-techjobs-mvc application that was deployed in the NGINX Reverse Proxy article. You may already have the artifact you will need on your computer, check in your home directory for a directory named spring-techjobs-mvc-artifact/.\nClone If Necessary If you do not have the artifact you will need to clone the repository that contains the artifact:\ngit clone https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact Install JRE 11 If Necessary If you do not already have the OpenJDK-11 JRE installed on your computer you can install it with:\nsudo apt update -y sudo apt install openjdk-11-jre Write Unit File Create a file named techjobs-mvc.service in /etc/systemd/system/:\nsudo touch /etc/systemd/system/techjobs-mvc.service Add the following contents to the file:\n[Unit] Description=TechJobs MVC LaunchCode Style!  [Service] ExecStart=/usr/bin/java -jar /home/student/spring-techjobs-mvc-artifact/spring-mvc.jar Restart=on-failure  [Install] WantedBy=multi-user.target Start Unit systemctl status techjobs-mvc sudo systemctl start techjobs-mvc After starting the unit the application should be available in your browser at port 8080.\n Warning If your application did not start it is likely port 8080 is currently being used. You can stop whatever process is running on that port in multiple ways. The easiest would be to reboot the virtual machine. Another would be to detect the PID of whatever is running on port 8080 and send a SIGNAL to stop it:\nsudo lsof -ti :8080 sudo kill -9 [output from previous command]    Enable Unit sudo systemctl enable techjobs-mvc Now that systemd has been instructed to restart the service when it fails, and to automatically start the service on computer boot, the application will restart itself if it crashes for any reason, and it will begin if the server itself ever crashes! Try killing the PID of the service and rebooting your computer and the application will still be available.\n Bonus If you have previous configured a web server like NGINX or Caddy to reverse proxy to an application running on port 8080 and the web server is currently running you will be able to access this spring application on port 80 in addition to port 8080. This is demonstrating how an application would be deployed on a server and made accessible through the internet!\n  ","description":"","tags":null,"title":"Spring Unit File","uri":"/systemd/walkthrough/spring-unit-file/"},{"content":"Getting Help There are tons of commands you can use in Linux. It would take an enormous amount of time for any person to learn all of them.\nLuckily, Linux and GNU have provided multiple ways for us to learn about the various commands we may want to use.\nman command The man command is used to bring up the reference manual for any given command. These reference manuals are often called man pages\nLet’s take a look at the man page for the which command.\nEnter man which.\nThe output of our screen changed considerably. We no longer have a means for entering commands. We are looking at a less display screen. We will learn about less in a future lesson. You can move up and down on this page with the directional keys. Alternatively you can use the j key to move down, and the k to move up.\nThe second thing to notice is how much useful information is being provided about the which command. This man page contains a Synopsis giving a brief example of how you can use the command. It also contains a highly beneficial description that goes far beyond what we learned just a moment ago. All of the explanations are listed for each option.\nThe man pages are one of the most powerful tools for learning, or remembering, how to use a command effectively.\nTo exit the man pages you simply need to press the q key on your keyboard.\n Bonus Checkout the man pages of the additional commands you have learned about in this class.\n  --help option The man pages are exhaustive and provide additional context, that can sometimes be distracting when you are solving a problem in the moment.\nMany commands contain a --help or -h option that will give you an abbreviated list of the most common options or arguments you may want to use.\nEnter ls --help.\nAfter scrolling to the top of the STDOUT we can see a shortened version of the man page. A brief description, and a list of options. All of this without leaving our terminal!\nThe --help flag isn’t enabled for all commands, but can provide assistance in a pinch.\n","description":"","tags":null,"title":"Getting Help","uri":"/bash-introduction/walkthrough/getting-help/"},{"content":"Major Concepts \u0026 Key Terminology  task scheduling cron cronjob crontab  syntax    Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"Cron","uri":"/cron/"},{"content":"The sudo command The sudo command stands for SUbstitute User Do. It allows you to run any Bash command as a substitute user.\nThe sudo command is most commonly used to run a command as the root user that has full permissions to everything on the machine.\n Note When using the sudo command to execute a command as a different user, your user must be in the sudoers file. You will be prompted to enter your password to authenticate the user and execute a command as another user. Ubuntu by default adds all new general users to the sudoers file. There is a sudoer bash command for managing the sudoers file. The sudoer file exists in the /etc directory.\n  Let’s take a look at how to use the powerful sudo command.\nThe whoami command The whoami command simply displays the current user.\nGo ahead and execute the whoami command:\nThis makes a lot of sense. We are the student user.\nThe whoami command as the daemon user Run the same command this time as the daemon user.\nExecute sudo -u daemon whoami:\nYou will be prompted to enter your password, which if you followed the configuration guide in this course should be admin. As you type nothing will be displayed on the terminal, this is a security feature so someone that can see your terminal will not know what your password is. After typing your password hit enter. Assuming your password was correct you should see the following:\nAs we can see we ran the whoami command as the daemon user and so the display reads daemon.\nThe whoami command as the root user Execute sudo whoami:\nThe default for the sudo command is to execute the command as the root user.\nUsing sudo Running a command as the root user is sometimes necessary. You may need to read, or edit a file that your current user doesn’t have read or write access to. However, the root user always has read, write, and execute access to all files. Making sudo [command] a very useful tool to have in your pocket.\nAs an example let’s say we needed to read the contents of the mysterious /etc/shadow file.\nOur student user doesn’t have read access to this file. So we can run the same command as root.\nsudo cat /etc/shadow\nRunning the command as the root user gave me read access to the file. General user’s do not have read access to this file because the file lists all users and their hashed password.\nYou can see clearly that the student user’s hashed password is: $6$YQsJ8yJfzXt5L....\n Bonus A hashed password can be cracked using a rainbow table, which goes way outside the scope of this class. However, knowing that a hashed password can be cracked illustrates why general users do not have access to read the /etc/shadow file.\n  ","description":"","tags":null,"title":"Sudo","uri":"/file-system/walkthrough/sudo/"},{"content":"Major Concepts \u0026 Key Terminology  Web Servers Used in this Course:  Caddy HTTP, automatic HTTPS, and reverse proxy server to serve web applications  Caddyfile: config file required for caddy caddy reload: command to reload web server with config file updates   NGINX - HTTP, HTTPS, and reverse proxy server to serve web applications  .conf file: config file required for nginx nginx -s reload: command to reload web server with config file updates      Content Links Caddy NGINX Exercises Next Steps  ","description":"","tags":null,"title":"Web Servers","uri":"/web-server/"},{"content":"Review We covered a lot of ground in this walkthrough. Look over the following list of terms used throughout this article:\n Shell Terminal Emulator Bash Shell Bash Commands  argument(s) option(s) pwd clear ls echo which   Shell Variables  $BASH $HOME $PATH $BASHPID   Manual Pages  man filename   --help  command --help    In a future lesson we will learn even more about the Bash Shell in the form of file-system navigation, and file/directory creation, editing, and deleting.\n","description":"","tags":null,"title":"Review","uri":"/bash-introduction/walkthrough/review/"},{"content":"Create a Pull Request Click the 3 branches section.\nOpen a pull request for the new-feature branch.\nClick the New pull request for the new-feature branch.\n Note You will notice that is says “There isn’t anything to compare.”. You need to change the base repository option to your personal github repo.\n  Click [your-github-username]/py-demo-web-logs-continued\n Note You will also need to select a different base reference.\n  Select master as the base branch reference.\nLastly we will be able to create a pull request:\nClick the Create pull request button.\nMerge pull request Since the new-feature branch did not have any conflicts with the master branch we can merge it automatically.\nClick the Merge pull request button.\nConfirm the merge Click Confirm merge\nDelete Merged Branch Now that the new-feature branch has been merged into the master branch it can be safely deleted.\n Bonus Deleting the branch on the remote repository will only delete the remote branch. You will still have access to this branch locally.\n  Click the Delete branch button.\n","description":"","tags":null,"title":"PR brief walkthrough","uri":"/git/walkthrough/merging/pull-request-hidden/"},{"content":"Major Concepts \u0026 Key Terminology  systemd is responsible for initializing and managing daemons and services  initialize daemons and services at various machine states (most commonly power-on but also power-off, user login, user logout, machine crash, kernel panic, etc) manage ongoing services \u0026 daemons  handle service \u0026 daemon dependencies directly control services \u0026 daemons     initialization system  systemd Init V   daemon: computer program that runs as a background process service: computer program that responds to requests from other computer programs where system daemon and service files live (existing services and daemons)  from https://www.enricozini.org/blog/2017/debian/systemd-01-intro/ linked from official debian systemd docs /lib/systemd/system/: for units provided by packaged software /run/systemd/system/: runtime-generated units /etc/systemd/system/: for units provided by systemd administrators (always a part of the system unit cache)   defining custom daemon or service with a unit file where personal unit files should live:  /etc/systemd/user (only a part of the unit cache when certain shell variables are true, like when the user is logged in) $HOME/.config/systemd/user (only a part of the unit cache when certain shell variables are true, like when the user is logged in) can technically live anywhere, they just have to be linked to correctly so systemd can find them on boot   systemctl  start stop enable disable status   journalctl  Content Links Walkthrough Exercises Next Steps  ","description":"","tags":null,"title":"systemd","uri":"/systemd/"},{"content":"Recap This class has touched many subjects:\n terminal bash bash streams, redirection \u0026 pipes Linux file system \u0026 permissions package manager version control bash scripting cron web servers systemd additional user space applications  At this point multiple web projects have been deployed to your Linux machine.\nGoing through the concepts and practicing is how you will become comfortable with the concepts and skills in this course.\nFor your final project you will be required to create two initialization scripts.\nAn initialization script is a bash script that is executed after a new virtual machine is created and configures the machine completely and automatically.\nOnce you have an initialization script for a specific project you can spin up a new Ubuntu machine on any device and run one script which will go through all the steps necessary to deploy a project. Initialization scripts are used commonly in the cloud computing world.\nThe Scripts  react-tic-tac-toe-configuration-and-deployment.sh spring-todo-mvc-configuration-and-deployment.sh  React Create an initialization script that when run on a new Ubuntu 22.04 image configures the machine and deploys the react-tic-tac-toe-tutorial project.\nSpring Create an initialization script that when run on a new Ubuntu 22.04 image configures the machine and deploys the spring-todo-mvc project.\n Note More information about each required deployment will be provided in an upcoming article.\n  Example Initialization Script As you have not seen an example of an initialization script we will provide one example for the angular-tour-of-heroes project in the next article.\n Note You are more than welcome to look at the example before starting to write your own initialization scripts, but if you feel like you have an idea of how to begin we recommended starting with your ideas first and referencing the example only when necessary.\n  Content Links Example: Angular Initialization Script React Initialization Script Spring Initialization Script Bonus: Build Artifacts Bonus: Redeployment Script Next Steps  ","description":"","tags":null,"title":"Final Project","uri":"/final-project/"},{"content":"At Least One, Possibly More + curl -s https://launchcodetechnicaltraining.org/api/walkthrough/transaction?data_format=csv | grep '\\$5[0-9]\\+' Maybe One, Possibly More * curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '^Paula*' Match Exact Number {}  Bonus echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paul' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paul$' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paula$' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paula*$' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paula\\+$' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paula\\{1\\}$' echo -e \"Paul\\nPaula\\nPaulaaaaaa\\nTim\" | grep '^Paula\\{6\\}$'    Regular Expression Groups () curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '\\(Paul\\|John\\)' curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '^\\(Paul\\|John\\),' curl -s https://launchcodetechnicaltraining.org/api/walkthrough/user?data_format=csv | grep '\\(Accenture\\|Boeing|)$' ","description":"","tags":null,"title":"Bonus Regular Expressions","uri":"/userspace-applications/walkthrough/grep/bonus/"},{"content":"Next Steps vim is a powerful text editing tool. We have barely touched the surface on what you can do with this text editor.\nIf you’d like to learn more we recommend going through the vimtutor application. It comes standard with the vim package.\n Bonus You can access vimtutor from your terminal by entering vimtutor. This will lock your terminal into vimtutor until you exit the package.\n  ","description":"","tags":null,"title":"Next Steps","uri":"/userspace-applications/walkthrough/vim/next-steps/"},{"content":"Next Steps How can they use concepts and skills in this class?  use a linux system as an end user ability to use and learn more about:  package manager userspace applications web servers scheduling recurring tasks with cron hardening deployments by utilizing systemd ability to parse bash scripts ability to create \u0026 execute bash scripts    Where do these skills lead?  cloud deployments CI/CD Further virtualization (Docker)  container orchestration (Kubernetes)   Intermediate Scripting Linux Systems Administration Linux System Automation  How can they apply this knowledge to professional projects?  Basic skills for deploying static websites Basic skills for deploying and reverse proxying to application servers Ability to read, parse, create, and execute bash scripts Understanding and ability to collaborate effectively with git  How can they apply this knowledge to personal projects?  Basic skills for deploying static websites Basic skills for deploying and reverse proxying to application servers Ability to read, parse, create, and execute bash scripts Understanding and ability to use git for version control  Learning More list some resources for furthering knowledge and skills for:\n GNU/Linux Bash scripting Web Servers Web Deployments Scheduling tasks Initialization Tooling Version Control  ","description":"","tags":null,"title":"Next Steps","uri":"/final-project/next-steps/"},{"content":"Content Links Quality of Life Improvement Articles  ","description":"","tags":null,"title":"Quality of Life Improvements","uri":"/quality-of-life/"},{"content":"Ways to Contribute Suggest a Change to a Page Creating a GitHub Issue  ","description":"","tags":null,"title":"Contributing to this Project","uri":"/contributing/"},{"content":"Linux What is this Course This course is an introduction to the Linux and the Command Line.\nThis course is designed to provide an understanding of the fundamental skills necessary to deploy web applications to a server using a Linux Operating System. You will learn about many of the operational tools used when working with a server.\nWhy take this Course Learning how to give instructions to a computer so that it performs any given task is the job of someone who works in tech. In this course you will learn and practice giving text based commands to a computer using the terminal to accomplish tasks.\n Note You have likely learned a programming language in the past. Programming languages are a great way to create applications that run on a computer that usually serve a third party user. Working with a terminal is a way of providing exact instructions to a computer with you as the end user.\n  Linux can be used in many ways to solve many problems, but we will specifically be learning Linux to serve as the deployment environment for web applications.\nYou will learn:\n How to Create, Read, Update, and Delete files with the Linux file system How to deploy a React project, Angular project, Spring project, and .NET project. How to configure a production grade web server (Caddy, NGINX) Package managers How to automate tedious tasks with bash scripting How to schedule tasks to execute at a specific time or on a recurring schedule How to configure a service to start upon system boot or failure How to craft http requests and render responses from a terminal How to search files or terminal output Git Basics and Collaborative strategies   Note A large percentage of cloud resources are Linux based.\nThese resources talk about the prevelence of Linux in cloud computing:\n Red Hat Linux Article: zdnet     Where this Course leads Upon completing this course you will be capable of configuring a server with deployed web applications.\nThe next step would be to learn cloud basics so that you can make the deployed application available on the internet.\nAdditionally this leads to:\n Operations Docker/Containers CI/CD Pipelines  Segments / Chapters One Week Schedule Configurations Introduction Bash: Introduction Bash: Streams, Redirection \u0026 Pipes File System File Permissions Package Manager Git Userspace Applications Bash: Scripting Cron Web Servers systemd Final Project  Pre-Course Requirements The only dependancy for this class is that you have VirtualBox installed on your machine and you are able to run Ubuntu 22.04. The configurations walkthrough will take you through the steps for both Windows and MacOS installations.\nConfigurations  Configurations Home  VirtualBox Download \u0026 Installation Ubuntu Image in VirtualBox    ","description":"","tags":null,"title":"Home","uri":"/"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"}]