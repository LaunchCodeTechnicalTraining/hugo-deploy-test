[{"content":"AWS Basics Welcome! This course will be exploring Amazon Web Services (AWS). The course will cover many key elements of AWS, some of the problems you can solve using this tool, and most importantly you will be getting hands on practice with this very commonly used tool.\nBrief History Amazon first began offering Information Technology services in 2006. The goal was to create a platform that allowed businesses and individuals alike to replace any infrastructure or on-premise servers with virtaul servers provided by AWS.\nAmazon created this platform as a low-cost alternative within the cloud that is highly scalable, reliable, and performance optimized.\nAmazon Elastic Compute Cloud and Amazon S3 are among the first services provided by AWS. These first-generation services are still used to this day but have of course changed over time.\nMajor Concepts \u0026 Key Terminology  Amazon Web Services Amazon Elastic Compute Cloud (Amazon EC2) Amazon Simple Storage Service (Amazon S3) AWS Web Console  ","description":"","tags":null,"title":"Introduction","uri":"/aws-basics/introduction/"},{"content":"AWS EC2 RDS Deployment Notes RDS Creation Method: Easy Create\n database identifier: database-1 Recommended best practices Some options can be changed after creation  Configuartion:\n Engine Type: PostgreSQL 13.4-R1 DB Instance Size: Free tier Db Instance idenfitifer: Name of database Master Username: username  Instance Configuartion:\n EC2 Instance Type: db.t3.micro  Storage:\n Storage Type: General Purpose SSD (gp2) Allocated Storage: 20 (default minimum) Storage Autoscaling: Disabled Maximum Threshhold: Removed when disabling Storage Autoscaling  Connectivity:\n VPC: Subnet Group: Public Access: No is the default setting VPC Security Group: Created new: rds-public-access Availability Zone: us-east-1a Database port: 5432  Database Options:\n initial database name: students db param group: default.postgres13  Content Links  ","description":"","tags":null,"title":"Public RDS","uri":"/aws-basics/ec2-rds/public-rds/"},{"content":"Launching Your First Instance Now that you are ready to launch your first instance there will be some options for us to select. The options we will be focusing on are as follows:\n Name of Instance AMI: Amazon Machine Image Instance Type Key Pair Security Group  Name and AMI The first step is to provide your new EC2 instance with a name and select an AMI.\nFor your first EC2 instance provide the name my-first-instance\nFrom the quick start menu select Ubuntu with the newest 22.04 LTS as the version.\nInstance Type Next you will select the type of instance for your image.\nFor this walkthrough you will be using the t2.micro which is Free tier eligible.\nSSH Key Pair In order to access our machine through the terminal you will need to provide an ssh key pair. Since this is your first time launching a new instance you will be creating a new key pair value.\nClick on the Create new key pair button.\nCreating a new SSH Key Pair Provide the name first-key-pair.\nYou will be leaving the Key pair type as RSA and the file format as a .pem file.\n Note After you click Create key pair it will download a new file to your machine called first-key-pair.pem. You will need access to this file in order to ssh into your new machine in the future. So make sure you know where it is located!\n  Click the Create key pair button.\nNetwork Settings Storage ","description":"","tags":null,"title":"First EC2 Instance","uri":"/aws-basics/ec2-web-console/walkthrough/first-instance-launch/"},{"content":"Deploying a Persistent Spring Boot Application Now that you have worked closely with the EC2 and S3 service it is time to take things one step further. You are going to deploy a web application that is connected to a MySQL database.\nBelow you will find the steps outlined.\nGetting Organized What needs to happen for the Java/Spring Persistent web application to be deployed?\nYou will need:\n New EC2 Instance Built Artifacts of application cloned to EC2 instance Correct version of Java installed on EC2 Web Server installed on EC2 Docker installed to create a MySQL container for the database  EC2 Instance Created  Name of Instance: java-spring-persistent AMI: Ubuntu 22.04 Instance Type: t2 micro Key Pair: Not Required Security Group: New Security Group:  HTTP enabled    After creating your new EC2 you can now use EC2 Instance Connect to connect to your virtual server.\nProject Artifacts The artifacts are already built, they just need to be installed onto the virtual machine with git.\n use git to clone the build artifacts   Note Build artifacts for this deployment: https://github.com/LaunchCodeTechnicalTraining/java-techjobs-persistent-artifacts\n  Java This application uses Java 11. To install the correct version of Java you will be using your package manager.\nRun the following command within the EC2 instance through EC2 Instance Connect\nsudo apt install openjdk-11-jre -y Web Server caddy, nginx, or some other web server must be installed to catch HTTP requests and respond as a reverse_proxy to our running application.\nBonus You can find Installation steps and further information for both caddy and nginx here:\n Caddy Installation Nginx Installation    Docker Installation In order to keep everything inside of our virtual-server you will be utilizing Docker to run a MySQL container.\nThis allows us to create a MySQL container inside of our virtual-server and configure it’s settings so that our Java application is able to connect to it.\n Note docker is an extremely useful tool and can be utilized in many different ways. To cover its entire purpose and numerous use cases is outside of the scope of this class.\nIf you would like to continue reading and learn more about docker you can find the documentation here: docker docs\n  sudo apt update -y  sudo apt install apt-transport-https ca-certificates curl software-properties-common  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  echo \"deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null  sudo apt update -y  apt-cache policy docker-ce  sudo apt install docker-ce Starting the Application Now that you have:\n Created a new EC2  Cloned the build artifacts Installed Java Installed a Web Server Installed docker    You are ready to do the following:\n Create a MySQL container using docker Start the Java-Spring application Configure the Web Server Access the running application in your browser  Creating the MySQL Docker Container Environment Variables: docker allows the user to provide enviroment variables when creating the MySQL container.\nThe available environment variables you will be using are as follows:\n MYSQL_ROOT_PASSWORD: Required variable when creating a MySQL docker container MYSQL_USER: Specifies username for database MYSQL_PASSWORD: Specifies password for the username MYSQL_DATABASE: Specifies name of database  Run the below command to create the MySQL container:\nsudo docker run --name name-of-container -p 3306:3306 -e MYSQL_ROOT_PASSWORD=\"admin\" -e MYSQL_USER=\"techjobs\" -e MYSQL_PASSWORD=\"tech\" -e MYSQL_DATABASE=\"techjobs\" -d mysql Breakdown of command:\n sudo docker run --name name-of-container: Creating a new container with any provided name -p 3306:3306: specifying what port the database can be accessed -e MYSQL_ROOT_PASSWORD=\"admin\" -e MYSQL_USER=\"techjobs\": Environment variables with values -d mysql: targeting MySQL docker image  Bonus If you would like to read the documentation for the MySQL docker image you can find the information here:\nDocker MySQL Image Docs\n  Starting Java-Spring Application This application was created using environment variables in order to connect to the MySQL database.\nSimilar to creating the docker image you will need to assign the variables values when starting the java application.\nThe available environment variables you will be using are as follows:\n RDS_ENDPOINT: Endpoint for MySQL database. This value will be the auto-assigned ipv4-address of your EC2 instance DB_PORT: Port MySQL is running on (3306) DB_NAME: Name of database DB_USERNAME: Username DB_PASSWORD: Password SERVER_PORT: Designated Port that you want the application to run on.  Run the following command to boot your Java-Spring project and connect to the MySQL database:\njava -DRDS_ENDPOINT=\"ipv4-address\" -DDB_PORT=\"3306\" -DDB_NAME=\"techjobs\" -DDB_USERNAME=\"techjobs\" -DDB_PASSWORD=\"tech\" -DSERVER_PORT=\"8080\" -jar path/to/build/artifacts/java-techjobs-persistent-artifacts.jar   Warning You will need to replace the -DRDS_ENDPOINT=\"ipv4-address\" with the public ipv4-address of your EC2!\nYou will also need to specify the path to the .jar file within your EC2 instance.\n  Configure Web Server This walkthrough will utilize caddy for the web server.\nYou will need to edit the default caddy file. This walkthrough utilizes vim to edit the file.\nBonus If you need a refresher on vim or are unfamiliar with the tool you can find useful information here:\nVim Walkthrough / Introduction\n  Run the following command:\nsudo vim /etc/caddy/Caddyfile Remove all content within the file.\nAdd the following content:\nyour-public-ipv4-address {  reverse_proxy 127.0.0.1:8080 } Write and Quit the file.\nReload Caddy In order for the changes you made to the default caddy file to take effect you will need to reload caddy.\nRun the following command:\nsudo caddy reload --config /etc/caddy/Caddyfile    Click here for Caddy Troubleshooting  If you are having issues with caddy you may need to run the following commands.\nsudo systemctl stop caddy sudo caddy start sudo caddy reload --config /etc/caddy/Caddyfile    Running Application After completing the above steps you should now be able to open your browser to the public-ipv4 address of your EC2 instance to view the running application.\n","description":"","tags":null,"title":"Java Spring Persistent","uri":"/aws-basics/final-project/java-spring-persistent/java-techjobs/"},{"content":"Reverse Proxy for MVC Application This walkthrough will take a Java/Spring application and proxy the HTTP requests to the running application server.\n Note The build artifacts for this walkthrough are located here: https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact\n  Machine Settings Create a new EC2 instance with the following:\n Name: your-ec2-name AMI: Ubuntu 22.04 LTS Instance Type: t2-micro (free tier) Key Pair: Proceed without a key pair Network Settings:  VPC: Default Subnet: Default Auto-assign public IP: Enabled Create Security Group  Allow SSH traffic Allow HTTPs traffic Allow HTTP traffic     Storage: Default settings Advanced Details: Default settings  Connecting to EC2 Instance After the EC2 has been created navigate to the dashboard of the EC2 instance.\nClick on the connect button which will take you to the Connect to Instance page.\nVerify your settings are similar to the above screenshot within the EC2 Instance Connect tab.\nClick the Connect button.\nNow that you have connected to your instance it is always good practive to update your server.\nRun the following command:\nsudo apt update -y Project Requirements In order start our Java/Spring application you will need the following:\n Project Artifacts cloned  https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact   open-jdk installed  openjdk-11-jre   Web Server Installed (Caddy)  Web Server configured (Caddy)    Clone Project Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/spring-techjobs-mvc-artifact Install Java SDK sudo apt install openjdk-11-jre Validate that it was installed correctly with the following commands:\nwhich java java --version  Note You can see that the openjdk-11 Runtime Environment was installed correctly. This will allow us to start our Java project using the build artifacts provided.\n  Install Caddy sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update sudo apt install caddy   Note Verify that caddy was installed using the following commands:\n  which caddy caddy version Configure Web Server Now that you have cloned the project build artifacts in addition to installing the correct Java runtime environment and Web Server you need to configure your Caddyfile.\n Note The Spring project will be running on port 8080. That means you will need to configure a reverse proxy within your Caddyfile to handle the HTTP requests to port 8080 on the running server.\n  Run the following command to open your default Caddyfile:\nsudo vim /etc/caddy/Caddyfile Remove all content within the file and overwrite it with the following:\nBonus If you need a refresher on how to use vim you can visit the Linux curriculum here: Vim Introduction\n  http://your-public-ipv4-address {  reverse_proxy 127.0.0.1:8080 } After making changes to your Caddyfile you will need to reload it with the following command:\nsudo caddy reload --config /etc/caddy/Caddyfile Start Java/Spring Application Now that the web server is configured you are ready to start your application.\nNavigate to your spring-techjobs-mvc-artifacts directory and run the following command:\njava -jar spring-mvc.jar Validation Now that the application is up and running you should be able to access it within your browser.\nOpen a new browser window and access the application at http://your-public-ipv4-address\n","description":"","tags":null,"title":"Java Spring MVC","uri":"/aws-basics/ec2-web-console/walkthrough/reverse-proxy-websites/java-spring/"},{"content":"AWS EC2 React Static Website Now you are ready to deploy a static website to a brand new EC2 instance. Let’s begin by creating a brand new EC2. Below you will find the appropriate settings for this walkthrough.\nEC2 Settings  Name: “first-static-website” Machine Image: “Ubuntu 22.04 LTS” Instance Type: “t2.micro” Key Pair: “first-key-pair” Security Group: “Create Security Group”  Allow SSH Traffic from Anywhere Allow HTTPs traffic from the internet Allow HTTP Traffic from the internet   Storage: Default  Once you have all of the above options selected you are ready to launch your EC2 instance.\nValidation Click the Launch Instance button.\nClick on the Instance ID to view the summary page for the new EC2 instance.\nConnect to the Instance Click on the Connect button.\nEC2 Instance Connect Within the EC2 Instance Connect click on the Connect button.\n Note The Instance ID and the Public IP Address will have different values for you.\n  Getting Organized The objective for this walkthrough is to deploy a static React application to an EC2 instance. Below you will find a list of items needed in order to accomplish this task:\n Build artificats of the React project   Note The build artifacts for the react project are located within this github repository: https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts.git\n  Web Server to deploy application: This walkthrough will utilize Caddy as the web server.  Clone the Build Artifacts Run the following command:\ngit clone https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts.git Caddy Installation sudo apt update -y  sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list  sudo apt update -y  sudo apt install caddy -y Caddy Install Validation To verify that you have installed caddy run the following command:\nwhich caddy Standing up Static React Website Now that you have a web server installed on your server in addition to the build artifacts you are ready to stand the application up.\nThe default Caddyfile is located in the following location: /etc/caddy/Caddfile.\nEditing the Caddy Config File You will need to edit the file as a sudo user and add the following content:\n Note This walkthrough will be using Vim to edit files. If you are unfamiliar with Vim you can learn more in our Linux Curriculum located here: https://launchcodetechnicaltraining.org/linux/userspace-applications/walkthrough/vim/.\n  Bonus The default Caddyfile will already have text inside. You should see the file with the following information: Feel free to remove all of the information inside of this file. It is simply there as an example.\n  You will need to edit the file as a sudo user and add the following content:\nsudo vim /etc/caddy/Caddyfile  Note In the above image you will need to replace the ip address 184.72.82.98 with your EC2 Instances IPV4 Public IP Address. The above address is specific to the machine used for this walkthrough.\n  In addition to the above you are also specifying that you will be using HTTP because you do not have a DNS attached to the IP address. Since Caddy runs HTTPS by default this is a required addition to the file.\nYou are also pointing to the directory holding the build artifacts for the react project and using the file_server annotation to serve the files.\n Warning You will also need to reload your caddy file after the above changes have been made. There are a couple of ways to accomplish this:\nWhile inside the /etc/caddy/ directory:\nsudo caddy reload From anywhere:\nsudo caddy reload --config /etc/caddy/Caddfile    Validation After completing the above steps you should be able to access the application running on your public IPV4 address while specifying http.\nNavigate a new private browser window to http://your-public-ipv4-address\nTroubleshooting If you are having issues accessing the application in your browser it very well could be a permissions issue. You will find a couple of fixes below that may help you.\n Run the following commands:  sudo systemctl stop caddy sudo caddy start Within your /etc/caddy/ directory:\nsudo caddy reload  bonus I have found that caddy is started and managed automatically by systemctl and if your project directory is in a location with incorrect permissions this can cause issues. Once you run all the commands as the same user it usually fixes the issues of caddy being able to access the project direcrory.\n  ","description":"","tags":null,"title":"React Static Website","uri":"/aws-basics/ec2-web-console/walkthrough/static-websites/react-static-website/"},{"content":"AWS Account Creation Steps The following information is meant to serve as a guide to create a new AWS account using all of the free options.\n Note Please note that you will need to provide a valid credit card while creating your AWS Account. You will not be immediately charged with any fees. This course will utilize all available free-tiers on the platform so that you accrue the absolute minimum amount possible.\n  There will also be an introduction to the billing section of the AWS platform that provides you with all of the information on any costs that you would have under the account.\nPlease click the following link to Create your AWS Account\n Warning If you already have an AWS Account you do not need to create a new one!\n  Click on the Create a Free Account button.\nAWS Email and Account name You will need to provide a Root user email address and an AWS account name.\nAccount Verification After providing the Root user email address and AWS account name you will need to verify the email.\nProvide the verification code sent to your email.\nRoot user password After providing the verification code you will need to create a Root user password for the account.\n Note This password will be used for the root user of the AWS account. Any users added to the AWS account through IAM roles will have their own username and password.\nIf you would like to learn more about IAM roles you can read the documentation here: AWS IAM Roles\n  Contact Information You will now need to provide your contact information.\nYou have the option to select a Business or Personal account. You will be using this as a Personal account.\nwarning Make sure to select Personal for the account type!\n  After filling in the required information you will need to select agree to the terms of the AWS Customer Agreement\nBilling Information Warning Please note that it states the following when completing the billing page:\n“We will not charge you for usage below AWS Free Tier limits. We may temporarily hold up to $1 USD (or an equivalent amount in local currency) as a pending transaction for 3-5 days to verify your identity.”\n  You do need to provide a Credit or Debit card to complete the billing stage.\nConfirm Identity To confirm the identity of the account you will need to verify using Text Message (SMS) or a Voice call.\nIf you have chosen the SMS option you will need to click the Send SMS button to move forward to the next step.\nSMS Verification Provide the SMS verification code\nSupport Plan Once you have provided the last verification you will need to select the Support plan\nYou will be using the Basic support - Free plan.\nClick on the Complete sign up button.\nSetup Complete Once your setup is complete you will receive a notification.\nFeel free to click on the Go to the AWS Management Console button to login.\nRoot User Login To log in to the AWS account you will need to provide the root user email address and password you created earlier in this walkthrough.\nAfter logging in to your your new AWS account you should see a view similar to the following screenshot:\n","description":"","tags":null,"title":"AWS Account Creation","uri":"/aws-basics/aws-account-creation/"},{"content":"Creating Your First S3 Bucket In order to create an S3 Bucket you will need to provide the following:\n Bucket Name: This name must be unique. If there is an existing bucket with the desired name you will not be able to create the bucket. Object Ownership: Public Access: Public access is blocked by default. This behavior can be changed. Bucket Versioning: Encryption:  Bucket Name For your first bucket you will only need to provide a unique name and leave all other options as they have been defaulted.\nThe name I used while creating the bucket is my-first-bucket-john.\nPublic Access For the following walkthroughs, you will need public access to be enabled for the S3 buckets. Public access cannot be blocked if the goal is to host a static website.\nTags You do not need to add a tag for this walkthrough, and the Default Encryption should be disabled.\nAfter you have completed the above steps hit the Create Bucket button.\n","description":"","tags":null,"title":"First S3 Bucket","uri":"/aws-basics/s3/walkthrough/first-s3-bucket/"},{"content":"React S3 Static Website Walkthrough Getting Organized Begin by creating a new S3 Bucket with the following settings:\n Bucket Name: react-tic-tac-toe-[insert random number] AWS Region: default region Object Ownership: ACLs disabled Public Access Settings: All Public Access Allowed Bucket Versioning: Disable Tags: None Default Encryption: Disable Advanced Settings: None  Once you have the above settings correct click the Create bucket button.\nClick on the name of your newly created bucket to view its dashboard.\nCloning Build Artifacts In order to host a static website you will need to upload the build artifacts for the application.\n Note The build artifacts you will be using for this static website are located within this github repository: https://github.com/LaunchCodeTechnicalTraining/react-tic-tac-toe-build-artifacts\n  You will need to clone the above build artifacts to your machine so that you can upload them to your newly created bucket.\nUploading Build Artifacts Once you have cloned the build artifacts click on the Upload button within the console.\nYou will be uploading the build artifacts that you cloned earlier in this walkthrough.\nBonus There are multiple ways that you can upload the build artifacts to this S3 bucket. I simply selected all files within the react-tic-tac-toe-build-artifacts folder to drag and drop them inside.\n  Once you have added the files to be uploaded, scroll to the bottom of the page and click the Upload button.\nValidation Upon uploading the build artifacts to your S3 bucket you should see a notification that lets you know the upload was successful.\nClick on the Close button located near the top right corner of your screen. This will take you back to your bucket dashboard.\nYou should see that the build artifacts are located within the Objects tab of your bucket.\nAll of the files you uploaded are a result of building a React project and taking what was inside of the build folder and storing them as build artifacts.\nEnable Static Website Hosting Now that you have had a look at what is inside the folder, you will need to enable the option for Static Website Hosting within this bucket.\nNavigate back to the main dashboard of your bucket and click the on Properties tab.\nThere are a lot of different properties within this tab. You are looking for the Static Website Hosting property.\nScroll down within this view until you reach the Static Website Hosting section.\nClick on the Edit button.\nClick on the Enable option.\nThis will open up a new menu with the following options:\n Hosting Type: For this walkthrough you will be selecting Host a static website as the option. Index Document: The Index Document you will be using is index.html that you uploaded earlier in this walkthrough. Error Document: This option you will leave as defaulted. Redirection Rules: This option you will leave as defaulted.  After you have selected and filled in the correct values, scroll to the bottom of the page and click the Save Changes button.\nValidation After saving the above changes, scroll to the bottom of your Properties tab and see the changes reflected under Static Website Hosting.\nYou can also now see the endpoint for your static website. In the above screenshot the bucket endpoint is:\n http://react-tic-tac-toe-1.s3-website-us-east-1.amazonaws.com  If you click on the link, your browser should open up a new window. You will most likely receive the following error on that new page:\nThis is there is no bucket policy attached to the react-tic-tac-toe bucket. You will need to attach a new bucket policy to this bucket in order to make the objects available to the public.\nAttaching Bucket Policy Open up the Permissions tab within your S3 Bucket.\nNavigate the permissions view until you come accross the Bucket Policy section as shown below:\nClick on the Edit button.\nThis will open up a new view so that you are able to attach a policy to the bucket.\nYou will be using the bucket policy provided in this article: AWS S3 Security Permissions Document\nYou can find the raw json below:\n{  \"Version\": \"2012-10-17\",  \"Statement\": [  {  \"Sid\": \"PublicReadGetObject\",  \"Effect\": \"Allow\",  \"Principal\": \"*\",  \"Action\": [  \"s3:GetObject\"  ],  \"Resource\": [  \"arn:aws:s3:::Bucket-Name/*\"  ]  }  ] } Add the above Policy to the empty field as shown in the screenshot below, replacing Bucket-Name with the name of your bucket:\n Warning You will need to add the name of your bucket under the “Resource” section in order for the policy to work. Without a valid bucket name you will most likely receive an error if you try to save changes.\n  Click on the Save changes button.\nValidation Now that you have attached a Policy to your bucket, you should be able to access your static website using the link found under the Static Website section under your Properties tab!\n Note This link is publicly available to anyone. Feel free to share the link!\n  ","description":"","tags":null,"title":"React Static Website","uri":"/aws-basics/s3/walkthrough/static-websites/react-static-website/"},{"content":"The following walkthrough content for the AWS S3 service will take you through these steps:\n Creating your first AWS S3 Bucket  Accessing / Connecting to the Bucket   Hosting Static Websites  React Angular    Content Links First S3 Bucket Accessing Your S3 Bucket Static Websites  ","description":"","tags":null,"title":"Walkthrough","uri":"/aws-basics/s3/walkthrough/"},{"content":"Private RDS Connected to EC2 with new VPC  Created a new private RDS Created a new VPC with RDS rules  Added new security rules for ports required  Allow ssh on port 22 Allow 80 for spring app allow port 5432 for RDS database allow 443 for https     Created new EC2 with VPC  Resources Used  VPC RDS EC2  VPC  Two Availability Regions  example: us-east-1-a example2: us-west-1-a   Four Subnets  Two Public Subnets  One Public Subnet for Each region   Two Private Subnets  One Private Subnet for Each region      RDS  Private Subnet  No public access Only Internal Private access   Security Groups  One Security Group  Inbound rules for requests  IPV4 PostgreSQL (TCP) on port 5432   CIDR block:  10.0.0.0/16   Outbound Rules  All traffic all ports everywhere all the time        EC2  Subnets  Subnets are either public or private Availability Zones  us-east-1-a     Security Groups  Security group with multiple rules  Inbound and Outbound Inbound rules  Port 443 for https Port 80 for default http   Outbound rules  All traffic all the time everywhere        ","description":"","tags":null,"title":"EC2 Private RDS","uri":"/aws-basics/ec2-rds/private-rds/"},{"content":"Accesssing Your EC2 Successful Launch Now that you have successfully launched an EC2 Instance you can view the instances dashboard.\nClick on the view all instances button.\nEC2 Instances View This view will show you all instances within the aws account. Once the EC2 has passed all status checks you should see that the instance state is Running\nClick on the Instance ID underneath the Instance ID section. in the above image the Instance ID is i-024d607e6b85c24df.\nInstance Summary View Once you have navigated into the Instance Summary view you will see a variety of details. Some important things to note:\n Public IPv4 address Instance ID VPC ID Subnet ID  This page has the information you would need in order to connect to the instance via SSH or by clicking on the Connect button.\nClick on the Connect button to connect to the server.\nConnecting to your Instance One of the newer AWS features is the ability to connect to your server through the browser using EC2 Instance Connect.\nYou will be connecting to the server using the following:\n Instance ID Public IP address User name  Within the EC2 Instance Connect tab click on the Connect button.\nTerminal Emulator After clicking the connect button your browser will open a new tab and start a new terminal emulator. You should see something similar to the below image:\n","description":"","tags":null,"title":"Access your EC2","uri":"/aws-basics/ec2-web-console/walkthrough/access-ec2/"},{"content":"Deploying a Persistent Spring Boot Application With User Data After deploying the persistent Java application you can take things one step further and create your EC2 instance providing User Data\nUser Data is a way for us to give instructions to the EC2 instance to complete on creation. This allows you to automate the process of installing the requirements to deploy your web application.\nGetting Organized This walkthrough will take the Java/Spring application deployment requirements and store them inside of one script.\nThe Script will need:\n Built Artifacts of application cloned to EC2 Correct version of Java installed on EC2 Web Server installed on EC2 Web Server file configured public-ipv4 address of web server  This will be needed for the web server configuration   Docker installed to create a MySQL container for the database Bash Heredoc within script to write to Web Server configuration file  Scripting with Bash This walkthrough will be completing the above task utilizing a Bash script.\nBonus The steps to manually deploy the application have been included below. The goal of this walkthrough is to have the script perform all of these steps so that the entire process is automated. For more information on scripting please reference the “Bash: Scripting” section from the Linux Curriculum\n  Project Artifacts The artifacts are already built, they just need to be installed onto the virtual machine with git.\n use git to clone the build artifacts   Note Build artifacts for this deployment: https://github.com/LaunchCodeTechnicalTraining/java-techjobs-persistent-artifacts\n  Java This application uses Java 11. To install the correct version of Java you will be using your package manager.\nThe following command will accomplish that.\nsudo apt install openjdk-11-jre -y Web Server caddy, nginx, or some other web server must be installed to catch HTTP requests and respond as a reverse_proxy to the running application.\nBonus You can find Installation steps and further information for both caddy and nginx here:\n Caddy Installation Nginx Installation    Docker Installation In order to keep everything inside of our virtual-server you will be utilizing Docker to run a MySQL container.\nThis allows us to create a MySQL container inside of our virtual-server and configure it’s settings so that our Java application is able to connect to it.\nDocker can be installed using the below commands:\nsudo apt update -y  sudo apt install apt-transport-https ca-certificates curl software-properties-common  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  echo \"deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null  sudo apt update -y  apt-cache policy docker-ce  sudo apt install docker-ce Creating the MySQL Docker Container Environment Variables: docker allows the user to provide enviroment variables when creating the MySQL container.\nThe available environment variables you will be using are as follows:\n MYSQL_ROOT_PASSWORD: Required variable when creating a MySQL docker container MYSQL_USER: Specifies username for database MYSQL_PASSWORD: Specifies password for the username MYSQL_DATABASE: Specifies name of database  Run the below command to create the MySQL container:\nsudo docker run --name name-of-container -p 3306:3306 -e MYSQL_ROOT_PASSWORD=\"admin\" -e MYSQL_USER=\"techjobs\" -e MYSQL_PASSWORD=\"tech\" -e MYSQL_DATABASE=\"techjobs\" -d mysql Starting Java-Spring Application This application was created using environment variables in order to connect to the MySQL database.\nSimilar to creating the docker image you will need to assign the variables values when starting the java application.\nThe available environment variables you will be using are as follows:\n RDS_ENDPOINT: Endpoint for MySQL database. This value will be the auto-assigned ipv4-address of your EC2 instance DB_PORT: Port MySQL is running on (3306) DB_NAME: Name of database DB_USERNAME: Username DB_PASSWORD: Password SERVER_PORT: Designated Port that you want the application to run on.  Run the following command to boot your Java-Spring project and connect to the MySQL database:\njava -DRDS_ENDPOINT=\"ipv4-address\" -DDB_PORT=\"3306\" -DDB_NAME=\"techjobs\" -DDB_USERNAME=\"techjobs\" -DDB_PASSWORD=\"tech\" -DSERVER_PORT=\"8080\" -jar path/to/build/artifacts/java-techjobs-persistent-artifacts.jar   Warning You will need to replace the -DRDS_ENDPOINT=\"ipv4-address\" with the public ipv4-address of your EC2!\nYou will also need to specify the path to the .jar file within your EC2 instance.\n  Configure Web Server This walkthrough will utilize caddy for the web server.\nYou will need to write the required content to the caddy config file with a Bash Heredoc.\nAdd the following content:\nyour-public-ipv4-address {  reverse_proxy 127.0.0.1:8080 } Reload Caddy In order for the changes you made to the default caddy file to take effect you will need to reload caddy.\nRun the following command:\nsudo caddy reload --config /path/to/your/Caddyfile    Click here for Caddy Troubleshooting  If you are having issues with caddy you may need to run the following commands.\nsudo systemctl stop caddy sudo caddy start sudo caddy reload --config /etc/caddy/Caddyfile      Script Solution  public_ipv4_address=$(curl http://169.254.169.254/latest/meta-data/public-ipv4) export public_ipv4_address  sudo apt update -y  ## Clone Build Artifacts  git clone https://github.com/LaunchCodeTechnicalTraining/java-techjobs-persistent-artifacts  ## Install Java  sudo apt install openjdk-11-jre -y  ## Install Caddy  sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list  sudo apt update  sudo apt install caddy  ## Docker Install  sudo apt update -y  sudo apt install apt-transport-https ca-certificates curl software-properties-common  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  echo \"deb [arch=$(dpkg --print-architecture)signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null  sudo apt update  apt-cache policy docker-ce  sudo apt install docker-ce  ## Create Docker MySQL Container   sudo docker run --name java-scripted-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=\"admin\" -e MYSQL_USER=\"techjobs\" -e MYSQL_PASSWORD=\"tech\" -e MYSQL_DATABASE=\"techjobs\" -d mysql  ## Configure Web Server with Heredoc   ( cat \u003c\u003cEOF http://$public_ipv4_address { reverse_proxy 127.0.0.1:8080 } EOF ) \u003e Caddyfile  ## Reload Caddy  sudo caddy reload  ## Start Java Project  sudo java -DRDS_ENDPOINT=\"127.0.0.1\" -DDB_PORT=\"3306\" -DDB_NAME=\"techjobs\" -DDB_USERNAME=\"techjobs\" -DDB_PASSWORD=\"tech\" -DSERVER_PORT=\"8080\" -jar /home/ubuntu/java-techjobs-persistent-artifacts/java-techjobs-persistent-artifacts.jar    ","description":"","tags":null,"title":"Scripting with User Data","uri":"/aws-basics/final-project/java-spring-persistent/java-techjobs-scripted/"},{"content":"Intro to Amazon Simple Storage Service (Amazon S3) Amazon S3 is another one of Amazon’s many Web Services covered in this basics course. One of the great benefits of the S3 service is that you are able to create virtual storage extremely fast.\nThe AWS S3 resource is primarily used to store objects. The service offers scalability, data availability, security, and high performance.\nCommon Use Cases:  Host Static Websites Store and secure small or large amounts of data Backup existing data  How This Course Utilizes Amazon S3:  Hosting Static Websites with Amazon S3 Buckets:  React Application Angular Application    Content Links Walkthrough  ","description":"","tags":null,"title":"Simple Storage Service","uri":"/aws-basics/s3/"},{"content":"SSH Into EC2 Instance Now that we have created a new EC2 Instance we will SSH into the machine from your local terminal.\n","description":"","tags":null,"title":"SSH Key Pair","uri":"/aws-basics/ec2-web-console/walkthrough/ssh-key-pair/"},{"content":"The following walkthrough content for the AWS EC2 service will take you through these steps:\n Creating your first AWS EC2 Instance  Accessing / Connecting to the Instance   Deploying Static Websites  React Angular   Deploying MVC Applications using a Reverse Proxy.  Java/Spring C#/ASP.NET    Content Links First EC2 Instance Access your EC2 Static Websites Reverse Proxy  ","description":"","tags":null,"title":"Walkthrough","uri":"/aws-basics/ec2-web-console/walkthrough/"},{"content":"AWS EC2 Angular Static Website Now you are ready to deploy a static website to a brand new EC2 instance. Let’s begin by creating a brand new EC2. Below you will find the appropriate settings for this walkthrough.\nEC2 Settings  Name: “first-static-website” Machine Image: “Ubuntu 22.04 LTS” Instance Type: “t2.micro” Key Pair: “first-key-pair” Security Group: “Create Security Group”  Allow SSH Traffic from Anywhere Allow HTTPs traffic from the internet Allow HTTP Traffic from the internet   Storage: Default  Once you have all of the above options selected you are ready to launch your EC2 instance.\nValidation Click the Launch Instance button.\nClick on the Instance ID to view the summary page for the new EC2 instance.\nConnect to the Instance Click on the Connect button.\nEC2 Instance Connect Within the EC2 Instance Connect click on the Connect button.\n Note The Instance ID and the Public IP Address will have different values for you.\n  Getting Organized The objective for this walkthrough is to deploy a static Angular application to an EC2 instance. Below you will find a list of items needed in order to accomplish this task:\n Build artificats of the Angular project   Note The build artifacts for the Angular project are located within this github repository: https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts\n  Web Server to deploy application: This walkthrough will utilize Caddy as the web server.  Clone the Build Artifacts Run the following command:\ngit clone https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts Caddy Installation sudo apt update -y  sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg  curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list  sudo apt update -y  sudo apt install caddy -y Caddy Install Validation To verify that you have installed caddy run the following command:\nwhich caddy Standing up Static Angular Website Now that you have a web server installed on your server in addition to the build artifacts you are ready to stand the application up.\nThe default Caddyfile is located in the following location: /etc/caddy/Caddfile.\nEditing the Caddy Config File  Note This walkthrough will be using Vim to edit files. If you are unfamiliar with Vim you can learn more in our Linux Curriculum located here: https://launchcodetechnicaltraining.org/linux/userspace-applications/walkthrough/vim/.\n  Bonus The default Caddyfile will already have text inside. You should see the file with the following information: Feel free to remove all of the information inside of this file. It is simply there as an example.\n  You will need to edit the file as a sudo user and add the following content:\nsudo vim /etc/caddy/Caddyfile  Note In the above image you will need to replace the ip address 18.206.162.35 with your EC2 Instances IPV4 Public IP Address. The above address is specific to the machine used for this walkthrough.\n  In addition to the above you are also specifying that you will be using HTTP because you do not have a DNS attached to the IP address. Since Caddy runs HTTPS by default this is a required addition to the file.\nYou are also pointing to the directory holding the build artifacts for the Angular project and using the file_server annotation to serve the files.\n Warning You will also need to reload your caddy file after the above changes have been made. There are a couple of ways to accomplish this:\nWhile inside the /etc/caddy/ directory:\nsudo caddy reload From anywhere:\nsudo caddy reload --config /etc/caddy/Caddyfile    Validation After completing the above steps you should be able to access the application running on your public IPV4 address while specifying http.\nNavigate a new private browser window to http://your-public-ipv4-address\nTroubleshooting If you are having issues accessing the application in your browser it very well could be a permissions issue. You will find a couple of fixes below that may help you.\n Run the following commands:  sudo systemctl stop caddy sudo caddy start Within your /etc/caddy/ directory:\nsudo caddy reload  bonus I have found that caddy is started and managed automatically by systemctl and if your project directory is in a location with incorrect permissions this can cause issues. Once you run all the commands as the same user it usually fixes the issues of caddy being able to access the project direcrory.\n  ","description":"","tags":null,"title":"Angular Static Website","uri":"/aws-basics/ec2-web-console/walkthrough/static-websites/angular-static-website/"},{"content":"Reverse Proxy for MVC Application This walkthrough will take an MVC application and proxy the HTTP requests to the running application server.\n Note The build artifacts for this walkthrough are located here: https://github.com/LaunchCodeTechnicalTraining/dotnet-mvc-artifacts\n  Machine Settings Create a new EC2 instance with the following:\n Name: your-ec2-name AMI: Ubuntu 22.04 LTS Instance Type: t2-micro (free tier) Key Pair: Proceed without a key pair Network Settings:  VPC: Default Subnet: Default Auto-assign public IP: Enabled Create Security Group  Allow SSH traffic Allow HTTPs traffic Allow HTTP traffic     Storage: Default settings Advanced Details: Default settings  Connecting to EC2 Instance After the EC2 has been created navigate to the dashboard of the EC2 instance.\nClick on the connect button which will take you to the Connect to Instance page.\nVerify your settings are similar to the above screenshot within the EC2 Instance Connect tab.\nClick the Connect button.\nNow that you have connected to your instance it is always good practive to update your server.\nRun the following command:\nsudo apt update -y Project Requirements In order start our C#/ASP.NET application you will need the following:\n Project Artifacts cloned  https://github.com/LaunchCodeTechnicalTraining/dotnet-mvc-artifacts   dotnet CLI installed  dotnet-sdk-3.1   Web Server Installed (Caddy)  Web Server configured (Caddy)    Clone Project Artifacts git clone https://github.com/LaunchCodeTechnicalTraining/dotnet-mvc-artifacts Install dotnet-sdk sudo apt install dotnet-sdk-6.0 Confirm that you want to Install the Package:\n Note Check that the Package has been successfully installed running the following command: which dotnet\n  which dotnet You can see that the Package has been installed and is located in the /usr/bin/ directory.\nYou can also check that you have the correct version installed with the following command:\ndotnet --version You can see that the version is 6.0.x.\nInstall Caddy sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update sudo apt install caddy   Note Verify that caddy was installed using the following commands:\n  which caddy caddy version Configure Web Server Now that you have cloned the project build artifacts in addition to installing the correct SDK and Web Server you need to configure your Caddyfile.\n Note The ASP.NET project will be running on port 5000. That means you will need to configure a reverse proxy within your Caddyfile to handle the HTTP requests to port 5000 on the running server.\n  Run the following command to open your default Caddyfile:\nsudo vim /etc/caddy/Caddyfile Remove all content within the file and overwrite it with the following:\nBonus If you need a refresher on how to use vim you can visit the Linux curriculum here: Vim Introduction\n  http://your-public-ipv4-address {  reverse_proxy 127.0.0.1:5000 } After making changes to your Caddyfile you will need to reload it with the following command:\nsudo caddy reload --config /etc/caddy/Caddyfile Start ASP.NET Application Now that the web server is configured you are ready to start your application.\nNavigate to your dotnet-mvc-artifacts directory and run the following command:\ndotnet run Validation Now that the application is up and running you should be able to access it within your browser.\nOpen a new browser window and access the application at http://your-public-ipv4-address\n","description":"","tags":null,"title":"ASP.NET MVC","uri":"/aws-basics/ec2-web-console/walkthrough/reverse-proxy-websites/dotnet-asp/"},{"content":"Accessing Your New S3 Bucket Now that you have created an S3 Bucket, you will want to access the resource.\nS3 Bucket Dashboard Navigate to the Amazon S3 Dashboard to view your existing buckets.\nClick on the name of your newly created bucket. The bucket I created is named my-first-bucket-john.\n Note This AWS Account also has an already existing bucket named launchcode-blog-images. You will only see the bucket you created in the previous walkthrough unless you have explored and utilized the S3 resource in the past!\n  Individual Bucket Dashboard Once you are viewing your newly created bucket, you will notice there are multiple tabs available.\n Objects: View for all existing objects within the bucket Properties: Various settings available for the bucket Permissions: Permissions for viewing the objects within the bucket (Public Access), any bucket policies, object ownership, and an ACL (Access Control List) Metrics: Data and Usage for the S3 Bucket Management: Lifecycle rules for objects within the bucket Access Points: Manage the access points for the bucket  Now that you have a general understanding of how and where to access your bucket, you are ready to add a folder containing the build artifacts for a static website.\n","description":"","tags":null,"title":"Accessing Your S3 Bucket","uri":"/aws-basics/s3/walkthrough/accessing-s3-bucket/"},{"content":"Angular S3 Static Website Walkthrough Getting Organized Begin by creating a new S3 Bucket with the following settings:\n Bucket Name: orbit-report-static-s3-[insert random number] AWS Region: default region Object Ownership: ACLs disabled Public Access Settings: All Public Access Allowed Bucket Versioning: Disable Tags: None Default Encryption: Disable Advanced Settings: None  Once you have the above settings correct, click the Create bucket button.\nClick on the name of your newly created bucket to view its dashboard.\nCloning Build Artifacts In order to host a static website you will need to upload the build artifacts for the application.\n Note The build artifacts you will be using for this static website are located within this github repository: https://github.com/LaunchCodeTechnicalTraining/orbit-report-artifacts\n  You will need to clone the above build artifacts to your machine so that you can upload them to your newly created bucket.\nUploading Build Artifacts Once you have cloned the build artifacts click on the Upload button within the console.\nYou will be uploading the build artifacts that you cloned earlier in this walkthrough.\nBonus There are multiple ways that you can upload the build artifacts to this S3 bucket. I simply selected all files within the orbit-report-artifacts folder to drag and drop them inside.\n  Once you have added the files to be uploaded, scroll to the bottom of the page and click the Upload button.\nValidation Upon uploading the build artifacts to your S3 bucket you should see a notification that lets you know the upload was successful.\nClick on the Close button located near the top right corner of your screen. This will take you back to your bucket dashboard.\nYou should see that the build artifacts are located within the Objects tab of your bucket.\nAll of the files you uploaded are a result of building an Angular project and taking what was inside of the build folder and storing them as build artifacts.\nEnable Static Website Hosting Now that you have had a look at what is inside of the folder you will need to enable the option for Static Website Hosting within this bucket.\nNavigate back to the main dashboard of your bucket and click the on Properties tab.\nThere are a lot of different properties within this tab. You are looking for the Static Website Hosting property.\nScroll down within this view until you reach the Static Website Hosting section.\nClick on the Edit button.\nClick on the Enable option.\nThis will open up a new menu with the following options:\n Hosting Type: For this walkthrough you will be selecting Host a static website as the option. Index Document: The Index Document you will be using is index.html that you uploaded earlier in this walkthrough. Error Document: This option you will leave as defaulted. Redirection Rules: This option you will leave as defaulted.  After you have selected and filled in the correct values scroll to the bottom of the page and click the Save Changes button.\nValidation After saving the above changes you should be able to scroll to the bottom of your Properties tab and see the changes reflected under Static Website Hosting.\nYou can also now see the endpoint for your static website. In the above screenshot the bucket endpoint is:\n http://my-first-bucket-john.s3-website-us-east-1.amazonaws.com  If you click on the link your browser should open up a new window. You will most likely receive the following error on that new page:\nThis is there is no bucket policy attached to the orbit-report-bucket. You will need to attach a new bucket policy to this bucket in order to make the objects available to the public.\nAttaching Bucket Policy Open up the Permissions tab within your S3 Bucket.\nNavigate the permissions view until you come accross the Bucket Policy section as shown below:\nClick on the Edit button.\nThis will open up a new view so that you are able to attach a policy to the bucket.\nYou will be using the bucket policy provided in this article: AWS S3 Security Permissions Document\nYou can find the raw json below:\n{  \"Version\": \"2012-10-17\",  \"Statement\": [  {  \"Sid\": \"PublicReadGetObject\",  \"Effect\": \"Allow\",  \"Principal\": \"*\",  \"Action\": [  \"s3:GetObject\"  ],  \"Resource\": [  \"arn:aws:s3:::Bucket-Name/*\"  ]  }  ] } Add the above Policy to the empty field as shown in the screenshot below, replacing Bucket-Name with the name of your bucket:\n Warning You will need to add the name of your bucket under the “Resource” section in order for the policy to work. Without a valid bucket name you will most likely receive an error if you try to save changes.\n  Click on the Save changes button.\nValidation Now that you have attached a Policy to your bucket you should now be able to access your static website using the link found under the Static Website section under your Properties tab!\n Note This link is publicly available to anyone. Feel free to share the link!\n  ","description":"","tags":null,"title":"Angular Static Website","uri":"/aws-basics/s3/walkthrough/static-websites/angular-static-website/"},{"content":"Intro to Amazon Elastic Compute Cloud (Amazon EC2) Amazon EC2 is one of Amazon’s many Web Services. One of the great benefits of the EC2 service is that you are able to create a virtual server within the cloud extremely fast.\nThe EC2 service is commonly referred to as secure, scalable, and reliable.\nDependant upon the requirements for your application, any Virtual Server you create within the EC2 service is customizable with various Instance Types, Network Settings, and Storage.\nSome of these settings are slightly out of scope for what we are trying to accomplish with this course. We will be utilizing the free tier eligible options so that you do not accrue larger amounts of cost when using AWS.\nCommon Use Cases  Hosting a web application Testing Load Balancing Migration  How This Course Utilizes Amazon EC2:  Deploying Static Websites to Virtual Linux Server’s:  Angular Application React Application   Deploying Persistent Web Applications to a Virtual Linux Server connected to a private RDS Database  Java/Spring Application    Bonus  To learn more about the Amazon Elastic Compute Cloud service please visit the AWS Docs: Amazon EC2    Content Links Walkthrough  ","description":"","tags":null,"title":"Elastic Compute Cloud","uri":"/aws-basics/ec2-web-console/"},{"content":"Walkthrough Content Links React Static Website Angular Static Website  ","description":"","tags":null,"title":"Static Websites","uri":"/aws-basics/ec2-web-console/walkthrough/static-websites/"},{"content":"Walkthrough The following walkthroughs will take MVC application build artifacts and deploy them to an EC2 instance.\nThese applications will need to be running on our virtual server and our web server. At that point you will be able to proxy the HTTP requests to the running server.\nThis will allow the applications to be available on the web.\nContent Links Java Spring MVC ASP.NET MVC  ","description":"","tags":null,"title":"Reverse Proxy","uri":"/aws-basics/ec2-web-console/walkthrough/reverse-proxy-websites/"},{"content":"AWS EC2 Notes Information needed to create a new EC2  image AMI = ami-09d56f8956ab235b3 instante type = (t2.micro) count = 1 SSH Key Pair = MyKeyPair VPC ID = vpc-db768aa6 Subnet ID = subnet-46ab0719 Security ID = sg-024730b92b8c9258e  Complete command to create new EC2 Instance:\naws ec2 run-instances --image-id ami-xxxxxxxx --count 1 --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-903004f8 --subnet-id subnet-6e7f829e   Note All of the IDs are from this specific example: EC2-VPC section\n  Finding the --image-id AMI --image-id ami-xxxxxxxx: Navigated to web console located here and looked up Ubuntu 22.04: ami-09d56f8956ab235b3 (64-bit (x86) option)\n Note --count: How many instances to create\n--instance-type: Processor of the server\n  Finding the --key-name If you already have a public key you can provide the key instead of creating a new one.\nCreating a New Key Pair if Necessary To create a new key-pair using the AWS CLI:\naws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text \u003e MyKeyPair.pem   Note You can replace “MyKeyPair” with the desired key name. This will be stored on the ec2 web console page as the public key for the instance. Also rename “MyKeyPair.pem” to the desired pem file name on your local machine. This is your private key. The permissions need to be 400 for the local key file.\nhttps://us-east-1.console.aws.amazon.com/ec2/v2/home?region=us-east-1#KeyPairs:\n  Find VPC Id For this POC we used the default PVC provided by AWS. Located here: https://us-east-1.console.aws.amazon.com/vpc/home?region=us-east-1#vpcs:VpcId=vpc-db768aa6\n Note We still need to explore creating a VPC using the CLI:\nAWS-VPC-CLI Docs\n  Find Subnet Id To find the subnets available for each VPC: https://us-east-1.console.aws.amazon.com/vpc/home?region=us-east-1#subnets:\nFind the Security Group Id If you already have a previously created security group you can provide the id which is located here: https://us-east-1.console.aws.amazon.com/ec2/v2/home?region=us-east-1#SecurityGroups:\nCreate new Security Group if Necessary To create a new security group using the CLI you can run the following command:\naws ec2 create-security-group --group-name my-sg --description \"My security group\" --vpc-id vpc-1a2b3c4d Command we executed:\naws ec2 create-security-group --group-name New-Group-Name --description \"New Security Group\" --vpc-id vpc-db768aa6 Add New Policy to Existing Security Group aws ec2 authorize-security-group-ingress –group-id sg-903004f8 –protocol tcp –port 3389 –cidr x.x.x.x\nCommand we executed:\naws ec2 authorize-security-group-ingress --group-id sg-903004f8 --protocol ssh --port 22 --cidr $(curl ipinfo.io/ip) Connect to machine:  ssh -i .pem-file ubuntu@server-address  Content Links  ","description":"","tags":null,"title":"EC2 Static Website CLI Outline","uri":"/aws-basics/ec2-web-console/walkthrough/ec2-static-cli/"},{"content":"S3 Static Website Walkthrough Below will be the walkthrough portion for an s3 static website using the web console\nContent Links React Static Website Angular Static Website  ","description":"","tags":null,"title":"Static Websites","uri":"/aws-basics/s3/walkthrough/static-websites/"},{"content":"Load Balancer Handling traffic and sending it to the appropriate location based on volume.\n EC2 taking amount of load and spinning up targets in the target group. How many do we have, whos requests are we sending to? This makes it so that none of our ec2s crash. 1 load balancer, ingress points, autoscales the target group, sometimes you will have multiple autoscaling groups. 3 squares. The VPC, the autoscaling group, and the target group How to define a target, target group, auto scaling group, load balancer inside of a target group, how to configure the load balancer? How to set the load? How much is too much?  New VPC Created:\nLoad Balancing:\n Load Balancers Target Groups Auto Scaling Launch Configs Auto Scaling Groups  Internal: Private Internet-Facing: Public\nVPC First to be (created), entire network where everything is living. Made up of subnets both public and private\nTarget Group Everything that gets launched is going to live inside of the target group. Only the EC2s that get created, part of the autoscaling group, managed by the load balancer\nLaunch Template Template with specifics about the EC2 Instance. What type of instance or machine are we letting AWS know we want to create?\nLoad Balancer Using an EC2 as our load balancer, server whos responsibility is to check the health of everything in the target group, Scaling up and down, proxying internet requests to those machines.\nAutoScaling Group (Last Thing to Be created). Collection of the load balancer (brain), target group (nodes), Launch Template (what will each node become), VPC (holds all of this).\n","description":"","tags":null,"title":"EC2 Load Balancer","uri":"/aws-basics/load-balancer/"},{"content":"Recap This AWS intro course has covered two of the most commonly used AWS Resources:\n Amazon S3  Static Websites  React Angular     Amazon EC2  Static Websites  React Angular   Reverse Proxy  Java/Spring Application C#/ASP.NET Application      At this point you have learned how to deploy the above applications using the S3 and EC2 resource. Taking things a step further you will do the following:\n Deploy a Persistent Java/Spring Application to a new EC2 instance.  Utilize a docker container that will be running MySQL for your database Connect the running application to the docker container with environment variables Reverse Proxy the HTTP requests to the running server   Script all of the above with a Bash script.  Java Spring Persistent Scripting with User Data  ","description":"","tags":null,"title":"Final Project","uri":"/aws-basics/final-project/"},{"content":"Outline of AWS Curriculum - Goal of Class - Learning how to deploy an application to the cloud, not necessarily learning about AWS specifically  EC2 Static - Web Console - CLI  EC2 RDS - Web Console - Public RDS - Private RDS - CLI - Public RDS - Private RDS  S3 to serve Static Files - Web Console - CLI  Other Topics to Potentially Include: - IAM - IAM Policy Structure - Creating new users - Creating new groups - EC2 - Instance Types  Final Project - MVC Application - Stretch Goal - Front end todo, API todo - Full stack project deployed using console and CLI - Angular/React + Spring/.NET + Database - Completed using User Data for initialization Script - Project can be something created previously, LC101 assignment, previous LiftOff Graduate project  EC2 First Walkthrough - Creating a new EC2 - image AMI - Instance Type - Number of Instances - SSH Key Pair - VPC ID - Subnet ID - Security ID - Change Permissions on Created SSH - ssh -i path/to/keypair ubuntu@server-ip - Once inside of the instance, do what? - Recreate Steps for CLI  EC2 Static Server Walkthrough - Create new EC2 using previously created subnets, security groups - Initialize Static File Server with User Data - Recreate Steps for CLI  EC2 RDS Walkthrough - Create your first RDS database - Provide Subnet - Provide Security Group - Connect RDS to Existing EC2  S3 Bucket Walkthrough - Create new S3 Bucket - secure copy files from local machine to s3 bucket as example - secure copy build artifcats to s3 bucket and initialize static website  Questions ? - Exercises? - What do I want to give them? Having taught the Linux course what did they say they liked or learned the most from? - Really enjoyed the exercises, enjoyed the Q\u0026A. - Source code repo or artifacts, requirements for infrastructure, paragraph? list? ec2? rds? s3? How is that outlined? Drawn diagram? - How to deliver the information as curriculum developer and teacher - Diagram to reflect infrastructure? - Potential Exercise  Walkthrough Order - Basic EC2 Console + CLI - Smallest I can build for using the web console? - 2 or 3 POCs for only web console instructions for EC2 static, S3 Static, EC2 MVC - Then do CLIs for exact same things - Is end goal to deploy everything with CLI? Or to use some combination of CLI and console they are comfortable deploying basic things on their own - Company will move towards IAC - Maybe not everything needs CLI instructions? Bonus missions to use CLI to accomplish the same things they just did -  ","description":"","tags":null,"title":"Curriculum Outline","uri":"/aws-basics/outline/"},{"content":"Content Links Public RDS EC2 Private RDS  ","description":"","tags":null,"title":"EC2 Rds","uri":"/aws-basics/ec2-rds/"},{"content":"AWS Basics What is this Course This course is an introduction to the AWS Console.\nThis course is designed to provide an understanding of some fundamental skills necessary to deploy web applications to a cloud environment. You will become familiar with\nWhy take this Course Learning how to navigate the AWS Console using the Amazon EC2 and Amazon S3 services to deploy static web applications is a great introduction to cloud services.\nYou will also learn how to connect an Amazon EC2 instance to an Amazon RDS Datastore for applications that utilize a database.\nThis will give you an excellent understanding of what steps you need to take in order to take applications that you or others have built and deploy them to the cloud so that they are available publicly.\nWhere this Course Leads Upon completing the content within this course you will be capable of configuring a virtual server within a cloud environment with deployed web applications.\nThe next step would be to learn additional cloud services so that you can integrate them with one another, make them scalable, and more secure.\nSegments / Chapters Introduction AWS Account Creation Simple Storage Service Elastic Compute Cloud Final Project  Pre-Course Requirements The only requirement to complete the content within this course is to have an AWS Account Created utilizing all free-tier eligible options.\n","description":"","tags":null,"title":"Home","uri":"/aws-basics/"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/aws-basics/categories/"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/aws-basics/tags/"}]